{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ed97d679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Dense,Flatten,Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import SimpleRNN,Input,Activation,Reshape,LSTM,GRU,Conv2D,MaxPooling2D,Flatten,Embedding,Dense,Dropout,UpSampling2D\n",
    "import torch\n",
    "import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8cab882",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e1200d",
   "metadata": {},
   "source": [
    "####  Toutology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaa8df64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tout(x):\n",
    "    weights = np.array([0,0])\n",
    "    bias = 1\n",
    "    y = np.dot(x,weights) + bias\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b52c9ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(tout(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35471e35",
   "metadata": {},
   "source": [
    "#### Not Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15136255",
   "metadata": {},
   "outputs": [],
   "source": [
    "### AND Gate\n",
    "\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "weights = np.array([[1],[1]])\n",
    "bias = np.array([-1])\n",
    "\n",
    "out = X@weights + bias\n",
    "y = np.array(list(map(step, out))).reshape(4,1)\n",
    "print(y)\n",
    "\n",
    "### OR Gate\n",
    "\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "weights = np.array([[1],[1]])\n",
    "bias = np.array([0])\n",
    "\n",
    "out = X@weights + bias\n",
    "y = np.array(list(map(step, out))).reshape(4,1)\n",
    "print(y)\n",
    "\n",
    "### NOR Gate\n",
    "\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "weights = np.array([[-1],[-1]])\n",
    "bias = np.array([1])\n",
    "\n",
    "out = X@weights + bias\n",
    "y = np.array(list(map(step, out))).reshape(4,1)\n",
    "print(y)\n",
    "\n",
    "### NAND Gate\n",
    "\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "weights = np.array([[-1],[-1]])\n",
    "bias = np.array([2])\n",
    "\n",
    "out = X@weights + bias\n",
    "y = np.array(list(map(step, out))).reshape(4,1)\n",
    "print(y)\n",
    "\n",
    "### Perceptron Training\n",
    "\n",
    "# Dataset\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "Y = np.array([[1],[1],[1],[1]])\n",
    "\n",
    "# Initialize Random Weights\n",
    "weights = np.random.rand(2,1)\n",
    "\n",
    "# Step Function\n",
    "def step(x):\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "# Training Loop\n",
    "epoch = 10000\n",
    "lr = 0.01\n",
    "\n",
    "for _ in range(epoch):\n",
    "    \n",
    "    # Forward Pass\n",
    "    y_cap = np.array(list(map(step,X@weights))).reshape(Y.shape)\n",
    "    \n",
    "    # Calculate Error\n",
    "    error = Y - y_cap\n",
    "    \n",
    "    # Update Weights\n",
    "    weights -= lr*(X.T@error)\n",
    "\n",
    "print(f\"Weights\",weights,sep=\"\\n\",end=\"\\n\\n\")\n",
    "print(f\"Output\",y_cap,sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb439d7",
   "metadata": {},
   "source": [
    "### XOR "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abd1c43",
   "metadata": {},
   "source": [
    "1 Input Layer <br>\n",
    "1 Hidden Layer - 2 Neurons <br>\n",
    "1 Output Layer - 1 Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b7022d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(x):\n",
    "    return 1 if x>0 else 0\n",
    "step = np.vectorize(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05fb2241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "w1 = np.array([[1,-1],[-1,1]])\n",
    "w2 = np.array([[1],[1]])\n",
    "\n",
    "y_cap = step(step(x@w1)@w2)\n",
    "y_cap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff59513c",
   "metadata": {},
   "source": [
    "### XNOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b823a1f",
   "metadata": {},
   "source": [
    "1 Input Layer <br>\n",
    "1 Hidden Layer - 2 Neurons <br>\n",
    "1 Output Layer - 1 Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3c45080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([[1],[0],[0],[1]])\n",
    "\n",
    "w1 = np.array([[1,-1],[1,-1]])\n",
    "w2 = np.array([[1],[1]])\n",
    "\n",
    "bias = np.array([[-1,1]])\n",
    "\n",
    "y_cap = step(step(x@w1 + bias)@w2)\n",
    "y_cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51900d92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912e28ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae137ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7c9043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83632448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edecb32e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2507cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae35886b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71ecbcc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6080b48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = tf.keras.datasets.boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b9dfad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = x_train.mean()\n",
    "x_train = x_train - mean\n",
    "std = x_train.std()\n",
    "x_train/=std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a9907870",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test -= mean\n",
    "x_test /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8e377881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 13)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea2a684",
   "metadata": {},
   "source": [
    "### MODEL 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0431a0ef",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 139.0666 - val_loss: 76.8312\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.1396 - val_loss: 50.8851\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 40.5181 - val_loss: 40.7767\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 33.1572 - val_loss: 37.7680\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 31.4480 - val_loss: 36.5413\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 31.0195 - val_loss: 35.9174\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8785 - val_loss: 35.6408\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8472 - val_loss: 35.6277\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8731 - val_loss: 35.5813\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8820 - val_loss: 35.6672\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8699 - val_loss: 35.7118\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.9116 - val_loss: 35.6478\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9081 - val_loss: 35.7112\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8952 - val_loss: 35.5889\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8489 - val_loss: 35.4892\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8661 - val_loss: 35.4336\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8825 - val_loss: 35.4351\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8908 - val_loss: 35.5996\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8610 - val_loss: 35.5091\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8782 - val_loss: 35.5005\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8476 - val_loss: 35.5071\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8837 - val_loss: 35.4777\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8661 - val_loss: 35.5638\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8387 - val_loss: 35.5960\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8854 - val_loss: 35.7152\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8643 - val_loss: 35.7275\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8705 - val_loss: 35.6263\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8675 - val_loss: 35.6274\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8534 - val_loss: 35.5837\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8803 - val_loss: 35.5165\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8441 - val_loss: 35.6324\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8554 - val_loss: 35.6472\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 30.8378 - val_loss: 35.5920\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8739 - val_loss: 35.6647\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8538 - val_loss: 35.6262\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8669 - val_loss: 35.6260\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8577 - val_loss: 35.6121\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8513 - val_loss: 35.5615\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8693 - val_loss: 35.5163\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8690 - val_loss: 35.5153\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8822 - val_loss: 35.5320\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8613 - val_loss: 35.5438\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8653 - val_loss: 35.6011\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8615 - val_loss: 35.6319\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8627 - val_loss: 35.7610\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8608 - val_loss: 35.6141\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8849 - val_loss: 35.6089\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8927 - val_loss: 35.6325\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8810 - val_loss: 35.6651\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8484 - val_loss: 35.6257\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 30.8442 - val_loss: 35.6425\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 30.8523 - val_loss: 35.7531\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8529 - val_loss: 35.6918\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8521 - val_loss: 35.6158\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8760 - val_loss: 35.6980\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8619 - val_loss: 35.6099\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8682 - val_loss: 35.6425\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 30.8729 - val_loss: 35.5625\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8827 - val_loss: 35.5780\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8642 - val_loss: 35.6559\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8570 - val_loss: 35.6714\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8626 - val_loss: 35.5480\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8775 - val_loss: 35.6615\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 30.9207 - val_loss: 35.6016\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 30.8777 - val_loss: 35.6584\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 30.8868 - val_loss: 35.6119\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 30.8936 - val_loss: 35.5838\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 30.8602 - val_loss: 35.6330\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 30.8737 - val_loss: 35.7287\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 30.8580 - val_loss: 35.6800\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 30.8820 - val_loss: 35.7265\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 30.8653 - val_loss: 35.6305\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8841 - val_loss: 35.6548\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8608 - val_loss: 35.6017\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8543 - val_loss: 35.4472\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.9005 - val_loss: 35.6430\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8859 - val_loss: 35.5646\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8896 - val_loss: 35.5474\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8487 - val_loss: 35.4861\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8677 - val_loss: 35.5951\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8546 - val_loss: 35.6381\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8655 - val_loss: 35.6115\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8673 - val_loss: 35.6445\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8919 - val_loss: 35.5857\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8572 - val_loss: 35.5356\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8683 - val_loss: 35.5591\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8642 - val_loss: 35.5858\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8651 - val_loss: 35.6464\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8545 - val_loss: 35.5557\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8619 - val_loss: 35.6483\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 30.9025 - val_loss: 35.5347\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8644 - val_loss: 35.5976\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8471 - val_loss: 35.5375\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8802 - val_loss: 35.5398\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8579 - val_loss: 35.6028\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8616 - val_loss: 35.6568\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8563 - val_loss: 35.6198\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8670 - val_loss: 35.5444\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8688 - val_loss: 35.5321\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8573 - val_loss: 35.5745\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8673 - val_loss: 35.5768\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8767 - val_loss: 35.6443\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8440 - val_loss: 35.5781\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 30.8737 - val_loss: 35.5430\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8821 - val_loss: 35.4967\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8347 - val_loss: 35.6329\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8962 - val_loss: 35.5772\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8926 - val_loss: 35.5379\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8664 - val_loss: 35.6010\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8922 - val_loss: 35.5955\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8632 - val_loss: 35.5870\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8999 - val_loss: 35.5460\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8567 - val_loss: 35.5219\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9438 - val_loss: 35.5529\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8517 - val_loss: 35.6080\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8696 - val_loss: 35.6720\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8820 - val_loss: 35.5204\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8706 - val_loss: 35.5162\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8763 - val_loss: 35.4207\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9183 - val_loss: 35.5040\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8718 - val_loss: 35.5853\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8680 - val_loss: 35.5778\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8730 - val_loss: 35.5446\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 30.8624 - val_loss: 35.6051\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8533 - val_loss: 35.4954\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8553 - val_loss: 35.5220\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8679 - val_loss: 35.5271\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8315 - val_loss: 35.6239\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8459 - val_loss: 35.5510\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8659 - val_loss: 35.5978\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8641 - val_loss: 35.5511\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8549 - val_loss: 35.5719\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8582 - val_loss: 35.5865\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8564 - val_loss: 35.5639\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8604 - val_loss: 35.4936\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8511 - val_loss: 35.5618\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9322 - val_loss: 35.4531\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8835 - val_loss: 35.4563\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8738 - val_loss: 35.3632\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9180 - val_loss: 35.4546\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8768 - val_loss: 35.5422\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8895 - val_loss: 35.5350\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8453 - val_loss: 35.7464\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8685 - val_loss: 35.6317\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8997 - val_loss: 35.5836\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.9158 - val_loss: 35.4723\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8535 - val_loss: 35.4299\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8619 - val_loss: 35.5310\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8733 - val_loss: 35.6224\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8628 - val_loss: 35.6135\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8702 - val_loss: 35.5820\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8747 - val_loss: 35.6246\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8273 - val_loss: 35.7257\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8580 - val_loss: 35.6524\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8434 - val_loss: 35.6205\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8731 - val_loss: 35.6031\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8960 - val_loss: 35.5561\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8749 - val_loss: 35.5392\n",
      "Epoch 159/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8687 - val_loss: 35.6392\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8999 - val_loss: 35.6828\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9036 - val_loss: 35.7167\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8701 - val_loss: 35.6338\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8444 - val_loss: 35.6062\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8521 - val_loss: 35.6851\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8936 - val_loss: 35.5382\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8527 - val_loss: 35.4675\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8959 - val_loss: 35.5292\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8916 - val_loss: 35.5975\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8841 - val_loss: 35.6040\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8739 - val_loss: 35.7793\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8844 - val_loss: 35.7700\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8985 - val_loss: 35.7029\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8615 - val_loss: 35.5406\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8698 - val_loss: 35.5621\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8349 - val_loss: 35.5903\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8747 - val_loss: 35.5997\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8493 - val_loss: 35.6518\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8935 - val_loss: 35.7111\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8523 - val_loss: 35.7660\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8577 - val_loss: 35.6823\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8691 - val_loss: 35.6360\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8822 - val_loss: 35.6207\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8856 - val_loss: 35.5841\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8792 - val_loss: 35.5820\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8438 - val_loss: 35.5067\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8682 - val_loss: 35.5032\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8600 - val_loss: 35.6660\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8600 - val_loss: 35.6156\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8612 - val_loss: 35.6940\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8525 - val_loss: 35.5941\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8926 - val_loss: 35.5550\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8420 - val_loss: 35.5543\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8883 - val_loss: 35.5074\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8699 - val_loss: 35.4610\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8483 - val_loss: 35.4657\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8535 - val_loss: 35.5873\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8590 - val_loss: 35.5149\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8730 - val_loss: 35.6204\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8527 - val_loss: 35.5959\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8447 - val_loss: 35.5431\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8670 - val_loss: 35.5370\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8543 - val_loss: 35.4892\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8486 - val_loss: 35.5603\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8606 - val_loss: 35.5496\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8942 - val_loss: 35.5427\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8842 - val_loss: 35.5949\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8442 - val_loss: 35.6760\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8743 - val_loss: 35.5697\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8582 - val_loss: 35.4976\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8655 - val_loss: 35.5680\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8570 - val_loss: 35.4239\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8864 - val_loss: 35.3646\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9118 - val_loss: 35.4514\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8477 - val_loss: 35.5144\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8783 - val_loss: 35.5242\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8836 - val_loss: 35.5016\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8550 - val_loss: 35.5254\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8732 - val_loss: 35.5641\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8728 - val_loss: 35.5799\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8547 - val_loss: 35.5365\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8807 - val_loss: 35.5030\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8940 - val_loss: 35.6077\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8824 - val_loss: 35.6436\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8474 - val_loss: 35.4907\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8832 - val_loss: 35.4345\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.9316 - val_loss: 35.5651\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8609 - val_loss: 35.5965\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8817 - val_loss: 35.6198\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8628 - val_loss: 35.5380\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8526 - val_loss: 35.6022\n",
      "Epoch 231/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8518 - val_loss: 35.5699\n",
      "Epoch 232/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9170 - val_loss: 35.5778\n",
      "Epoch 233/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8773 - val_loss: 35.5793\n",
      "Epoch 234/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8604 - val_loss: 35.6470\n",
      "Epoch 235/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8720 - val_loss: 35.7708\n",
      "Epoch 236/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8810 - val_loss: 35.6829\n",
      "Epoch 237/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 30.8643 - val_loss: 35.7076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8878 - val_loss: 35.5018\n",
      "Epoch 239/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9024 - val_loss: 35.5138\n",
      "Epoch 240/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8548 - val_loss: 35.6048\n",
      "Epoch 241/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8667 - val_loss: 35.6281\n",
      "Epoch 242/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8901 - val_loss: 35.5833\n",
      "Epoch 243/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 30.8881 - val_loss: 35.5716\n",
      "Epoch 244/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8928 - val_loss: 35.5634\n",
      "Epoch 245/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8917 - val_loss: 35.5821\n",
      "Epoch 246/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8511 - val_loss: 35.6377\n",
      "Epoch 247/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8935 - val_loss: 35.4854\n",
      "Epoch 248/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8385 - val_loss: 35.5275\n",
      "Epoch 249/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8486 - val_loss: 35.5755\n",
      "Epoch 250/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8700 - val_loss: 35.4126\n",
      "Epoch 251/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8802 - val_loss: 35.4307\n",
      "Epoch 252/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8605 - val_loss: 35.5222\n",
      "Epoch 253/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8672 - val_loss: 35.4650\n",
      "Epoch 254/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8642 - val_loss: 35.6050\n",
      "Epoch 255/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8604 - val_loss: 35.7430\n",
      "Epoch 256/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8587 - val_loss: 35.6938\n",
      "Epoch 257/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8600 - val_loss: 35.6070\n",
      "Epoch 258/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8664 - val_loss: 35.5669\n",
      "Epoch 259/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8485 - val_loss: 35.5068\n",
      "Epoch 260/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8517 - val_loss: 35.4855\n",
      "Epoch 261/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8625 - val_loss: 35.4960\n",
      "Epoch 262/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8676 - val_loss: 35.5192\n",
      "Epoch 263/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8585 - val_loss: 35.6252\n",
      "Epoch 264/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8935 - val_loss: 35.5337\n",
      "Epoch 265/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8673 - val_loss: 35.5025\n",
      "Epoch 266/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8767 - val_loss: 35.5109\n",
      "Epoch 267/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8569 - val_loss: 35.5557\n",
      "Epoch 268/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8506 - val_loss: 35.5563\n",
      "Epoch 269/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8771 - val_loss: 35.5658\n",
      "Epoch 270/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8575 - val_loss: 35.5345\n",
      "Epoch 271/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8436 - val_loss: 35.6892\n",
      "Epoch 272/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8901 - val_loss: 35.6054\n",
      "Epoch 273/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8434 - val_loss: 35.5439\n",
      "Epoch 274/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8741 - val_loss: 35.5740\n",
      "Epoch 275/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8865 - val_loss: 35.5573\n",
      "Epoch 276/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8446 - val_loss: 35.5086\n",
      "Epoch 277/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8503 - val_loss: 35.5625\n",
      "Epoch 278/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8552 - val_loss: 35.5528\n",
      "Epoch 279/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9161 - val_loss: 35.5008\n",
      "Epoch 280/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8629 - val_loss: 35.4568\n",
      "Epoch 281/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8518 - val_loss: 35.5104\n",
      "Epoch 282/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8748 - val_loss: 35.5012\n",
      "Epoch 283/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8511 - val_loss: 35.5956\n",
      "Epoch 284/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8551 - val_loss: 35.5627\n",
      "Epoch 285/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8481 - val_loss: 35.4841\n",
      "Epoch 286/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8456 - val_loss: 35.6609\n",
      "Epoch 287/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 30.8506 - val_loss: 35.5780\n",
      "Epoch 288/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 30.8977 - val_loss: 35.5668\n",
      "Epoch 289/1000\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 30.8774 - val_loss: 35.4988\n",
      "Epoch 290/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 30.8802 - val_loss: 35.5542\n",
      "Epoch 291/1000\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 30.8459 - val_loss: 35.5279\n",
      "Epoch 292/1000\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 30.8608 - val_loss: 35.6210\n",
      "Epoch 293/1000\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 30.9049 - val_loss: 35.6825\n",
      "Epoch 294/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 30.8810 - val_loss: 35.5632\n",
      "Epoch 295/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 30.8645 - val_loss: 35.6438\n",
      "Epoch 296/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8668 - val_loss: 35.6327\n",
      "Epoch 297/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.9293 - val_loss: 35.6717\n",
      "Epoch 298/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8656 - val_loss: 35.5936\n",
      "Epoch 299/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8656 - val_loss: 35.5772\n",
      "Epoch 300/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8689 - val_loss: 35.6142\n",
      "Epoch 301/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 30.8577 - val_loss: 35.6136\n",
      "Epoch 302/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8822 - val_loss: 35.5819\n",
      "Epoch 303/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8641 - val_loss: 35.5663\n",
      "Epoch 304/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8703 - val_loss: 35.6191\n",
      "Epoch 305/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 30.8507 - val_loss: 35.5210\n",
      "Epoch 306/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 30.9084 - val_loss: 35.4982\n",
      "Epoch 307/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9082 - val_loss: 35.5574\n",
      "Epoch 308/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 30.8469 - val_loss: 35.6577\n",
      "Epoch 309/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 30.8743 - val_loss: 35.6263\n",
      "Epoch 310/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 30.8733 - val_loss: 35.6996\n",
      "Epoch 311/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 30.8517 - val_loss: 35.6229\n",
      "Epoch 312/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8591 - val_loss: 35.5845\n",
      "Epoch 313/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8807 - val_loss: 35.5918\n",
      "Epoch 314/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8635 - val_loss: 35.5919\n",
      "Epoch 315/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8770 - val_loss: 35.6602\n",
      "Epoch 316/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 30.8569 - val_loss: 35.7474\n",
      "Epoch 317/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8548 - val_loss: 35.6447\n",
      "Epoch 318/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8718 - val_loss: 35.7750\n",
      "Epoch 319/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8715 - val_loss: 35.6687\n",
      "Epoch 320/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8649 - val_loss: 35.5765\n",
      "Epoch 321/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8754 - val_loss: 35.5453\n",
      "Epoch 322/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8613 - val_loss: 35.5964\n",
      "Epoch 323/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8506 - val_loss: 35.5442\n",
      "Epoch 324/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8747 - val_loss: 35.6006\n",
      "Epoch 325/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9008 - val_loss: 35.5569\n",
      "Epoch 326/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8597 - val_loss: 35.4564\n",
      "Epoch 327/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8489 - val_loss: 35.5022\n",
      "Epoch 328/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8695 - val_loss: 35.4913\n",
      "Epoch 329/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8725 - val_loss: 35.5784\n",
      "Epoch 330/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8611 - val_loss: 35.6090\n",
      "Epoch 331/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8636 - val_loss: 35.5403\n",
      "Epoch 332/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8744 - val_loss: 35.4556\n",
      "Epoch 333/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 30.9037 - val_loss: 35.5424\n",
      "Epoch 334/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8660 - val_loss: 35.5118\n",
      "Epoch 335/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8665 - val_loss: 35.4586\n",
      "Epoch 336/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8521 - val_loss: 35.4585\n",
      "Epoch 337/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8954 - val_loss: 35.5086\n",
      "Epoch 338/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8838 - val_loss: 35.5664\n",
      "Epoch 339/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8436 - val_loss: 35.5575\n",
      "Epoch 340/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8732 - val_loss: 35.6155\n",
      "Epoch 341/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9119 - val_loss: 35.7658\n",
      "Epoch 342/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8845 - val_loss: 35.6433\n",
      "Epoch 343/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8726 - val_loss: 35.6305\n",
      "Epoch 344/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8457 - val_loss: 35.6032\n",
      "Epoch 345/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8604 - val_loss: 35.5790\n",
      "Epoch 346/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8628 - val_loss: 35.6147\n",
      "Epoch 347/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8452 - val_loss: 35.5130\n",
      "Epoch 348/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8378 - val_loss: 35.6380\n",
      "Epoch 349/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8503 - val_loss: 35.6984\n",
      "Epoch 350/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8644 - val_loss: 35.5898\n",
      "Epoch 351/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8434 - val_loss: 35.5948\n",
      "Epoch 352/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8637 - val_loss: 35.6098\n",
      "Epoch 353/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8661 - val_loss: 35.5154\n",
      "Epoch 354/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8557 - val_loss: 35.5164\n",
      "Epoch 355/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8557 - val_loss: 35.5830\n",
      "Epoch 356/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8482 - val_loss: 35.5714\n",
      "Epoch 357/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8407 - val_loss: 35.6334\n",
      "Epoch 358/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8899 - val_loss: 35.6185\n",
      "Epoch 359/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8901 - val_loss: 35.6532\n",
      "Epoch 360/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8616 - val_loss: 35.6312\n",
      "Epoch 361/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8674 - val_loss: 35.6668\n",
      "Epoch 362/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8603 - val_loss: 35.7723\n",
      "Epoch 363/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8593 - val_loss: 35.7308\n",
      "Epoch 364/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8570 - val_loss: 35.7231\n",
      "Epoch 365/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8462 - val_loss: 35.4942\n",
      "Epoch 366/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8578 - val_loss: 35.5189\n",
      "Epoch 367/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8484 - val_loss: 35.5459\n",
      "Epoch 368/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8723 - val_loss: 35.5320\n",
      "Epoch 369/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8663 - val_loss: 35.5982\n",
      "Epoch 370/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8622 - val_loss: 35.6075\n",
      "Epoch 371/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8491 - val_loss: 35.5998\n",
      "Epoch 372/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9126 - val_loss: 35.7050\n",
      "Epoch 373/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8591 - val_loss: 35.6365\n",
      "Epoch 374/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8722 - val_loss: 35.5783\n",
      "Epoch 375/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8894 - val_loss: 35.4595\n",
      "Epoch 376/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8697 - val_loss: 35.4878\n",
      "Epoch 377/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8735 - val_loss: 35.5064\n",
      "Epoch 378/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8506 - val_loss: 35.5728\n",
      "Epoch 379/1000\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 30.8914 - val_loss: 35.5416\n",
      "Epoch 380/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 30.8606 - val_loss: 35.5618\n",
      "Epoch 381/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8692 - val_loss: 35.3996\n",
      "Epoch 382/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8649 - val_loss: 35.5169\n",
      "Epoch 383/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8610 - val_loss: 35.5143\n",
      "Epoch 384/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8719 - val_loss: 35.5381\n",
      "Epoch 385/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8510 - val_loss: 35.5216\n",
      "Epoch 386/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 30.8404 - val_loss: 35.4952\n",
      "Epoch 387/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 30.9201 - val_loss: 35.4949\n",
      "Epoch 388/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8636 - val_loss: 35.6108\n",
      "Epoch 389/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8616 - val_loss: 35.5961\n",
      "Epoch 390/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8763 - val_loss: 35.6549\n",
      "Epoch 391/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8975 - val_loss: 35.5568\n",
      "Epoch 392/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8581 - val_loss: 35.6883\n",
      "Epoch 393/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 30.8601 - val_loss: 35.5918\n",
      "Epoch 394/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8539 - val_loss: 35.5351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 395/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8681 - val_loss: 35.5170\n",
      "Epoch 396/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8503 - val_loss: 35.5639\n",
      "Epoch 397/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8797 - val_loss: 35.5745\n",
      "Epoch 398/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8720 - val_loss: 35.6541\n",
      "Epoch 399/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8774 - val_loss: 35.5716\n",
      "Epoch 400/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8492 - val_loss: 35.6589\n",
      "Epoch 401/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8791 - val_loss: 35.7256\n",
      "Epoch 402/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8610 - val_loss: 35.7026\n",
      "Epoch 403/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8803 - val_loss: 35.7028\n",
      "Epoch 404/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8640 - val_loss: 35.7504\n",
      "Epoch 405/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8550 - val_loss: 35.5838\n",
      "Epoch 406/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8571 - val_loss: 35.6360\n",
      "Epoch 407/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8774 - val_loss: 35.5238\n",
      "Epoch 408/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8989 - val_loss: 35.4718\n",
      "Epoch 409/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9148 - val_loss: 35.5805\n",
      "Epoch 410/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.9162 - val_loss: 35.4862\n",
      "Epoch 411/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8679 - val_loss: 35.5476\n",
      "Epoch 412/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8626 - val_loss: 35.5183\n",
      "Epoch 413/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8986 - val_loss: 35.4953\n",
      "Epoch 414/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8480 - val_loss: 35.5056\n",
      "Epoch 415/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8808 - val_loss: 35.6400\n",
      "Epoch 416/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8825 - val_loss: 35.6430\n",
      "Epoch 417/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8667 - val_loss: 35.6987\n",
      "Epoch 418/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8656 - val_loss: 35.5962\n",
      "Epoch 419/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8977 - val_loss: 35.6368\n",
      "Epoch 420/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8695 - val_loss: 35.6142\n",
      "Epoch 421/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 30.8370 - val_loss: 35.5641\n",
      "Epoch 422/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 30.8529 - val_loss: 35.4542\n",
      "Epoch 423/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8424 - val_loss: 35.5056\n",
      "Epoch 424/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8593 - val_loss: 35.5659\n",
      "Epoch 425/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8522 - val_loss: 35.6382\n",
      "Epoch 426/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8914 - val_loss: 35.5961\n",
      "Epoch 427/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8581 - val_loss: 35.6234\n",
      "Epoch 428/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8833 - val_loss: 35.5646\n",
      "Epoch 429/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 30.8625 - val_loss: 35.4875\n",
      "Epoch 430/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 30.8435 - val_loss: 35.5470\n",
      "Epoch 431/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8569 - val_loss: 35.6091\n",
      "Epoch 432/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8691 - val_loss: 35.5593\n",
      "Epoch 433/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8529 - val_loss: 35.6957\n",
      "Epoch 434/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8680 - val_loss: 35.6255\n",
      "Epoch 435/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8572 - val_loss: 35.5744\n",
      "Epoch 436/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8439 - val_loss: 35.4985\n",
      "Epoch 437/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8792 - val_loss: 35.4585\n",
      "Epoch 438/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8778 - val_loss: 35.4667\n",
      "Epoch 439/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 30.8756 - val_loss: 35.5829\n",
      "Epoch 440/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 30.8712 - val_loss: 35.5494\n",
      "Epoch 441/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8478 - val_loss: 35.4654\n",
      "Epoch 442/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8487 - val_loss: 35.5363\n",
      "Epoch 443/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8569 - val_loss: 35.6156\n",
      "Epoch 444/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8378 - val_loss: 35.5734\n",
      "Epoch 445/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8791 - val_loss: 35.4839\n",
      "Epoch 446/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8932 - val_loss: 35.5442\n",
      "Epoch 447/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8789 - val_loss: 35.6451\n",
      "Epoch 448/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9011 - val_loss: 35.5427\n",
      "Epoch 449/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8793 - val_loss: 35.4974\n",
      "Epoch 450/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8502 - val_loss: 35.5192\n",
      "Epoch 451/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8852 - val_loss: 35.5365\n",
      "Epoch 452/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8785 - val_loss: 35.5939\n",
      "Epoch 453/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9056 - val_loss: 35.5656\n",
      "Epoch 454/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8445 - val_loss: 35.6150\n",
      "Epoch 455/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8551 - val_loss: 35.6252\n",
      "Epoch 456/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8881 - val_loss: 35.6641\n",
      "Epoch 457/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9042 - val_loss: 35.5591\n",
      "Epoch 458/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8494 - val_loss: 35.6489\n",
      "Epoch 459/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8778 - val_loss: 35.7346\n",
      "Epoch 460/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8588 - val_loss: 35.6188\n",
      "Epoch 461/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8645 - val_loss: 35.5544\n",
      "Epoch 462/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8504 - val_loss: 35.4599\n",
      "Epoch 463/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8581 - val_loss: 35.5210\n",
      "Epoch 464/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8493 - val_loss: 35.5551\n",
      "Epoch 465/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8861 - val_loss: 35.5286\n",
      "Epoch 466/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8853 - val_loss: 35.5867\n",
      "Epoch 467/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8848 - val_loss: 35.5152\n",
      "Epoch 468/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8673 - val_loss: 35.5670\n",
      "Epoch 469/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8409 - val_loss: 35.5852\n",
      "Epoch 470/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8355 - val_loss: 35.6086\n",
      "Epoch 471/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8582 - val_loss: 35.6354\n",
      "Epoch 472/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8507 - val_loss: 35.4793\n",
      "Epoch 473/1000\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 30.8360 - val_loss: 35.7383\n",
      "Epoch 474/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 30.8497 - val_loss: 35.6627\n",
      "Epoch 475/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8467 - val_loss: 35.5535\n",
      "Epoch 476/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8531 - val_loss: 35.5250\n",
      "Epoch 477/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8737 - val_loss: 35.4813\n",
      "Epoch 478/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 30.8923 - val_loss: 35.5943\n",
      "Epoch 479/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 30.9108 - val_loss: 35.4980\n",
      "Epoch 480/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 30.8609 - val_loss: 35.5079\n",
      "Epoch 481/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8610 - val_loss: 35.5873\n",
      "Epoch 482/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8407 - val_loss: 35.6428\n",
      "Epoch 483/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8909 - val_loss: 35.5642\n",
      "Epoch 484/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8731 - val_loss: 35.5669\n",
      "Epoch 485/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8854 - val_loss: 35.5010\n",
      "Epoch 486/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 30.8621 - val_loss: 35.4996\n",
      "Epoch 487/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8730 - val_loss: 35.4498\n",
      "Epoch 488/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8545 - val_loss: 35.4778\n",
      "Epoch 489/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8401 - val_loss: 35.4612\n",
      "Epoch 490/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 30.8789 - val_loss: 35.4909\n",
      "Epoch 491/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 30.9000 - val_loss: 35.5409\n",
      "Epoch 492/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 30.8640 - val_loss: 35.5872\n",
      "Epoch 493/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.9030 - val_loss: 35.6260\n",
      "Epoch 494/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8763 - val_loss: 35.6049\n",
      "Epoch 495/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8603 - val_loss: 35.5052\n",
      "Epoch 496/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8671 - val_loss: 35.4359\n",
      "Epoch 497/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8867 - val_loss: 35.5035\n",
      "Epoch 498/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8899 - val_loss: 35.4880\n",
      "Epoch 499/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8549 - val_loss: 35.5563\n",
      "Epoch 500/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8570 - val_loss: 35.4847\n",
      "Epoch 501/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8620 - val_loss: 35.5164\n",
      "Epoch 502/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8768 - val_loss: 35.6341\n",
      "Epoch 503/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 30.8684 - val_loss: 35.6154\n",
      "Epoch 504/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 30.8841 - val_loss: 35.5562\n",
      "Epoch 505/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8676 - val_loss: 35.6213\n",
      "Epoch 506/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8529 - val_loss: 35.5738\n",
      "Epoch 507/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 30.8456 - val_loss: 35.5328\n",
      "Epoch 508/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8496 - val_loss: 35.4810\n",
      "Epoch 509/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8886 - val_loss: 35.4792\n",
      "Epoch 510/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8759 - val_loss: 35.5757\n",
      "Epoch 511/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8869 - val_loss: 35.4790\n",
      "Epoch 512/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8763 - val_loss: 35.6131\n",
      "Epoch 513/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8612 - val_loss: 35.7281\n",
      "Epoch 514/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8497 - val_loss: 35.6403\n",
      "Epoch 515/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9033 - val_loss: 35.7804\n",
      "Epoch 516/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8489 - val_loss: 35.5817\n",
      "Epoch 517/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8574 - val_loss: 35.5445\n",
      "Epoch 518/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9276 - val_loss: 35.4544\n",
      "Epoch 519/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8623 - val_loss: 35.4847\n",
      "Epoch 520/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8791 - val_loss: 35.4702\n",
      "Epoch 521/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8739 - val_loss: 35.6060\n",
      "Epoch 522/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.9095 - val_loss: 35.6969\n",
      "Epoch 523/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8621 - val_loss: 35.6157\n",
      "Epoch 524/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8551 - val_loss: 35.5651\n",
      "Epoch 525/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8838 - val_loss: 35.5536\n",
      "Epoch 526/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8793 - val_loss: 35.5514\n",
      "Epoch 527/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8734 - val_loss: 35.5528\n",
      "Epoch 528/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8455 - val_loss: 35.5962\n",
      "Epoch 529/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8594 - val_loss: 35.5219\n",
      "Epoch 530/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8614 - val_loss: 35.4999\n",
      "Epoch 531/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8890 - val_loss: 35.4927\n",
      "Epoch 532/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8775 - val_loss: 35.5251\n",
      "Epoch 533/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 30.8777 - val_loss: 35.4771\n",
      "Epoch 534/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8765 - val_loss: 35.4756\n",
      "Epoch 535/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8533 - val_loss: 35.5858\n",
      "Epoch 536/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8839 - val_loss: 35.5859\n",
      "Epoch 537/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8873 - val_loss: 35.5880\n",
      "Epoch 538/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8662 - val_loss: 35.4701\n",
      "Epoch 539/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8980 - val_loss: 35.5448\n",
      "Epoch 540/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8727 - val_loss: 35.6404\n",
      "Epoch 541/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8888 - val_loss: 35.6707\n",
      "Epoch 542/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8598 - val_loss: 35.5969\n",
      "Epoch 543/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8804 - val_loss: 35.6097\n",
      "Epoch 544/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8988 - val_loss: 35.5126\n",
      "Epoch 545/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8730 - val_loss: 35.5218\n",
      "Epoch 546/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8636 - val_loss: 35.6107\n",
      "Epoch 547/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8724 - val_loss: 35.5900\n",
      "Epoch 548/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8650 - val_loss: 35.6322\n",
      "Epoch 549/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8686 - val_loss: 35.6403\n",
      "Epoch 550/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8562 - val_loss: 35.5375\n",
      "Epoch 551/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8614 - val_loss: 35.5640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 552/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8601 - val_loss: 35.5780\n",
      "Epoch 553/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8430 - val_loss: 35.7768\n",
      "Epoch 554/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9092 - val_loss: 35.6307\n",
      "Epoch 555/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8544 - val_loss: 35.6067\n",
      "Epoch 556/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8611 - val_loss: 35.5512\n",
      "Epoch 557/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8740 - val_loss: 35.5886\n",
      "Epoch 558/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8670 - val_loss: 35.5894\n",
      "Epoch 559/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8985 - val_loss: 35.4746\n",
      "Epoch 560/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8566 - val_loss: 35.5491\n",
      "Epoch 561/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8634 - val_loss: 35.6534\n",
      "Epoch 562/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8820 - val_loss: 35.5781\n",
      "Epoch 563/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8883 - val_loss: 35.6421\n",
      "Epoch 564/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8550 - val_loss: 35.6096\n",
      "Epoch 565/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8850 - val_loss: 35.6284\n",
      "Epoch 566/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8864 - val_loss: 35.5815\n",
      "Epoch 567/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8814 - val_loss: 35.5873\n",
      "Epoch 568/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8387 - val_loss: 35.5474\n",
      "Epoch 569/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9022 - val_loss: 35.6630\n",
      "Epoch 570/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8448 - val_loss: 35.6062\n",
      "Epoch 571/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9241 - val_loss: 35.5443\n",
      "Epoch 572/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8736 - val_loss: 35.7479\n",
      "Epoch 573/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8857 - val_loss: 35.6514\n",
      "Epoch 574/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8456 - val_loss: 35.6315\n",
      "Epoch 575/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8696 - val_loss: 35.5937\n",
      "Epoch 576/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8968 - val_loss: 35.6065\n",
      "Epoch 577/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8673 - val_loss: 35.6173\n",
      "Epoch 578/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8686 - val_loss: 35.6112\n",
      "Epoch 579/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8807 - val_loss: 35.6597\n",
      "Epoch 580/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8702 - val_loss: 35.7135\n",
      "Epoch 581/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8625 - val_loss: 35.6707\n",
      "Epoch 582/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8899 - val_loss: 35.5823\n",
      "Epoch 583/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8575 - val_loss: 35.6113\n",
      "Epoch 584/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8449 - val_loss: 35.6188\n",
      "Epoch 585/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8538 - val_loss: 35.4836\n",
      "Epoch 586/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8466 - val_loss: 35.5914\n",
      "Epoch 587/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8744 - val_loss: 35.5651\n",
      "Epoch 588/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8866 - val_loss: 35.5627\n",
      "Epoch 589/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8581 - val_loss: 35.6156\n",
      "Epoch 590/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8497 - val_loss: 35.7915\n",
      "Epoch 591/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8756 - val_loss: 35.6068\n",
      "Epoch 592/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8580 - val_loss: 35.5815\n",
      "Epoch 593/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8518 - val_loss: 35.6508\n",
      "Epoch 594/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8655 - val_loss: 35.6330\n",
      "Epoch 595/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8797 - val_loss: 35.6598\n",
      "Epoch 596/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8840 - val_loss: 35.7902\n",
      "Epoch 597/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8846 - val_loss: 35.6568\n",
      "Epoch 598/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8861 - val_loss: 35.6325\n",
      "Epoch 599/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8529 - val_loss: 35.5615\n",
      "Epoch 600/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8516 - val_loss: 35.7169\n",
      "Epoch 601/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8867 - val_loss: 35.6163\n",
      "Epoch 602/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8552 - val_loss: 35.7031\n",
      "Epoch 603/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9027 - val_loss: 35.6925\n",
      "Epoch 604/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8706 - val_loss: 35.6481\n",
      "Epoch 605/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8753 - val_loss: 35.7348\n",
      "Epoch 606/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9070 - val_loss: 35.7365\n",
      "Epoch 607/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8551 - val_loss: 35.6010\n",
      "Epoch 608/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8773 - val_loss: 35.6068\n",
      "Epoch 609/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8478 - val_loss: 35.7385\n",
      "Epoch 610/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8710 - val_loss: 35.6461\n",
      "Epoch 611/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8778 - val_loss: 35.7421\n",
      "Epoch 612/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9265 - val_loss: 35.6590\n",
      "Epoch 613/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8569 - val_loss: 35.5546\n",
      "Epoch 614/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8612 - val_loss: 35.5961\n",
      "Epoch 615/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8423 - val_loss: 35.5833\n",
      "Epoch 616/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8449 - val_loss: 35.5122\n",
      "Epoch 617/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8967 - val_loss: 35.6791\n",
      "Epoch 618/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8853 - val_loss: 35.6137\n",
      "Epoch 619/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8751 - val_loss: 35.7245\n",
      "Epoch 620/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8599 - val_loss: 35.6209\n",
      "Epoch 621/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8670 - val_loss: 35.5286\n",
      "Epoch 622/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8523 - val_loss: 35.5657\n",
      "Epoch 623/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9020 - val_loss: 35.5103\n",
      "Epoch 624/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8600 - val_loss: 35.4968\n",
      "Epoch 625/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8692 - val_loss: 35.6409\n",
      "Epoch 626/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8795 - val_loss: 35.5699\n",
      "Epoch 627/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8591 - val_loss: 35.5120\n",
      "Epoch 628/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8570 - val_loss: 35.6519\n",
      "Epoch 629/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8701 - val_loss: 35.4921\n",
      "Epoch 630/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8600 - val_loss: 35.4464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 631/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8941 - val_loss: 35.5044\n",
      "Epoch 632/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8569 - val_loss: 35.5466\n",
      "Epoch 633/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8838 - val_loss: 35.7231\n",
      "Epoch 634/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9026 - val_loss: 35.8089\n",
      "Epoch 635/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8608 - val_loss: 35.7164\n",
      "Epoch 636/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8614 - val_loss: 35.7182\n",
      "Epoch 637/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8687 - val_loss: 35.5937\n",
      "Epoch 638/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8510 - val_loss: 35.7007\n",
      "Epoch 639/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8905 - val_loss: 35.5314\n",
      "Epoch 640/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8714 - val_loss: 35.5412\n",
      "Epoch 641/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9118 - val_loss: 35.6251\n",
      "Epoch 642/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8668 - val_loss: 35.5929\n",
      "Epoch 643/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8500 - val_loss: 35.5763\n",
      "Epoch 644/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8603 - val_loss: 35.6086\n",
      "Epoch 645/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8799 - val_loss: 35.5451\n",
      "Epoch 646/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8863 - val_loss: 35.4737\n",
      "Epoch 647/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8750 - val_loss: 35.4431\n",
      "Epoch 648/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8728 - val_loss: 35.5989\n",
      "Epoch 649/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8668 - val_loss: 35.5223\n",
      "Epoch 650/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8669 - val_loss: 35.5070\n",
      "Epoch 651/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8672 - val_loss: 35.5073\n",
      "Epoch 652/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8451 - val_loss: 35.6539\n",
      "Epoch 653/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9908 - val_loss: 35.6493\n",
      "Epoch 654/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8467 - val_loss: 35.5481\n",
      "Epoch 655/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8762 - val_loss: 35.5227\n",
      "Epoch 656/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8868 - val_loss: 35.5364\n",
      "Epoch 657/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8558 - val_loss: 35.5421\n",
      "Epoch 658/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8673 - val_loss: 35.4657\n",
      "Epoch 659/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8860 - val_loss: 35.5032\n",
      "Epoch 660/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8591 - val_loss: 35.5513\n",
      "Epoch 661/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8886 - val_loss: 35.6034\n",
      "Epoch 662/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8641 - val_loss: 35.5256\n",
      "Epoch 663/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8648 - val_loss: 35.5696\n",
      "Epoch 664/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8565 - val_loss: 35.6103\n",
      "Epoch 665/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8446 - val_loss: 35.5100\n",
      "Epoch 666/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8524 - val_loss: 35.4843\n",
      "Epoch 667/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8657 - val_loss: 35.4650\n",
      "Epoch 668/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8803 - val_loss: 35.5451\n",
      "Epoch 669/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8851 - val_loss: 35.5144\n",
      "Epoch 670/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8440 - val_loss: 35.6071\n",
      "Epoch 671/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8502 - val_loss: 35.6161\n",
      "Epoch 672/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8705 - val_loss: 35.6535\n",
      "Epoch 673/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8817 - val_loss: 35.5247\n",
      "Epoch 674/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8406 - val_loss: 35.5103\n",
      "Epoch 675/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8420 - val_loss: 35.5416\n",
      "Epoch 676/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8520 - val_loss: 35.4986\n",
      "Epoch 677/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8470 - val_loss: 35.4932\n",
      "Epoch 678/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8694 - val_loss: 35.6482\n",
      "Epoch 679/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 30.8675 - val_loss: 35.6217\n",
      "Epoch 680/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8673 - val_loss: 35.5192\n",
      "Epoch 681/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8645 - val_loss: 35.5862\n",
      "Epoch 682/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8807 - val_loss: 35.6092\n",
      "Epoch 683/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8832 - val_loss: 35.6621\n",
      "Epoch 684/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8810 - val_loss: 35.6555\n",
      "Epoch 685/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9043 - val_loss: 35.6523\n",
      "Epoch 686/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8405 - val_loss: 35.6161\n",
      "Epoch 687/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8623 - val_loss: 35.7336\n",
      "Epoch 688/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8565 - val_loss: 35.7200\n",
      "Epoch 689/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8798 - val_loss: 35.6990\n",
      "Epoch 690/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9021 - val_loss: 35.6009\n",
      "Epoch 691/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8605 - val_loss: 35.6448\n",
      "Epoch 692/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8887 - val_loss: 35.5469\n",
      "Epoch 693/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8774 - val_loss: 35.5431\n",
      "Epoch 694/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8553 - val_loss: 35.4941\n",
      "Epoch 695/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8967 - val_loss: 35.6065\n",
      "Epoch 696/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8774 - val_loss: 35.4824\n",
      "Epoch 697/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8374 - val_loss: 35.5826\n",
      "Epoch 698/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8575 - val_loss: 35.6072\n",
      "Epoch 699/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8433 - val_loss: 35.5355\n",
      "Epoch 700/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8647 - val_loss: 35.5062\n",
      "Epoch 701/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8928 - val_loss: 35.5651\n",
      "Epoch 702/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8559 - val_loss: 35.6768\n",
      "Epoch 703/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8669 - val_loss: 35.6568\n",
      "Epoch 704/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8839 - val_loss: 35.6630\n",
      "Epoch 705/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8605 - val_loss: 35.5906\n",
      "Epoch 706/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8582 - val_loss: 35.6156\n",
      "Epoch 707/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8591 - val_loss: 35.6596\n",
      "Epoch 708/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8878 - val_loss: 35.6511\n",
      "Epoch 709/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8456 - val_loss: 35.6029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 710/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8680 - val_loss: 35.5985\n",
      "Epoch 711/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8616 - val_loss: 35.5598\n",
      "Epoch 712/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8405 - val_loss: 35.5246\n",
      "Epoch 713/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8885 - val_loss: 35.4741\n",
      "Epoch 714/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8708 - val_loss: 35.5285\n",
      "Epoch 715/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8887 - val_loss: 35.4948\n",
      "Epoch 716/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8732 - val_loss: 35.6099\n",
      "Epoch 717/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8576 - val_loss: 35.5293\n",
      "Epoch 718/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.9023 - val_loss: 35.4941\n",
      "Epoch 719/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.9082 - val_loss: 35.4319\n",
      "Epoch 720/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8819 - val_loss: 35.5772\n",
      "Epoch 721/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8811 - val_loss: 35.6547\n",
      "Epoch 722/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8513 - val_loss: 35.7040\n",
      "Epoch 723/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8489 - val_loss: 35.6076\n",
      "Epoch 724/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8845 - val_loss: 35.6021\n",
      "Epoch 725/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8488 - val_loss: 35.5997\n",
      "Epoch 726/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8601 - val_loss: 35.5043\n",
      "Epoch 727/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8418 - val_loss: 35.5483\n",
      "Epoch 728/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8501 - val_loss: 35.5593\n",
      "Epoch 729/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8384 - val_loss: 35.5368\n",
      "Epoch 730/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8682 - val_loss: 35.5868\n",
      "Epoch 731/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8773 - val_loss: 35.5180\n",
      "Epoch 732/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8510 - val_loss: 35.4798\n",
      "Epoch 733/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8614 - val_loss: 35.5610\n",
      "Epoch 734/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8872 - val_loss: 35.5405\n",
      "Epoch 735/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8693 - val_loss: 35.4815\n",
      "Epoch 736/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8543 - val_loss: 35.5987\n",
      "Epoch 737/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8567 - val_loss: 35.6168\n",
      "Epoch 738/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8872 - val_loss: 35.6616\n",
      "Epoch 739/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8442 - val_loss: 35.7471\n",
      "Epoch 740/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8607 - val_loss: 35.5987\n",
      "Epoch 741/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8493 - val_loss: 35.5929\n",
      "Epoch 742/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8408 - val_loss: 35.7476\n",
      "Epoch 743/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8884 - val_loss: 35.6432\n",
      "Epoch 744/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8437 - val_loss: 35.6730\n",
      "Epoch 745/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8815 - val_loss: 35.6098\n",
      "Epoch 746/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8566 - val_loss: 35.5849\n",
      "Epoch 747/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8570 - val_loss: 35.5639\n",
      "Epoch 748/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8803 - val_loss: 35.4923\n",
      "Epoch 749/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8746 - val_loss: 35.5463\n",
      "Epoch 750/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8681 - val_loss: 35.5080\n",
      "Epoch 751/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8520 - val_loss: 35.5442\n",
      "Epoch 752/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8485 - val_loss: 35.4935\n",
      "Epoch 753/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9033 - val_loss: 35.5943\n",
      "Epoch 754/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8726 - val_loss: 35.5945\n",
      "Epoch 755/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8672 - val_loss: 35.6426\n",
      "Epoch 756/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8556 - val_loss: 35.5718\n",
      "Epoch 757/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8763 - val_loss: 35.6092\n",
      "Epoch 758/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8762 - val_loss: 35.5227\n",
      "Epoch 759/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8809 - val_loss: 35.5034\n",
      "Epoch 760/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8990 - val_loss: 35.5787\n",
      "Epoch 761/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8621 - val_loss: 35.6426\n",
      "Epoch 762/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8715 - val_loss: 35.5955\n",
      "Epoch 763/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8940 - val_loss: 35.4744\n",
      "Epoch 764/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8745 - val_loss: 35.5446\n",
      "Epoch 765/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8508 - val_loss: 35.5329\n",
      "Epoch 766/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8807 - val_loss: 35.5514\n",
      "Epoch 767/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8497 - val_loss: 35.5262\n",
      "Epoch 768/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8774 - val_loss: 35.5593\n",
      "Epoch 769/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8479 - val_loss: 35.5177\n",
      "Epoch 770/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8799 - val_loss: 35.5842\n",
      "Epoch 771/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8643 - val_loss: 35.5850\n",
      "Epoch 772/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8565 - val_loss: 35.6716\n",
      "Epoch 773/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8590 - val_loss: 35.6390\n",
      "Epoch 774/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8720 - val_loss: 35.6022\n",
      "Epoch 775/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8706 - val_loss: 35.5910\n",
      "Epoch 776/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8603 - val_loss: 35.6423\n",
      "Epoch 777/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8742 - val_loss: 35.5967\n",
      "Epoch 778/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8688 - val_loss: 35.5979\n",
      "Epoch 779/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8582 - val_loss: 35.6976\n",
      "Epoch 780/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8854 - val_loss: 35.6288\n",
      "Epoch 781/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8923 - val_loss: 35.7446\n",
      "Epoch 782/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8920 - val_loss: 35.6156\n",
      "Epoch 783/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8745 - val_loss: 35.5968\n",
      "Epoch 784/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8705 - val_loss: 35.6660\n",
      "Epoch 785/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8699 - val_loss: 35.5713\n",
      "Epoch 786/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8623 - val_loss: 35.5273\n",
      "Epoch 787/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8464 - val_loss: 35.5731\n",
      "Epoch 788/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8524 - val_loss: 35.6337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 789/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8896 - val_loss: 35.5909\n",
      "Epoch 790/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8546 - val_loss: 35.5278\n",
      "Epoch 791/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8579 - val_loss: 35.5770\n",
      "Epoch 792/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8716 - val_loss: 35.4964\n",
      "Epoch 793/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8483 - val_loss: 35.5234\n",
      "Epoch 794/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8712 - val_loss: 35.5128\n",
      "Epoch 795/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8874 - val_loss: 35.6443\n",
      "Epoch 796/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8665 - val_loss: 35.5265\n",
      "Epoch 797/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8500 - val_loss: 35.6704\n",
      "Epoch 798/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8763 - val_loss: 35.7236\n",
      "Epoch 799/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8691 - val_loss: 35.6567\n",
      "Epoch 800/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8640 - val_loss: 35.5395\n",
      "Epoch 801/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8675 - val_loss: 35.7003\n",
      "Epoch 802/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9126 - val_loss: 35.6586\n",
      "Epoch 803/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8889 - val_loss: 35.5294\n",
      "Epoch 804/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8542 - val_loss: 35.6054\n",
      "Epoch 805/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8993 - val_loss: 35.6834\n",
      "Epoch 806/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8806 - val_loss: 35.6470\n",
      "Epoch 807/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8493 - val_loss: 35.6374\n",
      "Epoch 808/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8506 - val_loss: 35.7020\n",
      "Epoch 809/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8733 - val_loss: 35.6767\n",
      "Epoch 810/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8554 - val_loss: 35.6249\n",
      "Epoch 811/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8577 - val_loss: 35.4861\n",
      "Epoch 812/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8935 - val_loss: 35.5846\n",
      "Epoch 813/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8637 - val_loss: 35.5995\n",
      "Epoch 814/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8924 - val_loss: 35.6571\n",
      "Epoch 815/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8606 - val_loss: 35.6678\n",
      "Epoch 816/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8611 - val_loss: 35.5094\n",
      "Epoch 817/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8967 - val_loss: 35.5941\n",
      "Epoch 818/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.9120 - val_loss: 35.5596\n",
      "Epoch 819/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8999 - val_loss: 35.6486\n",
      "Epoch 820/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 30.8619 - val_loss: 35.5246\n",
      "Epoch 821/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8393 - val_loss: 35.4516\n",
      "Epoch 822/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8720 - val_loss: 35.5802\n",
      "Epoch 823/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8757 - val_loss: 35.5260\n",
      "Epoch 824/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8813 - val_loss: 35.6514\n",
      "Epoch 825/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8785 - val_loss: 35.6458\n",
      "Epoch 826/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.9057 - val_loss: 35.4799\n",
      "Epoch 827/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8723 - val_loss: 35.4913\n",
      "Epoch 828/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8508 - val_loss: 35.4487\n",
      "Epoch 829/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8823 - val_loss: 35.4959\n",
      "Epoch 830/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8523 - val_loss: 35.5631\n",
      "Epoch 831/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8460 - val_loss: 35.7035\n",
      "Epoch 832/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8717 - val_loss: 35.6698\n",
      "Epoch 833/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8819 - val_loss: 35.6059\n",
      "Epoch 834/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8559 - val_loss: 35.5564\n",
      "Epoch 835/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8716 - val_loss: 35.6009\n",
      "Epoch 836/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8607 - val_loss: 35.6300\n",
      "Epoch 837/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8572 - val_loss: 35.6447\n",
      "Epoch 838/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8893 - val_loss: 35.5722\n",
      "Epoch 839/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8427 - val_loss: 35.5709\n",
      "Epoch 840/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8464 - val_loss: 35.5385\n",
      "Epoch 841/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8546 - val_loss: 35.6410\n",
      "Epoch 842/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8514 - val_loss: 35.5364\n",
      "Epoch 843/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8571 - val_loss: 35.6129\n",
      "Epoch 844/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8704 - val_loss: 35.5384\n",
      "Epoch 845/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8598 - val_loss: 35.5810\n",
      "Epoch 846/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8669 - val_loss: 35.5926\n",
      "Epoch 847/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8521 - val_loss: 35.5923\n",
      "Epoch 848/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8735 - val_loss: 35.6214\n",
      "Epoch 849/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8772 - val_loss: 35.5309\n",
      "Epoch 850/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8735 - val_loss: 35.4833\n",
      "Epoch 851/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8580 - val_loss: 35.5947\n",
      "Epoch 852/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8445 - val_loss: 35.5569\n",
      "Epoch 853/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.9004 - val_loss: 35.6673\n",
      "Epoch 854/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8780 - val_loss: 35.5992\n",
      "Epoch 855/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8610 - val_loss: 35.5648\n",
      "Epoch 856/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8900 - val_loss: 35.6331\n",
      "Epoch 857/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8545 - val_loss: 35.5644\n",
      "Epoch 858/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8895 - val_loss: 35.5944\n",
      "Epoch 859/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8608 - val_loss: 35.6199\n",
      "Epoch 860/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8555 - val_loss: 35.6274\n",
      "Epoch 861/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8537 - val_loss: 35.6656\n",
      "Epoch 862/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8629 - val_loss: 35.5848\n",
      "Epoch 863/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 30.8813 - val_loss: 35.5862\n",
      "Epoch 864/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8743 - val_loss: 35.5266\n",
      "Epoch 865/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9002 - val_loss: 35.7133\n",
      "Epoch 866/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8706 - val_loss: 35.5645\n",
      "Epoch 867/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9131 - val_loss: 35.5749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 868/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8898 - val_loss: 35.5241\n",
      "Epoch 869/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8862 - val_loss: 35.5432\n",
      "Epoch 870/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8427 - val_loss: 35.5804\n",
      "Epoch 871/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8500 - val_loss: 35.6093\n",
      "Epoch 872/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 30.8794 - val_loss: 35.6082\n",
      "Epoch 873/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8620 - val_loss: 35.5350\n",
      "Epoch 874/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8794 - val_loss: 35.5336\n",
      "Epoch 875/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9158 - val_loss: 35.5653\n",
      "Epoch 876/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8658 - val_loss: 35.5948\n",
      "Epoch 877/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8511 - val_loss: 35.7638\n",
      "Epoch 878/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8535 - val_loss: 35.8351\n",
      "Epoch 879/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8669 - val_loss: 35.6756\n",
      "Epoch 880/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9319 - val_loss: 35.5650\n",
      "Epoch 881/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8650 - val_loss: 35.5501\n",
      "Epoch 882/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8793 - val_loss: 35.5399\n",
      "Epoch 883/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8509 - val_loss: 35.5721\n",
      "Epoch 884/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8758 - val_loss: 35.6943\n",
      "Epoch 885/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8992 - val_loss: 35.7421\n",
      "Epoch 886/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8695 - val_loss: 35.7066\n",
      "Epoch 887/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8815 - val_loss: 35.7941\n",
      "Epoch 888/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8662 - val_loss: 35.6633\n",
      "Epoch 889/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8555 - val_loss: 35.6055\n",
      "Epoch 890/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8866 - val_loss: 35.6227\n",
      "Epoch 891/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8586 - val_loss: 35.7029\n",
      "Epoch 892/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8707 - val_loss: 35.6327\n",
      "Epoch 893/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8918 - val_loss: 35.6471\n",
      "Epoch 894/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8483 - val_loss: 35.5258\n",
      "Epoch 895/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8597 - val_loss: 35.5687\n",
      "Epoch 896/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8739 - val_loss: 35.5524\n",
      "Epoch 897/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8555 - val_loss: 35.5952\n",
      "Epoch 898/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8648 - val_loss: 35.5439\n",
      "Epoch 899/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8860 - val_loss: 35.6147\n",
      "Epoch 900/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8749 - val_loss: 35.6179\n",
      "Epoch 901/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8681 - val_loss: 35.6845\n",
      "Epoch 902/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8537 - val_loss: 35.5992\n",
      "Epoch 903/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8435 - val_loss: 35.5695\n",
      "Epoch 904/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8518 - val_loss: 35.5595\n",
      "Epoch 905/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8583 - val_loss: 35.6124\n",
      "Epoch 906/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8859 - val_loss: 35.6321\n",
      "Epoch 907/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8711 - val_loss: 35.6114\n",
      "Epoch 908/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8493 - val_loss: 35.5868\n",
      "Epoch 909/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8479 - val_loss: 35.5882\n",
      "Epoch 910/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8815 - val_loss: 35.5230\n",
      "Epoch 911/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8632 - val_loss: 35.6055\n",
      "Epoch 912/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8815 - val_loss: 35.5784\n",
      "Epoch 913/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8724 - val_loss: 35.5901\n",
      "Epoch 914/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8661 - val_loss: 35.5180\n",
      "Epoch 915/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8829 - val_loss: 35.4709\n",
      "Epoch 916/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8951 - val_loss: 35.4895\n",
      "Epoch 917/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8913 - val_loss: 35.5179\n",
      "Epoch 918/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8681 - val_loss: 35.5807\n",
      "Epoch 919/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9082 - val_loss: 35.6287\n",
      "Epoch 920/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8791 - val_loss: 35.5805\n",
      "Epoch 921/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8714 - val_loss: 35.6006\n",
      "Epoch 922/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8692 - val_loss: 35.5067\n",
      "Epoch 923/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8441 - val_loss: 35.5119\n",
      "Epoch 924/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8384 - val_loss: 35.6172\n",
      "Epoch 925/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8688 - val_loss: 35.5560\n",
      "Epoch 926/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8606 - val_loss: 35.5352\n",
      "Epoch 927/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8841 - val_loss: 35.5819\n",
      "Epoch 928/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8966 - val_loss: 35.7686\n",
      "Epoch 929/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9355 - val_loss: 35.6575\n",
      "Epoch 930/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8764 - val_loss: 35.5585\n",
      "Epoch 931/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8696 - val_loss: 35.7404\n",
      "Epoch 932/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8650 - val_loss: 35.6874\n",
      "Epoch 933/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8590 - val_loss: 35.6320\n",
      "Epoch 934/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8736 - val_loss: 35.5711\n",
      "Epoch 935/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8882 - val_loss: 35.5885\n",
      "Epoch 936/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9176 - val_loss: 35.7294\n",
      "Epoch 937/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8642 - val_loss: 35.6547\n",
      "Epoch 938/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8708 - val_loss: 35.6441\n",
      "Epoch 939/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8478 - val_loss: 35.5518\n",
      "Epoch 940/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8658 - val_loss: 35.5615\n",
      "Epoch 941/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8560 - val_loss: 35.6107\n",
      "Epoch 942/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8736 - val_loss: 35.7279\n",
      "Epoch 943/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9179 - val_loss: 35.5756\n",
      "Epoch 944/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8654 - val_loss: 35.5530\n",
      "Epoch 945/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8781 - val_loss: 35.6321\n",
      "Epoch 946/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8724 - val_loss: 35.5913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 947/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9450 - val_loss: 35.5770\n",
      "Epoch 948/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8601 - val_loss: 35.6581\n",
      "Epoch 949/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8635 - val_loss: 35.6832\n",
      "Epoch 950/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8889 - val_loss: 35.7555\n",
      "Epoch 951/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8686 - val_loss: 35.5988\n",
      "Epoch 952/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8589 - val_loss: 35.5829\n",
      "Epoch 953/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8489 - val_loss: 35.6916\n",
      "Epoch 954/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8964 - val_loss: 35.6285\n",
      "Epoch 955/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8970 - val_loss: 35.6889\n",
      "Epoch 956/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8430 - val_loss: 35.6076\n",
      "Epoch 957/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8540 - val_loss: 35.6575\n",
      "Epoch 958/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9228 - val_loss: 35.7065\n",
      "Epoch 959/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8521 - val_loss: 35.7206\n",
      "Epoch 960/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8718 - val_loss: 35.6202\n",
      "Epoch 961/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8503 - val_loss: 35.5660\n",
      "Epoch 962/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8739 - val_loss: 35.5033\n",
      "Epoch 963/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8607 - val_loss: 35.4833\n",
      "Epoch 964/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8992 - val_loss: 35.5574\n",
      "Epoch 965/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8582 - val_loss: 35.4888\n",
      "Epoch 966/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8565 - val_loss: 35.5373\n",
      "Epoch 967/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8791 - val_loss: 35.4216\n",
      "Epoch 968/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8543 - val_loss: 35.4644\n",
      "Epoch 969/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8829 - val_loss: 35.6914\n",
      "Epoch 970/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8434 - val_loss: 35.5155\n",
      "Epoch 971/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8411 - val_loss: 35.5432\n",
      "Epoch 972/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8577 - val_loss: 35.5549\n",
      "Epoch 973/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8632 - val_loss: 35.6172\n",
      "Epoch 974/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8744 - val_loss: 35.5310\n",
      "Epoch 975/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8908 - val_loss: 35.6096\n",
      "Epoch 976/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9151 - val_loss: 35.6362\n",
      "Epoch 977/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8695 - val_loss: 35.5243\n",
      "Epoch 978/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8554 - val_loss: 35.5792\n",
      "Epoch 979/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8696 - val_loss: 35.4999\n",
      "Epoch 980/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8601 - val_loss: 35.5325\n",
      "Epoch 981/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8749 - val_loss: 35.5868\n",
      "Epoch 982/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8632 - val_loss: 35.6337\n",
      "Epoch 983/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8619 - val_loss: 35.5377\n",
      "Epoch 984/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8812 - val_loss: 35.4729\n",
      "Epoch 985/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8576 - val_loss: 35.5138\n",
      "Epoch 986/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.9154 - val_loss: 35.5688\n",
      "Epoch 987/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8464 - val_loss: 35.6923\n",
      "Epoch 988/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8808 - val_loss: 35.5812\n",
      "Epoch 989/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8791 - val_loss: 35.4475\n",
      "Epoch 990/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9058 - val_loss: 35.4424\n",
      "Epoch 991/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8487 - val_loss: 35.6301\n",
      "Epoch 992/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8457 - val_loss: 35.7152\n",
      "Epoch 993/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8802 - val_loss: 35.6303\n",
      "Epoch 994/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8684 - val_loss: 35.5882\n",
      "Epoch 995/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8732 - val_loss: 35.5652\n",
      "Epoch 996/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8778 - val_loss: 35.6530\n",
      "Epoch 997/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8786 - val_loss: 35.6929\n",
      "Epoch 998/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9123 - val_loss: 35.6880\n",
      "Epoch 999/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8424 - val_loss: 35.6127\n",
      "Epoch 1000/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8474 - val_loss: 35.5182\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(32,activation='relu',input_shape=(x_train.shape[1],)))\n",
    "model1.add(Dense(16,activation='relu'))\n",
    "model1.add(Dense(1))\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "model1.compile(optimizer=opt,loss='MAPE')\n",
    "history1 = model1.fit(x=x_train,y=y_train,epochs=1000,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82cfebe",
   "metadata": {},
   "source": [
    "### MODEL 2 - Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "785f83f0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 [==============================] - 1s 13ms/step - loss: 99.5559 - val_loss: 95.2041\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 91.8190 - val_loss: 86.2072\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 82.2448 - val_loss: 75.0067\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 70.3085 - val_loss: 63.6074\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 57.2590 - val_loss: 55.3847\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 48.2394 - val_loss: 50.6813\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 42.9846 - val_loss: 47.2100\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 40.0991 - val_loss: 45.2596\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 38.3169 - val_loss: 43.7570\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 36.7577 - val_loss: 42.4340\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 35.3923 - val_loss: 41.2075\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 34.2631 - val_loss: 40.0688\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 33.1654 - val_loss: 38.8756\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 32.2216 - val_loss: 37.7522\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 31.2965 - val_loss: 36.7284\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.4219 - val_loss: 35.7842\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 29.5800 - val_loss: 34.9210\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 28.9251 - val_loss: 34.1877\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 28.4433 - val_loss: 33.7503\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 28.0894 - val_loss: 33.2419\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 27.7754 - val_loss: 32.7740\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 27.5166 - val_loss: 32.3858\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 27.2573 - val_loss: 32.0107\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 26.9743 - val_loss: 31.6707\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 26.7922 - val_loss: 31.3932\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 26.6355 - val_loss: 31.1597\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 26.4624 - val_loss: 30.8905\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 26.3036 - val_loss: 30.8356\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 26.1154 - val_loss: 30.5270\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 25.9733 - val_loss: 30.3476\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 25.8339 - val_loss: 30.2485\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 25.7130 - val_loss: 30.0589\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 25.5743 - val_loss: 29.9156\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 25.4520 - val_loss: 29.8468\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 25.3095 - val_loss: 29.6502\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 25.1868 - val_loss: 29.5666\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 25.1028 - val_loss: 29.4813\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 24.9149 - val_loss: 29.3768\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 24.7599 - val_loss: 29.2144\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 24.6495 - val_loss: 29.1434\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 24.5740 - val_loss: 29.0065\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 24.4402 - val_loss: 28.8387\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 24.3373 - val_loss: 28.7320\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 24.2677 - val_loss: 28.6377\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 24.1975 - val_loss: 28.5143\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 24.0390 - val_loss: 28.4026\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 23.9296 - val_loss: 28.3112\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 23.8720 - val_loss: 28.1906\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 23.7392 - val_loss: 28.0842\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 23.6822 - val_loss: 28.0028\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 23.6155 - val_loss: 27.9102\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 23.5610 - val_loss: 27.8061\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 23.4562 - val_loss: 27.7713\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 23.3420 - val_loss: 27.6236\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 23.3031 - val_loss: 27.5581\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 23.2284 - val_loss: 27.4753\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 23.0750 - val_loss: 27.3894\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 23.0401 - val_loss: 27.3283\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 22.9195 - val_loss: 27.2441\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 22.8577 - val_loss: 27.1874\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 22.7693 - val_loss: 27.0733\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 22.6977 - val_loss: 27.0185\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 22.6492 - val_loss: 27.0310\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 22.5778 - val_loss: 26.9179\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 22.5250 - val_loss: 26.8342\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 22.4138 - val_loss: 26.7947\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 22.3456 - val_loss: 26.8040\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 22.3802 - val_loss: 26.6192\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 22.2231 - val_loss: 26.5775\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 22.1505 - val_loss: 26.4904\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 22.0506 - val_loss: 26.3733\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 22.0326 - val_loss: 26.3283\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 21.9951 - val_loss: 26.3460\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 21.9984 - val_loss: 26.3484\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.8611 - val_loss: 26.1329\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 21.7803 - val_loss: 26.1748\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 21.7768 - val_loss: 26.0875\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.6589 - val_loss: 26.0304\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.6248 - val_loss: 26.1415\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.5664 - val_loss: 25.9250\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 21.4956 - val_loss: 25.8145\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 21.4228 - val_loss: 25.8017\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 21.3820 - val_loss: 25.8008\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 21.3447 - val_loss: 25.6501\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 21.3263 - val_loss: 25.7360\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 21.2566 - val_loss: 25.5891\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 21.1581 - val_loss: 25.6659\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 21.2343 - val_loss: 25.5382\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.1375 - val_loss: 25.5724\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 21.1559 - val_loss: 25.5702\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 21.0483 - val_loss: 25.5173\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 21.0036 - val_loss: 25.2746\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.9588 - val_loss: 25.5092\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.9547 - val_loss: 25.6247\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 21.0112 - val_loss: 25.3644\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.8950 - val_loss: 25.3068\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.8783 - val_loss: 25.1057\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.8936 - val_loss: 25.1569\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.8282 - val_loss: 25.1821\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.8057 - val_loss: 25.1401\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.7598 - val_loss: 25.0972\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.7294 - val_loss: 25.2362\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.8064 - val_loss: 25.2272\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.8562 - val_loss: 25.2404\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.7598 - val_loss: 25.1553\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.6728 - val_loss: 25.3089\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.6759 - val_loss: 25.3347\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.6485 - val_loss: 25.0330\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.5959 - val_loss: 25.0644\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.5940 - val_loss: 25.0676\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.5740 - val_loss: 25.0639\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.5357 - val_loss: 25.0350\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.5459 - val_loss: 25.0315\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.5236 - val_loss: 25.3474\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.4796 - val_loss: 24.9979\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.7024 - val_loss: 25.0559\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.5474 - val_loss: 25.1366\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.4914 - val_loss: 24.9971\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.5118 - val_loss: 25.0135\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.3386 - val_loss: 25.2709\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.4410 - val_loss: 25.1215\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 20.4354 - val_loss: 24.9111\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 20.4502 - val_loss: 24.9328\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.4606 - val_loss: 24.9162\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 20.3924 - val_loss: 25.0252\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.4413 - val_loss: 24.9554\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.3140 - val_loss: 24.8796\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.3456 - val_loss: 25.0958\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.4045 - val_loss: 24.9319\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.2621 - val_loss: 24.8830\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.3003 - val_loss: 24.9812\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.3925 - val_loss: 24.9134\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.2566 - val_loss: 24.9259\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.3061 - val_loss: 24.8792\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.2561 - val_loss: 25.1539\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.2500 - val_loss: 24.8585\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.2145 - val_loss: 24.8398\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.2555 - val_loss: 24.8673\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.2526 - val_loss: 24.8126\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.2753 - val_loss: 24.7145\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.2007 - val_loss: 24.7156\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.1864 - val_loss: 24.7508\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.0985 - val_loss: 24.9327\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.2088 - val_loss: 24.8024\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.2430 - val_loss: 24.9204\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.1860 - val_loss: 25.0574\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.1324 - val_loss: 24.6755\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.1301 - val_loss: 24.7581\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.1888 - val_loss: 24.7065\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.1531 - val_loss: 24.7311\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.2096 - val_loss: 24.6346\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.1099 - val_loss: 24.7985\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.0438 - val_loss: 24.6806\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.1375 - val_loss: 24.6528\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.1353 - val_loss: 24.6643\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.1042 - val_loss: 24.7543\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.1483 - val_loss: 24.6260\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.0499 - val_loss: 24.6512\n",
      "Epoch 159/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 20.0562 - val_loss: 24.7235\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.0572 - val_loss: 24.7400\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.1147 - val_loss: 24.6927\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.1488 - val_loss: 24.6829\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.0648 - val_loss: 24.7523\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.1678 - val_loss: 24.6222\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.0385 - val_loss: 24.5923\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.0584 - val_loss: 24.6451\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.0774 - val_loss: 24.5883\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.1531 - val_loss: 24.5807\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.0534 - val_loss: 25.0348\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.0746 - val_loss: 24.6365\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.0018 - val_loss: 24.7318\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.0627 - val_loss: 24.5612\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.1027 - val_loss: 24.6169\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.0552 - val_loss: 24.5809\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.9722 - val_loss: 24.5570\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.0496 - val_loss: 24.7036\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.9716 - val_loss: 24.6148\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.0063 - val_loss: 24.5229\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.8637 - val_loss: 24.6775\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.9700 - val_loss: 24.4766\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.0227 - val_loss: 24.5423\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.9335 - val_loss: 24.5652\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.9991 - val_loss: 24.5087\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.9104 - val_loss: 24.5779\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.9784 - val_loss: 24.5783\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.9362 - val_loss: 24.5673\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.9410 - val_loss: 24.5261\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.0705 - val_loss: 24.5007\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.8871 - val_loss: 24.5450\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.9408 - val_loss: 24.5294\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.8961 - val_loss: 24.5814\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.8905 - val_loss: 24.5491\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.9302 - val_loss: 24.6499\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.8893 - val_loss: 24.4842\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.8956 - val_loss: 24.4734\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.8236 - val_loss: 24.6282\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.8579 - val_loss: 24.4537\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.8384 - val_loss: 24.5936\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.8467 - val_loss: 24.4613\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.8507 - val_loss: 24.7955\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.9615 - val_loss: 24.5558\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.8961 - val_loss: 24.4712\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.8224 - val_loss: 24.4894\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.8281 - val_loss: 24.6160\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.8599 - val_loss: 24.4739\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.8761 - val_loss: 24.4682\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.7887 - val_loss: 24.5182\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.7918 - val_loss: 24.5641\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.7994 - val_loss: 24.4576\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.7520 - val_loss: 24.6625\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.7557 - val_loss: 24.4191\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.7395 - val_loss: 24.4153\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.7453 - val_loss: 24.3895\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.7293 - val_loss: 24.5893\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.8396 - val_loss: 24.4685\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.7068 - val_loss: 24.3651\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.7331 - val_loss: 24.3881\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.8054 - val_loss: 24.5173\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.7806 - val_loss: 24.4329\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.7463 - val_loss: 24.6483\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.7434 - val_loss: 24.4152\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.7993 - val_loss: 24.3590\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.7380 - val_loss: 24.5425\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.7306 - val_loss: 24.4753\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.7275 - val_loss: 24.3004\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.7039 - val_loss: 24.3701\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.7714 - val_loss: 24.4737\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.6370 - val_loss: 24.5565\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.7206 - val_loss: 24.3259\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.7330 - val_loss: 24.3706\n",
      "Epoch 231/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.6160 - val_loss: 24.3337\n",
      "Epoch 232/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 19.5969 - val_loss: 24.7342\n",
      "Epoch 233/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.7242 - val_loss: 24.4779\n",
      "Epoch 234/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.6685 - val_loss: 24.3667\n",
      "Epoch 235/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.7086 - val_loss: 24.4156\n",
      "Epoch 236/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.6209 - val_loss: 24.3807\n",
      "Epoch 237/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.6702 - val_loss: 24.6947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.7376 - val_loss: 24.6741\n",
      "Epoch 239/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.6731 - val_loss: 24.3250\n",
      "Epoch 240/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.7182 - val_loss: 24.2961\n",
      "Epoch 241/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.5740 - val_loss: 24.3500\n",
      "Epoch 242/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.6820 - val_loss: 24.4054\n",
      "Epoch 243/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.6501 - val_loss: 24.4375\n",
      "Epoch 244/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.5314 - val_loss: 24.6045\n",
      "Epoch 245/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.6467 - val_loss: 24.3853\n",
      "Epoch 246/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.5867 - val_loss: 24.4360\n",
      "Epoch 247/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.6549 - val_loss: 24.2896\n",
      "Epoch 248/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.6868 - val_loss: 24.3265\n",
      "Epoch 249/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.6451 - val_loss: 24.2785\n",
      "Epoch 250/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.5346 - val_loss: 24.4145\n",
      "Epoch 251/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.6643 - val_loss: 24.2814\n",
      "Epoch 252/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.6237 - val_loss: 24.2873\n",
      "Epoch 253/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.5570 - val_loss: 24.3062\n",
      "Epoch 254/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.5723 - val_loss: 24.1835\n",
      "Epoch 255/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.6441 - val_loss: 24.3513\n",
      "Epoch 256/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.6528 - val_loss: 24.2619\n",
      "Epoch 257/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.5763 - val_loss: 24.3078\n",
      "Epoch 258/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.5376 - val_loss: 24.2253\n",
      "Epoch 259/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 19.4829 - val_loss: 24.4097\n",
      "Epoch 260/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.6880 - val_loss: 24.3032\n",
      "Epoch 261/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.4831 - val_loss: 24.2289\n",
      "Epoch 262/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.5842 - val_loss: 24.3223\n",
      "Epoch 263/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.5195 - val_loss: 24.2014\n",
      "Epoch 264/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.4896 - val_loss: 24.4137\n",
      "Epoch 265/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.5408 - val_loss: 24.2756\n",
      "Epoch 266/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.4702 - val_loss: 24.2933\n",
      "Epoch 267/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.5046 - val_loss: 24.4241\n",
      "Epoch 268/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.5080 - val_loss: 24.2497\n",
      "Epoch 269/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.5344 - val_loss: 24.3739\n",
      "Epoch 270/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.4656 - val_loss: 24.2778\n",
      "Epoch 271/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.4747 - val_loss: 24.3045\n",
      "Epoch 272/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.4943 - val_loss: 24.2597\n",
      "Epoch 273/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.5019 - val_loss: 24.4927\n",
      "Epoch 274/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 19.5789 - val_loss: 24.2897\n",
      "Epoch 275/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.4562 - val_loss: 24.2826\n",
      "Epoch 276/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.4507 - val_loss: 24.2736\n",
      "Epoch 277/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.4500 - val_loss: 24.2301\n",
      "Epoch 278/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.4077 - val_loss: 24.2026\n",
      "Epoch 279/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.5527 - val_loss: 24.1797\n",
      "Epoch 280/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.4706 - val_loss: 24.1342\n",
      "Epoch 281/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.5792 - val_loss: 24.1401\n",
      "Epoch 282/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.4609 - val_loss: 24.1311\n",
      "Epoch 283/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.4177 - val_loss: 24.0953\n",
      "Epoch 284/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.4915 - val_loss: 24.0954\n",
      "Epoch 285/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.4136 - val_loss: 24.1631\n",
      "Epoch 286/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.4075 - val_loss: 24.1706\n",
      "Epoch 287/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.3866 - val_loss: 24.2445\n",
      "Epoch 288/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.4897 - val_loss: 24.1419\n",
      "Epoch 289/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 19.3396 - val_loss: 24.2955\n",
      "Epoch 290/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 19.3804 - val_loss: 24.2138\n",
      "Epoch 291/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.4805 - val_loss: 24.1361\n",
      "Epoch 292/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.5305 - val_loss: 24.3176\n",
      "Epoch 293/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.3859 - val_loss: 24.3063\n",
      "Epoch 294/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.4165 - val_loss: 24.1812\n",
      "Epoch 295/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.3628 - val_loss: 24.1789\n",
      "Epoch 296/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.3780 - val_loss: 24.1703\n",
      "Epoch 297/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.3024 - val_loss: 24.2304\n",
      "Epoch 298/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.3747 - val_loss: 24.1635\n",
      "Epoch 299/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.3101 - val_loss: 24.2466\n",
      "Epoch 300/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.4364 - val_loss: 24.1246\n",
      "Epoch 301/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.4538 - val_loss: 24.0981\n",
      "Epoch 302/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.4315 - val_loss: 24.0188\n",
      "Epoch 303/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.2835 - val_loss: 24.0435\n",
      "Epoch 304/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.4299 - val_loss: 24.0845\n",
      "Epoch 305/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.3297 - val_loss: 24.1000\n",
      "Epoch 306/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.2927 - val_loss: 24.2217\n",
      "Epoch 307/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.4465 - val_loss: 24.1124\n",
      "Epoch 308/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.3713 - val_loss: 24.1394\n",
      "Epoch 309/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.3024 - val_loss: 24.0650\n",
      "Epoch 310/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.3061 - val_loss: 24.0703\n",
      "Epoch 311/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.3744 - val_loss: 24.0903\n",
      "Epoch 312/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.3926 - val_loss: 24.1190\n",
      "Epoch 313/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.2917 - val_loss: 24.0911\n",
      "Epoch 314/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.3720 - val_loss: 24.0341\n",
      "Epoch 315/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.2967 - val_loss: 24.1973\n",
      "Epoch 316/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.3107 - val_loss: 24.0849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 317/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.2973 - val_loss: 24.0571\n",
      "Epoch 318/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.2024 - val_loss: 24.3514\n",
      "Epoch 319/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.2863 - val_loss: 24.0761\n",
      "Epoch 320/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.4778 - val_loss: 24.1323\n",
      "Epoch 321/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.2092 - val_loss: 24.1110\n",
      "Epoch 322/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.2640 - val_loss: 24.1559\n",
      "Epoch 323/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.2643 - val_loss: 24.1191\n",
      "Epoch 324/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.2625 - val_loss: 24.1046\n",
      "Epoch 325/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.3276 - val_loss: 24.1135\n",
      "Epoch 326/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.2999 - val_loss: 24.0455\n",
      "Epoch 327/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.3691 - val_loss: 24.1259\n",
      "Epoch 328/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.1338 - val_loss: 24.0028\n",
      "Epoch 329/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.2574 - val_loss: 24.0168\n",
      "Epoch 330/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.2425 - val_loss: 24.0964\n",
      "Epoch 331/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.2139 - val_loss: 24.0934\n",
      "Epoch 332/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.2711 - val_loss: 24.0538\n",
      "Epoch 333/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.2805 - val_loss: 24.1228\n",
      "Epoch 334/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.2896 - val_loss: 24.0449\n",
      "Epoch 335/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.1873 - val_loss: 24.0587\n",
      "Epoch 336/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.1557 - val_loss: 24.1479\n",
      "Epoch 337/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.2336 - val_loss: 23.9920\n",
      "Epoch 338/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.2153 - val_loss: 24.1207\n",
      "Epoch 339/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.1684 - val_loss: 24.0616\n",
      "Epoch 340/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.1765 - val_loss: 24.4218\n",
      "Epoch 341/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.3039 - val_loss: 24.0457\n",
      "Epoch 342/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.3023 - val_loss: 24.0957\n",
      "Epoch 343/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.1852 - val_loss: 24.0844\n",
      "Epoch 344/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.2506 - val_loss: 24.2440\n",
      "Epoch 345/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.2230 - val_loss: 24.0459\n",
      "Epoch 346/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.1343 - val_loss: 24.0293\n",
      "Epoch 347/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.1784 - val_loss: 24.4238\n",
      "Epoch 348/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.1187 - val_loss: 24.0803\n",
      "Epoch 349/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.1751 - val_loss: 24.3957\n",
      "Epoch 350/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.1927 - val_loss: 24.1531\n",
      "Epoch 351/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.2704 - val_loss: 23.9847\n",
      "Epoch 352/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.1435 - val_loss: 24.2118\n",
      "Epoch 353/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.2884 - val_loss: 24.2444\n",
      "Epoch 354/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.1529 - val_loss: 23.9948\n",
      "Epoch 355/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.2369 - val_loss: 23.9854\n",
      "Epoch 356/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.2454 - val_loss: 23.9954\n",
      "Epoch 357/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.0986 - val_loss: 23.9280\n",
      "Epoch 358/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.1936 - val_loss: 23.9267\n",
      "Epoch 359/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.1398 - val_loss: 23.8800\n",
      "Epoch 360/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.1457 - val_loss: 23.9912\n",
      "Epoch 361/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.1793 - val_loss: 24.0282\n",
      "Epoch 362/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.1250 - val_loss: 23.9933\n",
      "Epoch 363/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.1615 - val_loss: 24.0870\n",
      "Epoch 364/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.1009 - val_loss: 23.9729\n",
      "Epoch 365/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.0996 - val_loss: 24.2498\n",
      "Epoch 366/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.1796 - val_loss: 23.8868\n",
      "Epoch 367/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.1490 - val_loss: 23.9583\n",
      "Epoch 368/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.1881 - val_loss: 23.9142\n",
      "Epoch 369/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.2227 - val_loss: 23.9743\n",
      "Epoch 370/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.0815 - val_loss: 23.9819\n",
      "Epoch 371/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.1233 - val_loss: 23.9722\n",
      "Epoch 372/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.1296 - val_loss: 24.0561\n",
      "Epoch 373/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.1460 - val_loss: 24.1536\n",
      "Epoch 374/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.1948 - val_loss: 24.0243\n",
      "Epoch 375/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.1490 - val_loss: 24.1344\n",
      "Epoch 376/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.2847 - val_loss: 23.9720\n",
      "Epoch 377/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.1093 - val_loss: 24.0735\n",
      "Epoch 378/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.0870 - val_loss: 23.9659\n",
      "Epoch 379/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.0879 - val_loss: 23.9641\n",
      "Epoch 380/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.1190 - val_loss: 24.0052\n",
      "Epoch 381/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.2347 - val_loss: 23.8841\n",
      "Epoch 382/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.0730 - val_loss: 23.9393\n",
      "Epoch 383/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.1805 - val_loss: 24.2830\n",
      "Epoch 384/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.2003 - val_loss: 23.9328\n",
      "Epoch 385/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.0783 - val_loss: 24.0472\n",
      "Epoch 386/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.0358 - val_loss: 24.0926\n",
      "Epoch 387/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.0343 - val_loss: 24.2702\n",
      "Epoch 388/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.0759 - val_loss: 24.0706\n",
      "Epoch 389/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.0178 - val_loss: 24.0390\n",
      "Epoch 390/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.0293 - val_loss: 23.9277\n",
      "Epoch 391/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.0940 - val_loss: 24.0105\n",
      "Epoch 392/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.0233 - val_loss: 23.9369\n",
      "Epoch 393/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.1068 - val_loss: 23.9455\n",
      "Epoch 394/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.0432 - val_loss: 23.7618\n",
      "Epoch 395/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 18.7564 - val_loss: 24.3221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.1027 - val_loss: 23.9524\n",
      "Epoch 397/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.0640 - val_loss: 23.8583\n",
      "Epoch 398/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.0687 - val_loss: 23.8508\n",
      "Epoch 399/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.0263 - val_loss: 23.8202\n",
      "Epoch 400/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 18.9840 - val_loss: 23.8715\n",
      "Epoch 401/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 18.9910 - val_loss: 23.7915\n",
      "Epoch 402/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.0753 - val_loss: 23.7519\n",
      "Epoch 403/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 18.9339 - val_loss: 23.9147\n",
      "Epoch 404/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 18.9712 - val_loss: 23.7844\n",
      "Epoch 405/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.1171 - val_loss: 24.0412\n",
      "Epoch 406/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.0579 - val_loss: 23.8642\n",
      "Epoch 407/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 18.9353 - val_loss: 23.8411\n",
      "Epoch 408/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 18.9285 - val_loss: 23.7860\n",
      "Epoch 409/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.0826 - val_loss: 23.9236\n",
      "Epoch 410/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 18.9047 - val_loss: 23.7958\n",
      "Epoch 411/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 18.9485 - val_loss: 23.7847\n",
      "Epoch 412/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 19.0698 - val_loss: 24.1702\n",
      "Epoch 413/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.0443 - val_loss: 23.8505\n",
      "Epoch 414/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 18.9524 - val_loss: 23.7908\n",
      "Epoch 415/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 18.8800 - val_loss: 23.7452\n",
      "Epoch 416/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 18.9604 - val_loss: 23.7549\n",
      "Epoch 417/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.0515 - val_loss: 23.9492\n",
      "Epoch 418/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.0447 - val_loss: 23.7751\n",
      "Epoch 419/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 18.9900 - val_loss: 23.7962\n",
      "Epoch 420/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.0393 - val_loss: 23.7922\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(32,activation='relu',input_shape=(x_train.shape[1],)))\n",
    "model2.add(Dense(1))\n",
    "\n",
    "es = EarlyStopping(monitor='loss',mode='min',patience=25)\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "\n",
    "model2.compile(optimizer=opt,loss='MAPE')\n",
    "history2 = model2.fit(x_train,y_train,epochs=1000,validation_data=(x_test,y_test),callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af92603f",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "512dd17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = x_train.shape[0]\n",
    "x_train = torch.tensor(x_train,dtype=torch.float)\n",
    "y_train = torch.tensor(y_train,dtype=torch.float)\n",
    "x_test = torch.tensor(x_test,dtype=torch.float)\n",
    "y_test = torch.tensor(y_test,dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "83b05dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = torch.utils.data.TensorDataset(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f8be3e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = torch.utils.data.DataLoader(datasets,batch_size=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6a28cd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e89b46cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_n = x_train.shape[1]\n",
    "net = torch.nn.Sequential(torch.nn.Linear(weight_n,1))\n",
    "torch.nn.init.normal(net)\n",
    "torch.nn.init.constant_(net[0].bias, val=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ddf854",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    for x, y in train_iter:\n",
    "        output = net(x)\n",
    "        l = loss(output, y)\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "    print(\"epoch {} loss: {:.4f}\".format(epoch + 1, l.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d010d164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86d6251b",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "506fb2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84a7829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train/255\n",
    "x_test=x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29158d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1,28,28,1)\n",
    "x_test = x_test.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0437a3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = tf.keras.utils.to_categorical(y_train,num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4c2bb0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Conv2D(filters=32,kernel_size=(5,5),padding='Same',activation='relu',\n",
    "                 input_shape=(28,28,1)))\n",
    "model3.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model3.add(Dropout(0.25))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(256,activation='relu'))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7db5b37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (10000, 28, 28, 1) (60000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,x_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "bff68937",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "90e5a23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer=opt,loss=tf.keras.losses.sparse_categorical_crossentropy,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7e954b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 82s 43ms/step - loss: 1.2103 - accuracy: 0.6760 - val_loss: 0.5152 - val_accuracy: 0.8803\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 86s 46ms/step - loss: 0.5239 - accuracy: 0.8495 - val_loss: 0.3456 - val_accuracy: 0.9106\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 84s 45ms/step - loss: 0.4109 - accuracy: 0.8797 - val_loss: 0.2873 - val_accuracy: 0.9215\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 85s 45ms/step - loss: 0.3562 - accuracy: 0.8955 - val_loss: 0.2519 - val_accuracy: 0.9279\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 87s 47ms/step - loss: 0.3183 - accuracy: 0.9056 - val_loss: 0.2267 - val_accuracy: 0.9338\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 75s 40ms/step - loss: 0.2914 - accuracy: 0.9142 - val_loss: 0.2070 - val_accuracy: 0.9388\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 72s 38ms/step - loss: 0.2682 - accuracy: 0.9209 - val_loss: 0.1912 - val_accuracy: 0.9433\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 72s 38ms/step - loss: 0.2512 - accuracy: 0.9252 - val_loss: 0.1774 - val_accuracy: 0.9485\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 79s 42ms/step - loss: 0.2339 - accuracy: 0.9308 - val_loss: 0.1642 - val_accuracy: 0.9523\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 85s 45ms/step - loss: 0.2210 - accuracy: 0.9354 - val_loss: 0.1533 - val_accuracy: 0.9532\n"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98b14f7",
   "metadata": {},
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b114df85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Flatten())\n",
    "model4.add(Dense(256, activation = \"relu\"))\n",
    "model4.add(Dense(64, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e6ab4d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b72456ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(optimizer=opt,loss=tf.keras.losses.sparse_categorical_crossentropy,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "431f0aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 9s 4ms/step - loss: 2.2841 - accuracy: 0.5383 - val_loss: 1.1263 - val_accuracy: 0.8137\n"
     ]
    }
   ],
   "source": [
    "history4 = model4.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245950bd",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "afdf138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = tf.keras.datasets.imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "92e78e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000,), (25000,), (25000,), (25000,))"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train.shape,y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ce1abc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import pad_sequences\n",
    "x_train = pad_sequences(x_train,maxlen=300)\n",
    "x_test = pad_sequences(x_test,maxlen=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a6544ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(Embedding(10000,32,input_length=(300)))\n",
    "model5.add(SimpleRNN(16,activation='relu'))\n",
    "model5.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "b363055b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 300, 32)           320000    \n",
      "                                                                 \n",
      " simple_rnn_4 (SimpleRNN)    (None, 16)                784       \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,801\n",
      "Trainable params: 320,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "3a913060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 300), (25000,), (25000, 300), (25000,))"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train.shape,y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "c592cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "1139f062",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 63s 79ms/step - loss: 0.5746 - accuracy: 0.6969\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 62s 80ms/step - loss: 0.3633 - accuracy: 0.8478\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 61s 78ms/step - loss: 0.2910 - accuracy: 0.8816\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 61s 78ms/step - loss: 0.2431 - accuracy: 0.9042\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 66s 84ms/step - loss: 0.2202 - accuracy: 0.9171\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 65s 83ms/step - loss: 0.2014 - accuracy: 0.9266\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 62s 79ms/step - loss: 0.1791 - accuracy: 0.9326\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 63s 81ms/step - loss: 0.1707 - accuracy: 0.9374\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 61s 78ms/step - loss: 0.1568 - accuracy: 0.9427\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 58s 74ms/step - loss: 0.1436 - accuracy: 0.9487\n"
     ]
    }
   ],
   "source": [
    "history5 = model5.fit(x_train,y_train,epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7584fa5e",
   "metadata": {},
   "source": [
    "### LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "eb5f881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = Sequential()\n",
    "model6.add(Embedding(10000,input_length=(300),output_dim=32))\n",
    "model6.add(LSTM(128))\n",
    "model6.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "0cad5fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model6.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "3cf53d9f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 34/782 [>.............................] - ETA: 3:41 - loss: 0.6928 - accuracy: 0.5303"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[211], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history6 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel6\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history6 = model6.fit(x_train,y_train,epochs=3,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff9ad17",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "abc5f21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = Sequential()\n",
    "model7.add(Embedding(10000,input_length=(300),output_dim=32))\n",
    "model7.add(GRU(128))\n",
    "model7.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "6c75c95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model7.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b579590e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history7 = model7.fit(x_train,y_train,epochs=3,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340f0864",
   "metadata": {},
   "source": [
    "### AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "73192aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3d949b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(len(x_train),28,28,1)\n",
    "x_test = x_test.reshape(len(x_test),28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "81732886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[100],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cadbc7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Sequential()\n",
    "encoder.add(Flatten(input_shape=(28,28)))\n",
    "encoder.add(Dense(256,activation='relu'))\n",
    "encoder.add(Dropout(0.25))\n",
    "encoder.add(Dense(128,activation='relu'))\n",
    "encoder.add(Dropout(0.25))\n",
    "encoder.add(Dense(64,activation='relu'))\n",
    "encoder.add(Dropout(0.25))\n",
    "encoder.add(Dense(32,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "da02db47",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Sequential()\n",
    "decoder.add(Dense(64,input_shape=(32,),activation='relu'))\n",
    "decoder.add(Dropout(0.25))\n",
    "decoder.add(Dense(128,activation='relu'))\n",
    "decoder.add(Dropout(0.25))\n",
    "decoder.add(Dense(256,activation='relu'))\n",
    "decoder.add(Dropout(0.25))\n",
    "decoder.add(Dense(784,activation='sigmoid'))\n",
    "decoder.add(Reshape((28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "80a5f5f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c4f91380",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Input(shape = (28, 28))\n",
    "latent_vector = encoder(img)\n",
    "output = decoder(latent_vector)\n",
    "model8 = Model(inputs=img,outputs=output)\n",
    "model8.compile('adam',loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "968df9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 28, 28])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "68cf8f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(60000, 32), dtype=float32, numpy=\n",
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.01359682,\n",
       "        0.09271489],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.17927001],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.06265103,\n",
       "        0.13783547],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.17481732],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.14350685]], dtype=float32)>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8afc4029",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 609/1875 [========>.....................] - ETA: 10s - loss: 0.2478"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[130], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mmodel8\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    model8.fit(x_train,x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db126569",
   "metadata": {},
   "source": [
    "#### Anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862e28db",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,Y_train),(X_test,Y_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f18efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing Threshold \n",
    "\n",
    "reconstruction_error_digit = []\n",
    "reconstruction_error_fashion = []\n",
    "\n",
    "for i in x_test[:100]:\n",
    "    error =  model8.evaluate([i], [i], verbose=0)[0]\n",
    "    reconstruction_error_digit.append(error)\n",
    "    \n",
    "for i in X_test[:100]:\n",
    "    error = model8.evaluate([i], [i], verbose=0)[0]\n",
    "    reconstruction_error_fashion.append(error)\n",
    "    \n",
    "reconstruction_error_digit = np.array(reconstruction_error_digit)\n",
    "reconstruction_error_fashion = np.array(reconstruction_error_fashion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe50c3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = [reconstruction_error_digit.mean() - 2*reconstruction_error_digit.std(), reconstruction_error_digit.mean() + 2*reconstruction_error_digit.std()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f526a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_anomaly(image):\n",
    "    \n",
    "    error = autoencoder.evaluate([image], [image], verbose=0)[0]\n",
    "    \n",
    "    if error >= threshold[0] and error <= threshold[1]:\n",
    "        print(\"Noice !!!\")\n",
    "        return 0\n",
    "    else:\n",
    "        print(\"Anomaly Detected\")\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dc0985",
   "metadata": {},
   "source": [
    "### TEXT Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a487fe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b88eafd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Downloads/poems.txt', 'r', encoding='utf-8') as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80e4376d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(set(text_data))\n",
    "char_to_num = {char: num for num, char in enumerate(chars)}\n",
    "num_to_char = {num: char for num, char in enumerate(chars)}\n",
    "\n",
    "numerical_text = [char_to_num[char] for char in text_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8797b878",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 100\n",
    "step_size = 3\n",
    "\n",
    "sequences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(numerical_text) - sequence_length, step_size):\n",
    "    sequences.append(numerical_text[i:i + sequence_length])\n",
    "    next_chars.append(numerical_text[i + sequence_length])\n",
    "\n",
    "X = np.array(sequences)\n",
    "y = np.array(next_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bb02898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 256)          13056     \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 100, 512)          1182720   \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 512)               1575936   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 51)                26163     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2797875 (10.67 MB)\n",
      "Trainable params: 2797875 (10.67 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=len(chars), output_dim=256, input_length=sequence_length),\n",
    "    GRU(512, return_sequences=True),\n",
    "    GRU(512),\n",
    "    Dense(len(chars), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "243176eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_next_character(predictions, temperature=1.0):\n",
    "    predictions = np.asarray(predictions).astype('float64')\n",
    "    predictions = np.log(predictions) / temperature\n",
    "    exp_predictions = np.exp(predictions)\n",
    "    probabilities = exp_predictions / np.sum(exp_predictions)\n",
    "    sampled_index = np.random.choice(len(predictions), p=probabilities)\n",
    "    return sampled_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eaa72523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed_text, length, temperature=1.0):\n",
    "    generated_text = seed_text\n",
    "\n",
    "    for _ in range(length):\n",
    "        # Ensure the input is of the correct length\n",
    "        sampled_input = [char_to_num.get(char, 0) for char in generated_text[-sequence_length:]]\n",
    "        if len(sampled_input) < sequence_length:\n",
    "            sampled_input = [0] * (sequence_length - len(sampled_input)) + sampled_input\n",
    "        sampled_input = np.array(sampled_input)\n",
    "        sampled_input = np.reshape(sampled_input, (1, sequence_length))\n",
    "\n",
    "        predictions = model.predict(sampled_input, verbose=0)[0]\n",
    "        next_index = sample_next_character(predictions, temperature)\n",
    "        next_char = num_to_char[next_index]\n",
    "\n",
    "        generated_text += next_char\n",
    "        generated_text = generated_text[1:]\n",
    "\n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "16a72e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.1222\n",
      "Epoch 2/15\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.1002\n",
      "Epoch 3/15\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.0698\n",
      "Epoch 4/15\n",
      "5/5 [==============================] - 18s 3s/step - loss: 0.0585\n",
      "Epoch 5/15\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.0431\n",
      "Epoch 6/15\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0373\n",
      "Epoch 7/15\n",
      "5/5 [==============================] - 22s 4s/step - loss: 0.0317\n",
      "Epoch 8/15\n",
      "5/5 [==============================] - 19s 4s/step - loss: 0.0248\n",
      "Epoch 9/15\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.0224\n",
      "Epoch 10/15\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.0192\n",
      "Epoch 11/15\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0169\n",
      "Epoch 12/15\n",
      "5/5 [==============================] - 21s 4s/step - loss: 0.0153\n",
      "Epoch 13/15\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.0138\n",
      "Epoch 14/15\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.0127\n",
      "Epoch 15/15\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.0119\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1de8526e8d0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PlateauLR(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, patience=3, factor=0.5, min_lr=1e-6):\n",
    "        super(PlateauLR, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.factor = factor\n",
    "        self.min_lr = min_lr\n",
    "        self.wait = 0\n",
    "        self.best_loss = float('inf')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current_loss = logs.get('loss')\n",
    "\n",
    "        if current_loss is None:\n",
    "            return\n",
    "\n",
    "        if current_loss < self.best_loss:\n",
    "            self.best_loss = current_loss\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                lr = tf.keras.backend.get_value(self.model.optimizer.lr)\n",
    "                lr *= self.factor\n",
    "                lr = max(lr, self.min_lr)\n",
    "                tf.keras.backend.set_value(self.model.optimizer.lr, lr)\n",
    "                self.wait = 0\n",
    "\n",
    "# Define the PlateauLR instance\n",
    "plateau_lr = PlateauLR()\n",
    "\n",
    "# Training the model\n",
    "model.fit(X, y, batch_size=batch_size, epochs=epochs, callbacks=[loss_callback, plateau_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e51d6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and and the doul for the ot laspt asd the \n"
     ]
    }
   ],
   "source": [
    "seed_text = \"The quick brown fox jumps over the lazy dog\"\n",
    "generated_text = generate_text(seed_text, length=300, temperature=0.5)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7191938e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbaa3d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
