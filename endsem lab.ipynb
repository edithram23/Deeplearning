{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e477ff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "import keras\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Conv2D,MaxPooling2D,Input,Dense,Dropout,Flatten,Reshape,Embedding,GRU,LSTM,SimpleRNN\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6210ba62",
   "metadata": {},
   "source": [
    "### Ex 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ad9aa251",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = np.array([[1,1],[0,1],[1,0],[0,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1248f8",
   "metadata": {},
   "source": [
    "#### Toutology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5145681c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "weights = np.array([[0],[0]])\n",
    "bias = np.array([1])\n",
    "output = input1@weights + bias\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651e27a3",
   "metadata": {},
   "source": [
    "#### Not Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e0b90c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "inputnot = np.array([[1],[0]])\n",
    "def not1(x):\n",
    "    weights = np.array([-1])\n",
    "    bias = np.array([1])\n",
    "    return x@weights + bias\n",
    "print(not1(inputnot))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7039013b",
   "metadata": {},
   "source": [
    "#### Or Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "05ca4eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step (s):\n",
    "    return 1 if(s>0) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e21fff09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "def or1(x):\n",
    "    weights = np.array([[1],[1]])\n",
    "    bias = np.array([0])\n",
    "    return x@weights + bias\n",
    "print([step(i) for i in or1(input1)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f99ca77",
   "metadata": {},
   "source": [
    "#### And Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a220a6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def and1(x):\n",
    "    weights = np.array([[1],[1]])\n",
    "    bias = np.array([-1])\n",
    "    return x@weights+bias\n",
    "print([step(i) for i in and1(input1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5379af8",
   "metadata": {},
   "source": [
    "#### Nor Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "72f1e09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "out = [step(i) for i in or1(input1)]\n",
    "print(not1([[i] for i in out]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c53c562",
   "metadata": {},
   "source": [
    "#### Nand Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6970f483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "out = [step(i) for i in and1(input1)]\n",
    "print(not1([[i] for i in out]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671eecee",
   "metadata": {},
   "source": [
    "#### XOR\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "96c09671",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = np.vectorize(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "73e088ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "w1 = np.array([[1,-1],[-1,1]])\n",
    "w2 = np.array([[1],[1]])\n",
    "out = step(step(input1@w1)@w2)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cb38f6",
   "metadata": {},
   "source": [
    "#### XNOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0ba4a400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "w1 = np.array([[1,-1],[1,-1]])\n",
    "w2 = np.array([[1],[1]])\n",
    "bias = np.array([-1,1])\n",
    "out = step(step(input1@w1 + bias)@w2)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73709896",
   "metadata": {},
   "source": [
    "## Linear Regression - Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9ebf9053",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "epochs=1000\n",
    "np.random.seed(23)\n",
    "\n",
    "x = np.random.random_sample(500).reshape(-1,1)\n",
    "y = x*2 + 0.5*np.random.random(500).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3c44fd",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "baf56560",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "model.compile(optimizer=opt,loss='mean_absolute_error')\n",
    "model.fit(x,y,epochs=epochs,batch_size=64,verbose=False)\n",
    "y_pred = model.predict(x,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9eb9618d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e705517e20>]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAACAQElEQVR4nO3deXgUVdYG8LezL2QlQDdrwqaEyJIoJKA4YEBWt3FUEBdUFIRRwQVREREdRP0GVBAEEUUEdAQHEIwE2THILoSwxgAaEpgkkEBC1q7vj1Chq7vWTmd/f8/D85jqqurbjVon9557jkkQBAFERERENcStpgdAREREDRuDESIiIqpRDEaIiIioRjEYISIiohrFYISIiIhqFIMRIiIiqlEMRoiIiKhGMRghIiKiGuVR0wPQw2q14ty5cwgICIDJZKrp4RAREZEOgiDg8uXLaN68OdzclOc/6kQwcu7cObRq1aqmh0FERERO+PPPP9GyZUvF1+tEMBIQEACg/MMEBgbW8GiIiIhIj7y8PLRq1ariOa6kTgQj4tJMYGAggxEiIqI6RivFggmsREREVKMYjBAREVGNMhSMzJgxA7fccgsCAgLQtGlT3HPPPTh+/LjqNVu2bIHJZHL4c+zYsUoNnIiIiOoHQ8HI1q1bMW7cOOzatQuJiYkoLS3FgAEDkJ+fr3nt8ePHkZGRUfGnQ4cOTg+aiIiI6g9DCawJCQmSnxcvXoymTZti37596NOnj+q1TZs2RXBwsOEBEhERUf1WqZyR3NxcAEBoaKjmud27d4fFYsEdd9yBzZs3q55bVFSEvLw8yR8iIiKqn5wORgRBwMSJE3HrrbciKipK8TyLxYIFCxZg5cqVWLVqFW644Qbccccd2LZtm+I1M2bMQFBQUMUfFjwjIiKqv0yCIAjOXDhu3DisW7cOO3bsUK2qJmfYsGEwmUxYs2aN7OtFRUUoKiqq+FksmpKbm8s6I0RERHVEXl4egoKCNJ/fThU9++c//4k1a9Zg27ZthgMRAIiNjcXSpUsVX/f29oa3t7czQyMiIiIAZVYBu9NycOFyIZoG+KBHRCjc3WpnfzdDwYggCPjnP/+JH374AVu2bEFERIRTb3rgwAFYLBanriUiIiJ1CckZmLY2BRm5hRXHLEE+mDosEgOjat/z11AwMm7cOCxbtgyrV69GQEAAMjMzAQBBQUHw9fUFAEyePBnp6elYsmQJAGD27NkIDw9H586dUVxcjKVLl2LlypVYuXKliz8KERERJSRnYOzS/bDPwcjMLcTYpfsxb2R0rQtIDAUj8+bNAwD87W9/kxxfvHgxHn/8cQBARkYGzp49W/FacXExXnrpJaSnp8PX1xedO3fGunXrMHjw4MqNnIiIiCTKrAKmrU1xCEQAQABgAjBtbQr6R5pr1ZKN0wms1UlvAgwREVFDlpSajeELd2met3x0LOLaNa7y8eh9frM3DRERUT1x4XKh9kkGzqsuDEaIiIjqiaYBPi49r7owGCEiIqonekSEwhLkA6VsEBPKd9X0iNCunF6dGIwQERHVE+5uJkwdFgkADgGJ+PPUYZG1KnkVYDBCRERUrwyMsmDeyGiYg6RLMeYgn1q5rRdwsgIrERER1V4DoyzoH2muMxVYOTNCRERENYozI0RERPVMXSsHz5kRIiKiekQsB28biABAxrVy8AnJGTU0MmWcGSEiIqon1MrBA+Ul4V9deQgBPp7IulJUa3JJGIwQERHVE7vTchxmROxdulqKhz//reLn2rB8w2UaIiKiesKZMu+ZtWD5hjMjREREdVSZVZBs3w1r5G34HrWhmy+DESIiojpIbseMOdAb/l7uyC8uM3QvAeUJrrvTcqqlm689BiNERER1SJlVwJxNJzFr40mH187nFSkmr+pRU918GYwQERFVA/slFWd2sSQkZ+CtNSnIzJMPGsRAxGTzz0bUVDdfBiNERERVzBVFyMT6IXqCDKOBiAnlvWtqqpsvd9MQERFVIaUiZEZ2sWjVD5Ezqnc4Qv29NM+rDd18GYwQERFVEbUgQjw2bW0KyqzqYYae+iH2Vh9MR05+ccXPof6eGH1bBCy1sJsvl2mIiIiqiFYQoXcXy8aUTMPvnZNfIvn5Yn4JPt+ehrkjuiPE37tWdfNlMEJERFRF9O5OsT/PNtn1dFY+Fu08XemxiPVEpq87ih2T+tV4AGKLwQgREVEV0bs7xfY8uWRXvUL9PJFTUKL4ek3XE1HCnBEiIqIq0iMiFJYgHyjNQZhQvqtG3MWilOyqx4T4jpgyNFLXuTVVT0QJgxEiIqIq4u5mwtRhygGCAOCurha4u5mc2jEjeqJ3OJ6P7wBzkK+u82uqnogSBiNERERVaGCUBU/3iVB8fcG2NCQkZzi1Y0bUP9IMwPhMTG3BYISIiKgKlVkFrPldvZbItLXKVVXV2AcXtjMx9gFJbagnooTBCBERkU5lVgFJqdlYfTAdSanZmvVBAP3be3OuFDk1JvvgYmCUBfNGRsNcC+uJKOFuGiIiIh2cLemuN1k01N8L5kBvZObpD0peiO8o+94DoyzoH2mudC+c6sJghIiISINSXxixpLvajIPeZNGzOVdRWGo1NK7wMD/F19zdTLVq+64aLtMQERGpqGxJdz1JpcF+npi98QQuqdQIkZN1uUjXUlFtx2CEiIhIhZGS7nK0kkrFUMKZkGL6uqOImZ6IjzaecD4osVqBvDznrnURBiNEREQqnC3pbkstqXRCfAfDMyK2Ll0twayNJxHzTqKuDsAS774LuLsDQUFAcrLTY6gs5owQERGpcKakuxylpNIfD51zxTBxqaBEM3+lwqFDQNeu0mPBwS4ZhzMYjBAREakQcz4ycwtll1JMKJ/h0FNITC6p1JXVUAWU56/0jzTL75wpLi4PQo4dkx4/eRJo2dJl4zCKyzREREQqqrqQmN4EV70U81c++gjw9pYEItY5c5B0Kgurr/jqrptSFTgzQkREDUKZVTBUd8P+/LkjojF9nbTOiFlHnREtYrAzdul+SUIrcD3YGdUrArM2ntB9z52nsq5/zpIsuHe6UXpCly746Ys1eH39ceQs3FVxWE/dlKpgEgSh1u8JysvLQ1BQEHJzcxEYGFjTwyEiojrGaMEypfOnDOmEEH/vKikkpjbG/pFm3Dpzk6HeNe7WMny/9BV0zzgufSE5GTPOmPDZtjTZ60yAyyq16n1+MxghIqJ6TalgmRhC2D94jZ7vSmqzNwnJGRizdL+u+/zj0AZ88NPHkmPHn5+MG2b/C+sPZeDZZer3sQT5YMekfpUOtPQ+v5kzQkRE9ZbRgmWVLXBWWWKC693dWiCuXWOHnjPzR0ar5o+0yL2A0zOHSgKRvwKb4IYXV+HxZneguNSKV1Ye0hyHWt2UqsCcESIiqpP05IAYKVgW166x4fOrm7g9eM6mU1i8Mw2XrpbXJzEJVnz5n7dwe5p0xmPYo7Nw2NIBuDbur349jStFpbreS299FVdgMEJERHWO3hwQowXLXFHgrKq5u5nwfHwHjO/XHrvTcuCx8j+4ZdJYyTlz4h7Ah30edbh2z+ls3e/jyi3HWhiMEBFRnWKkaZ3RgmWuKnBWHdwvnEdce2nuSp6XH2LHfYUCL1/Za/y89D32/b3cddVNcRXmjBARUZ1hNKcj60qR5j3dTEBMmxAA2jU/gPIZmKp4UJdZBSSlZmP1wXT1mh+CADz4IGCRBiJjR/8bXSd8pxiIBPt54u/R+gqbPXVbhMt2CenBYISIiOoMIzkdZVYBU9cc0bynVQD2nbkIQFrgTMldXS0uf1AnJGfg1pmbMHzhLjy/4iCGL9yFW2ducuw1s24d4OYGfPfd9WPjxgGCgLufe0i12d6lghJcLizVLKDm7+WO5+7o6PyHcQKDESIiqjOM5HTsTstBTn6x4fsOjLIgPrKp4rkLtqUZb0inQlx2sg+yxGWnhOQMIDsbMJmAoUOlF+fkAHPmAAD6R5pVAw0TgOnrUvCve6JUx/N/D3St1lkRgMEIERHVIUZyOowkmdred/2hc0hMuaB4rtj/xRXbe7WWnQQAhU+MBsLCpC8mJACCgLKg4IqlnS93pql2/xVnjUL8vTF/ZDTMgd6S182B5ceru/oqwARWIiKqQ/Q2rYtpE4Kvk07rumeov2dFDkiZVcAbq5M1r3HV9l61Zae4M4ewfMVrkmPWh0fit7dm4cKVIpzeeBLLd59FZp6xnT2ZeYUwB/pg0sAbkZNfjNBG3jAHuraarFEMRoiIqNazrSny0C2tFfu0CCjP6bj9g826S6e/c3dUxUO4fGlHeXbBliu298oFEo2KCrBnziPwLZUm327acgiv/3oBGZ//Vqn3nP7jEclnFLdE11QgAjAYISKiWk6upogapZ4rcp7pE4HBXZpX/Ozs0o6zcux2+7y6+QuM2b1KcuyZe15Do+H3Y9VPZ1UTVHW/p12wJbcluroxGCEiolpLqaZIZTX298L0u6MwuIv04Rvm761whVSov5dkacdIN2D7+wBAt3PH8d+vX5S8trHdLXjq72+WJ67uP6frfkrsuwHbEq69Pm1tCvpHmmtkhoTBCBER1UpqyZ2VcX90S8y8v4v8Q1fnc/jR2DZwdzMZ7gZsr7mXgN1zHkHT/IuS43FjFyMjsIm+wegQ6u+FbJWdRTVd5p7BCBERVQvbGYQwf2/AVF6UzNm+Ms76fv9fiI9sKhss6CmSBgBtwvzx0caTsrkrupc93nkHPadMkRyaOGQCVkXdoWsMWqYM6YSwAG80DfBBZu5VTPjud81raqrMPYMRIiKqclp5H5XpK+MMpSUJvXkgb689gosK22g1lz0OHQK6dpUc+q1VFIY/9C6sbu56P4IqS5APHu99vYpqUqq+njQ1VeaedUaIiKhKKRX1siUp8HVNVT4YxSUJe3rKwQNQDEREtsseFYqLgU6dHAIRnDyJi+s3INDfdZ/XfneM1ucyoerK3OvBYISIiKqM3rwPub4y4gNUL6Npl3IzL7bl4O3v50xaZ8V7fPQR4O0NHDt2/cW5c8v7zLRvj4FRFswdEe3EO0i5mYBPR3R3WB7S87lqcnsvgxEiIqoyRvI+xNmEL3emYfXBdOxOy8HQLvq3mpqDfDB/ZDQmxHfQdb7SzMvAKAvmjYyG2S4QEne+GNHyf3+V74Z54YXrB7t0KZ8lefZZybmx7RprzspohQqBPh5wUwgolD6XOcinRrf1AoBJEARXJyq7XF5eHoKCgpCbm4vAwMCaHg4REem0+mA6nl9xsEruPfq2CPS7sZlkSy0A7ErNxrPL9iP3qvxSilildcekfqozAfZbdvUmgQKAu7UM3y99Bd0zjktfSE4GOndWvE5c0gKkW3HFUc4dEY2TF67gs22pKCguk/1sAFSDi8psRTZK7/ObCaxERFRlqirvwwTgx0MZeHVQp4oHqZ7iaEaWJNzdTJJtrnqTQP9xaAM++OljybHjz0/GDbP/pXmtOHth/znMNgm+ZVYBy3efkQ1GxOTZt9YcQYCPp+xuJfvPVRsYCkZmzJiBVatW4dixY/D19UWvXr0wc+ZM3HDDDarXbd26FRMnTsSRI0fQvHlzvPLKKxgzZkylBk5ERLWfVi8ZZ9nXxdBbHM1soAaIvR4RoQj281RsRtci9wJ2zn9CcuyvwCa4Y/RnCG0ciB1WQdcMxMAoC/pHmhVnL3an5SAzT3kLsgAgM68ID9uUjTdS+6QmGMoZ2bp1K8aNG4ddu3YhMTERpaWlGDBgAPLz8xWvSUtLw+DBg3HbbbfhwIEDeO211/Dcc89h5cqVlR48ERHVbmqJk65w4XKhriRZf293jOvbDh/e3xX9I80uHYNJsOKr7950CESGPToLt45djCIPL8XdO0rE2Yu7u7VAXLvGkiDGmS3PcruVahNDMyMJCQmSnxcvXoymTZti37596NOnj+w18+fPR+vWrTF79mwAQKdOnbB37158+OGH+Pvf/+7cqImIqM4Qlx5eXXVYtcW9M5oG+OhKks0vKsPczamYuznV6VmC3Wk5DuMfcnQ75q6ZKTk2J+4BfNjnUYfrXVU3xZmlr9pQ8l1NpXJGcnNzAQChocr7kpOSkjBgwADJsTvvvBOLFi1CSUkJPD09Ha4pKipCUdH1Kai8vLzKDJOIiGqBXBcGImISao+IUPx4yFjfFmcbw9kGE02uXMSeuY9IXs/z8kPsuK9Q4OUre71WEKE3sVRruUhJTZd8V+N0MCIIAiZOnIhbb70VUVFRiudlZmaiWbNmkmPNmjVDaWkpsrKyYLE4/oswY8YMTJs2zdmhERFRLeLqHjP2SahGZwqcnSVoGuADCALmrHkfQ49tl7z2wIj3sLuV/LPQNnBSUtkeN0bUVMl3NU7XGRk/fjwOHTqE5cuXa55rMkn/osXdxPbHRZMnT0Zubm7Fnz///NPZYRIRUQ1zdY8Z+7oYPSJCEervOMuuRrZCqoYeKUk4/f4wSSDyVfQQhE/6UTUQAdR37yhVqFXK85BbLjKipkq+q3FqZuSf//wn1qxZg23btqFly5aq55rNZmRmZkqOXbhwAR4eHmjcWH6ayNvbG97e+to4ExFR7eaq38QfjWuDQVEWh+ULdzcT7u3WAot2nq6asWVnA2FhsO8a0+X5FcjzaQSgPOgQAIflE63dO2qzRkozOM5+n3pmaGqKoWBEEAT885//xA8//IAtW7YgIiJC85q4uDisXbtWcmzDhg24+eabZfNFiIiofnHVb+JiICKXVxEfaXYqGNEc2zPPAAsWSA49PeIdbGjVTXIs2M8TM+67SXVLrhytWSP7PI8yq4Csy/o6C9uqDSXf1RgKRsaNG4dly5Zh9erVCAgIqJjxCAoKgq9vecLO5MmTkZ6ejiVLlgAAxowZgzlz5mDixIkYPXo0kpKSsGjRIl3LO0REVPeJtUYqs1RjApB9uQi3ztwkm1fRP9JsuJ6JamO4zZuBfv0kh1Z17ouJQyaWl3e3IzbOM1pQTO8sx4XLhbqKuimpTH2V6mCoHLxSjsfixYvx+OOPAwAef/xxnD59Glu2bKl4fevWrZgwYUJF0bNJkyYZKnrGcvBERHVbQnIGxlwrc+5KtuXPAciWUlfyTJ8ITB4cKT2Ylwc0awYUSh/4MeOXIts/WHUcSiXm1XbJJKVmY/jCXZpjnRDfAbM3njScBBzs54m5w6MRa1erpLrofX6zNw0REVWLjzaexKyNJ1x+X9tAIDElU/fsgQl2PVxefhn48EPJORMfmIJVET11j2X56FjJzIjWLpkyq4BbZ25SnNERP5sgCKpVV42MqTrpfX6zay8REVWL8f3aI8jH9S3RbPMqBkZZsGNSPywfHYtZD3TV7LQ7bW0KypJ2lS+92AQiO26MRfgraw0FIgDwU3IGklKzUWYVdO2Ssa1Qq+ShW1o7HYgAtXMrrz02yiMiIgBV183V9r79I5vh+/3pLhitI/GhK+ZtJKVmIye/WPF875JCrH73Ebi/dlFyvNfYxTgX2MSpMSxJOoMlSWdgDvRGYalV1y6ZgVEWPN0nAgu3p8Fqc4GbqbwzcXiYn1NjEdXGrbz2GIwQETUgSgFHVRXdkruvyQRURYJA1uUilNk0o1ObERj/6wq8tH2p5Jh18ZfondHSJTVRtGYyxNmcXX9kY+/pi/hsW5rjOQLw2bY0DIpq5ngDHWrzVl57zBkhImog5AKDUH8vdGsVhE3H/udwvm1yqDMBid5Ouq5kG0DJJYd2uvAHflr8nORY3i1xCEzajqTTl3Qlk7pSkI8HcgtLXX7fyv7duQpzRoiIqIJS/kJOfrFsIAJc35EybW0KyqzGQgo9JeDtV4D8vOzLihlnm48R0yak4j08y0rwy8IxDoHI355eAM8d2wF39xrJrahsICJ+hcF+0rpd9lVqazsu0xAR1XOV6Q3jbHM1PSXgrQIwZUgnhAV4o2mAD6xWAQ8v+s2JUUrHK+ZjBPh4wioAo/auxtRfFkrOe6P/WCyNHgIA6D1zE/51b5Sh3IpG3h64UuT6GQ2jzDZ1Vqoi36e6MBghIqonlPJBXNEbxuisgd7zwwK8cXe3FgDKx69WuMwEoFmgN568tS3eXX9U8Z5iAHVs616cnjlU8trRJuEY9thslLpff/zl5Bdj7NL9mDsiWrNwWrCvJz4Z3h0vf3+oRoOR8X3bo3f7MEnQUds68RrBYISIqB5QS0AtKrVW+v5Gd2ToPd/+vIduaS1bi0T8Hf+tuzprfh53axm+X/oKumcclxzv/8RcnGzSRvYaAcD0dSmYMqQTxi07UNFrxv793/v7TfBwd0NmnvPBnX3/Gmd0aNaoTgcf9pgzQkRUx2nVszidle/0vU3QKJuuQCwBr7RQYH/fhOQM3Dpzk2JRNNscCLVA5x+HNiD1g7slgcjM2x9D+KQfFQMRUUZuIUL8vTFvZDTMQdL3sH1/Z3NLbu8YhuWjYzF3eLRT19uqC9t1jeDMCBFRHabV9RUAlu8+C3OgD87n6e/bAlSuuZpYzGvs0v2KswzifbV23UyI74Dx/TpUjEEMdGyXU1rkXsDO+U9IrhNat0biqi2Y/58U3ePOzCvEvd1bVORgZOZeRU5+MUIbeSPI1wtlVgFhjZzrKr/1RBaG92jtVB8dUV3armsEZ0aIiOowPfkgmXlFuLV9+ZS+kZCisjsyBkZZNGcZtJJrTQBW7PlTcsy2aqmbYMWSb6c4BCK/rvgJpjNnMCAmAvNGRiPAR99OnZwrRRXvkXu1GO//fBzT1x3FhG8PYvjCXYh5JxHPfrNP173kPsu0teWBkTh+I38ftb3zbmVwZoSIqA7Tm7vw/f70iu2fWvkKo3qFY0Bns0t2ZAyMsqju9NAKppR28wyMsuCHsL/Q7WVp09Uv/zYC5k8+lARQA6MsyC8qw4v/+V1zvGL5eKXZmsrketiXrZ83Mlq1j46bCZKKrLW9825lMBghIqrDxN/k9cgtKIGA8mWPvKsl+OFgOnLyHR+uCUcy0bOteiCip3S8eI7tUoc9vfkXkvMyMwGLBd1sXi9pFID9Ow/jkajWsuNuHuyr633MQb6V2gqth/hZ7AO1MH9vwARkXSlC0wAfxLQJwb4zF+vsdl0jGIwQEdVhWo3gbIk1OFbs+RM7JvVDTJsQPLvsgMN5mbmFGLN0PybEd0B4mL/Dg1Bt5474cN2YkolVB9JxUWYmwbZKqqFdN4IAPPQQ8N130he3boVnnz5Qa2nXIyIU5kAf1ZkkMaHWFVuh1dh+ZrGPjpL6tGNGDYMRIqI6zByk7zd+kW1PlOnr5Gt1iDMCszaerDgmBhAAZJcvxABGz7bVjGu7fOaNjNZM5qxI2ExJAtoPk744bhwwZ47qe4kSUzJRWFqm+LoJ13MxKlOJNdjXE7lXS9Q/Sz1LPnUFJrASEdVh4s4So5JSsw399i9uE3511WHVnTtGciq0kjlNAIKv5iHptXi432UXiOTk6A5ExPwPpbGF+HlKEnUrs212VO+IirHbqs/Jp67AYISIqI4SczIGR5mduNpYRoRw7U9li3XZ3s8+mdN+182sTZ/iwMcjpBcmJJQv14SE6HofPfkf3h5u6B95/TvUqpGixBLkg/H92mvuICJHXKYhIqqD5PI27HdfyBGXCuLahmHO5tSqHaQOcsmc1k2/oPfTD0pPHDkSWLIEMBkLEfRufbbdrWNbI8UIcdZDawcROWIwQkRUy2jtVFHadipcO9DvxibYdOx/qsXGYts1hiXIp0oTNfWQJHNeuYy4qJZAod2Yzp8HmjZ16v6ZuVedOk+crXnth8OyO47sTYjvIJn10EpMJSku0xAR1SJiWfThC3fh+RXlhbZunbkJCckZALQrrpoAHM24jE9HdFddKrAtHFZTJGXmX34ZCAqSBiIrV5ZHWE4GIkB5EzxnzxsYZcGuyfFo5K3+e3v58kwHp8ZH5TgzQkRUSyjNeGTa7D4J8vXSVSQsxN8bOyb1U51hGRhlwZO9w7Fo52ld4zOhvMmb3HZdoyp2r+zZDcTGSl8cOhRYs8bwkoxcXZOcAp3BSEExVh9Md/ieNh07r9mdl0mplcdghIioFiguteK1H5R3qoilxF8ZeKOu+124XKhrqSA+0qw7GAGAGffdBKtVwPjlBzTzU5SE+Hli5qB2GNA/uryAma2zZ4FWrQzfUy6Hxoi5NvkztjVTxB0/SoL9PCXJr+QcLtMQEdWwhOQMxM74RTU3QZzx0FtxVe/21Jg2IQj199Q8z2KzxBPi7+1UIBLk64EJ8R2wz/QbBvRoLw1EvvqqfEnGyUBErmuxs8SZqDmbTmne81JBCXan5bjkfRsyzowQEdUgrY619kL9vTQ7vrqZgIs6ciXE2QStBE37rrlGioKF+HlWdMHtkfcn3KNvkJ7Qpw+waRPgrq+Rnb2qKN0uzkQt/jVN1/mVKZJG5TgzQkRUQ5x5kJqDfDUTT60CMG7Z/oqkVzl6ZhMsQT74dER39IhojB8PnUNSajbKrIKhomCXCkqwdNtJ3BTfE+7R3aUvnjwJbN2qGYiUWQUkpWZj9cH0ijGIqqp0u5GaKpUpkkblODNCRFRDjDxIbUuJu7uZMHdEd828jWlrU9A/0izbwE4rCGrs74XXB3XC9HVHHXrQTBnSSXN2RvT43tWY+stC6cG5c4Fnn9W4spxaH5yBUZYqn5VgeffqwZkRIqIaYvRBartrQytvw7bCqT09QVB2fjHGrzjgcF5mbiHGLTuAu7qW19RQ2kMSkZOO0zOHSgKR/Bs7A8XFhgIRudkbMacjITmjymclRvUOB8Dy7lWNwQgRUQ3R+yD193bHC/EdJLs29AYycudVZjZBjH/W/J6BuSMcy567W8vww5IXsXnhM5Lj/Z+Yi43LfwY8tZNlAe16KkD5zE9MmxCnevPoIdYPYXn3qsdlGiKiGiL2QNFa7sgvKsOsjSexYs+fFcsTegMZufMqO5twvZaJF3ZM6ocvd6Zh+rqj+MehDfjgp48l5868/THMi/2H4ffVmr0Rx7DvzMWK0u2uTGIFWN69OjEYISKqZrbl3h+6pRVmbTzpULpdjm3xs/6RZtVARi2fQW8QpEWsZfJ4Szc8OXOo5LW/ApvgjtGfocjDy6ncCr2zN5l5hbi3ewvMGxldqTojttxMwJzh0SzvXo0YjBARuZCevjL2D81gv/KlC63dG7bFz/pHmitmBNR60Mj99m7bCE7uWr0BSlN/L+DOO+G+YYPk+LBHZ+GwpYOusSgJ8/fWdd7ba5Ph6+kmmb1Yd/gclu46q/u97M0Z3h2Du3D5pToxZ4SISAe17aUirb4ySgmZuQUlyC0owYT4jhjft53qOGwTU8Vmbs7kM6hd++mIaFiCfBSTU00ARp5JQlzHpoBNIPL5bQ8hfNKPFYEIAAT5eTqMRc93qfjmdi4WlFYks4qzF0Nuaq7r2lB/L8nPliAfzB8ZjcFd9F1PrsOZESIiDVrbS8Vz1PrKzB3RHdPXHVUt975iz1lD5d4BVCqfQe1aNzfIzpw0uXIRe+Y+IrlPSaMAdBv9BfK9fB3e41JBCY5nXq7YYqznuyz/fPoqzYqmrU1BvxubYd+Zi8jMK0Sov6diMTdx2Wjry32x78xF5oHUAiZBEFyd8+NyeXl5CAoKQm5uLgIDA2t6OETUgCgFGeIjS8zfuHXmJsV8BROAEJWHo60pQ8pre2hZPjq2ynMYJIGDIGDOmvcx9Nh2yTllm7fg1qRSzVwNc6AP7u5mwYJtaarf5cAoCxKSM/DaD4d1fV+21AIQpfeiqqX3+c2ZESIiBVrbS8X8jQAfT82dH3ofrFrl3quz0JY4c3LiixXoNHqE9MVx44A5c7A7NRsZCbs075WZV4jPtsmXV7f9Lq1WAeOWHXAqsVbPd2yWmYWhmsdghIhIgd7tpUmp2S57T7HcuzOJqS6XnQ33sDB0sj+ekwOEhABwXV8W8bt8Y3WyS7fomlAe4L0xpBPMQb5ciqmlmMBKRKRA/4O28o9PE8pzJ3pEhFYqMdVlnn4aCAuTHktIQFmZFUk51orkU727XvQyujSjRUB5NVlzkC/i2jVmIFJLcWaEiEjB6awCXecF+XrCHOiD83nO1e2Qm/GosUJbmzcD/fpJj40cCSxZgoQjmZhmlxtjDvRBsJ8ncgvk+7fUFuysW7sxGCEikpGQnIFZG0/oOvfd9cfQyNvd6YexUh5DtRbayssDmjUDCu0e2ufPA02bKibyOhuA2ROXU7Lzi11wN0fsrFu7cZmGiBoUPTUuyqwCXl112NB9rxSVGR7L+L7tsXx0LHZM6lezCZUvvwwEBUkDkZUrAUEAmjbVlcgb4ueJZgFeMmdoE+d6pt8dpVrfxNl7W9hZt9bjzAgRNRh6a1zsSs3WrIbqCh2aNXKY+dCq4OpSv/0GxMZKjw0dCqxZA5iuv6eeRN6LBSX45qme2Hv6ouyMkni3p/tEYM3vGdKlHpu/A6X6JnLcTFDtXCxiZ93aj8EIETUIWkXJbBNDk/7IqpYx2S8d6A2WKq2gAGjXDsjMlB4/exZo1crhdL35FllXivB8fAfcYG7k8DlsA45XBnZSDLjE5F2572HKkE4I8ffGhcuFyLpcpKseywvxHbmNtw5gMEJE9Z7eeiFilVDdtcidJFcrxEiwpEZzZmX6dODNN6UXffUV8Oijivc02iFYK/lWKxdGT/Lu6oPpusYUHuan6zyqWQxGiKje01svZHdaDuLaNUZcu8aYs/lUlYxFbueMmKOiP1iSpzqzUnYB6NZNekGfPsCmTYC7u+qYtbr8ygVXlU2+1breaIBEtRsTWImo3ktMydQ+CdeXI2LbNq7opFtZ9s3Y5GqFzNl0UjVHxTZYUqLUhC875zI63N7DMRA5eRLYulUzEAGud/kFHOeMqr0Q2zVigKTWzI+Jq3UHZ0aIqF4rswr478Fzus4Vf4t2dzPhvftuwpil+51+X6VmbDFtQrDvzEWsPphe8fPinad13VMpd0NpGWrU3tWY+stC6cG5c4FnnzX8eZRyOey3JZdZBez6I/taVVoBcW3DEHtthsOVibligFQrKtVSpTEYIaJ6bXdaDnJ01K4I9feU/BY9MMqC+SOj8daaFGTmSZc97upqcdgRYk8A8NAtrSXLDQnJGbj9g82S60L9vXDpqr6dO0pLDvbLUBE56di88BnJOUebhCN3WxJibzRrvo9S3olWLkdCcgZeXXVYMsszZ3Mq/Lzc4eXhJjluDvTBW3dVLjFXb4BEtR+DESKq1/TuBLm3WwuH36LVHr7ijpDElEz89+A52YBn1sYT+PLXPxDXtjEEmPBTsuNykZ5ACQCC/TwVlxzEz+huLcPKpS+jW4Z0a23/J+biZJM2+KhQuxaK1o4epVyOhOQMxZmkguIyFBRL3zszrxBjlu7H/EqWt6+xSrXkUgxGiKhe05vAGB8pP2Og9PAVj8e1a4zXh0RizqaTmLXxpMN5FwtKsT75vLFByxjVK0LxAds0wAf/OLQBH/z0seT4zNsfw7zYf0jOs2U/A3Ixvxjjlinv6Jk7Ihoh/l4OD/0yq4C31qQ49bkmrzqsmZirpVor1VKVYDBCRHWa1lZWrZ0gABDs6wmrIKDMKuh6KNq/Z0ybEKzY86eLPpGjRt4eGN+vvfyLZ84grn044mwO/RXYBHeM/gxFHteTZ0PsZlbkZkDcTPKFxsRj45fvlxQZE2dMgny9JEtZRlwsKMGuP7LRu32Y9slUbzEYIaI6S0+RMLVER9GlqyV4+PPfdBUYk3vPUH8v3cstznjg5paOQZLVCgwaBGzYIDk87NFZOGzp4HCPSwUl+Dk5E4O7WBRrmmhVM7V/XZwxeaJ3uL4PoiAplcFIQ8etvURUJyltZRUfkAnJGRXHxERHc5D6ko3ctXresyoDEQDob7+E9O235VtybQKROXEPIHzSj7KBCFAehD27bD/WHzqnWADOKPEeP+gsQKZ9J2qoGIwQUZ2jVVEVKC8SZtsEb2CUBTsm9cM3T/ZEsK98DRGla7XesypJamVkZJT3jHnooYrXSxsF4J3lv+HDPsoVVG29sTpZdReQUQKAnPwSh3oqRsS15axIQ8dghIjqHL0VVWclHpd05nV3M8HNzaS6lVapwJjWe7qaWJR+6rBIuJsAPPgg0Ly55Jyxo/+N9uOW4/OD/9N935z8qmkAeE+35tonyQj286yoQ0INF3NGiKjO0btdd87mVMzZnCrJBdF7rf15eq9zlYpaGWf2AzcNlbx25qHH8bc299eqxY3+kWb0iAh1qDOi5b37buI2XGIwQkR1j9F+I7bN5pztaVKdPU6mDOmEx28MhHvTJg6vlWVl46EFByBUYpbGlQm3tn1p3N1M6B9pdqjAmnu1BG//eASZeUUV15kDvfHWXZ1ZmIwAMBghojpIz3ZdW7bN5ra+3Ndw0zfb99RaqjGhfBvtLRGh2HL8fygqter7UDbvPWrJDLh9/rn0xYQE4M47sTs1u1LLRZYgH0wZEolnlzlf6t6WgPLgybYjb+/2YQ67Y+6MYmEyUsacESKqc9QatykRc0H2nbnoVNM32/fUep+cghL8fOS8oUAEAGLPHELSa/GSQMT68Mjybbx33gmg8stFU4dFYnAXCybEd9R9jRhgmQO9ZV+fvu6o4g4kkViY7O5uLRDXrjEDEZIwHIxs27YNw4YNQ/PmzWEymfDf//5X9fwtW7bAZDI5/Dl27JizYyYi0r1d196Fy4WK18p11LV/z1G92jg9ZiWNigpw7P/uw/IVr0mOx4xfit6dH0fCketl5J1dLnIzAZ+O6F7x2cb3a68YXMiZcd9NeHNoZ9nXtLZEE2kxvEyTn5+Prl27YtSoUfj73/+u+7rjx48jMDCw4ucmTRzXQomIjLDtS7LzVBbmbD6leY34MHemp0lCcgZW/+7aB+7kzV/gmd2rJMeeuec1/HxDLwCAySbfZWCUxfASlWjO8GgM7nI9yHJ3M+Gtuzpj7LV+Mkr3EpN/+0eacevMTbLn2C6DVba0OzVMhoORQYMGYdCgQYbfqGnTpggODjZ8HRE1DHJl3QHttvPi9H+PiFCs3P+XoVwQPT1NxHElpmTii52nK/kpr+t27jj++/WLkmMb292Cp/7+ZnktkWvkHvRaFWVtqVWVVep629jfC3d3a16xQ8bdzYQkjVwV2y3R7BNDRlVbAmv37t1RWFiIyMhIvPHGG+jbt6/iuUVFRSgqup51nZeXVx1DJKIaIldiPdivvDCZ7TZR+werfQAzZUgnjFt2wOEhrZYLYnRcleVTUohtn41G0/yLkuNxYxcjI1B+xtj+Qa8URNgK9vXEqN4RGN+vvepntp8hCvP3BkxA1pUiyXnObokm0qPKgxGLxYIFCxYgJiYGRUVF+Prrr3HHHXdgy5Yt6NOnj+w1M2bMwLRp06p6aERUCyj1SZGrVWG7RReAbF+ap/tEYM3vGZLjZh09Z/SOqzL+uXM5XtzxjeTYxCETsCrqDl3X2z7oxSBizqZTmLXxhMO5uVdLMHvjCdxgbqT5ucUZooTkDLz0/e+yvX6c3RJNpIdJEASn/1szmUz44YcfcM899xi6btiwYTCZTFizZo3s63IzI61atUJubq4k74SI6rYyq4BbZ24yNPNgAhDk54ncghKHQEH8/V+p1X1VjktNpwt/4KfFz0mO/dYqCsMfehdWN3fd91k+OlayBKI1TnFpasekfpqfXyn4sv1Op69L0VwG0/Ne1HDk5eUhKChI8/ldI3VGYmNjsXTpUsXXvb294e2tP8ubiOomZ0qsC5CfNRFfMwGYvi6lUg9FV5V+9ywrQcIX49EuR9pI7vanF+BMiP7y6Uq1T/SWxdfK49Dq9SN+p65eBiMS1UidkQMHDsBiYdU9ooauKvILlHrLGOHsuMyB3nimTwQsQT4YtXc1Tn54ryQQeaP/WIRP+tFwIALIP+hdlcehN6gJ8fd2aks0kRbDMyNXrlzBqVPXt8+lpaXh4MGDCA0NRevWrTF58mSkp6djyZIlAIDZs2cjPDwcnTt3RnFxMZYuXYqVK1di5cqVrvsURFQnVWV+QWUCHWfGNSG+Y3my6KmTmDwkXvLa0SbhGPbYbJS6a/8v19/bHflFZRU/q+W7uCqPw0hQc3e3Foa3RBNpMRyM7N27V7ITZuLEiQCAxx57DF9++SUyMjJw9uzZiteLi4vx0ksvIT09Hb6+vujcuTPWrVuHwYMHu2D4RFSXOVszQ4/KBDpGxlWxw+fGJkBcLLB7t+T1/k/Mxckm+gul5ReVIdTfC/fYba11ZpxKyzv2jAY1erZEExlRqQTW6qI3AYaI6h4xcRLQrpkhClZIYAVcl0ipNa4ne4cjXgwWFn8BPPWU9IQZM7B64CN4fsVBw+8tjlrP0ofSOI3cQ0yEZXIquZre5zd70xBRjVIqzR7i5wk/L8edJsF+nnjw5pYAjPWWsVVmFZCUmo3VB9ORlJqNMqvjI1hpXJYgH8wfGY0pwzojzuMK3N3dpIFI69bA1avAq686PTsjjmba2hTZsekZp5E8DrVeP0xOperAmREiqhXsC5hdzC/GuGXKW03l6omoVRsVyRUyC/X3xDt3R2FwF8fEUrnKsO4QgEGDgA0bpCfv2QPcfLPkWrUZBz3st/MqkR2nweBB7rvR850SKdH7/GYwQkS1jt76GVtf7ot9Zy4a6i2jVsjsmT4RmDxYozPvt98CDz0kPfbaa8C776q+J6B/GcrWRw91w93dWjhxpXNcEdQQiWp1nREiqhtq6sGkd6vpvjMXdSdSqtXSEH22LQ1dW4ZIGspVyMgAmtvNnAQGAunpQKNGivfUU7pdTXVXNGVyKtUEBiNEJKsmp+yrog+K3kJmU1Yn484om86zglA+E/Ldd9ITt24FFFpa2LPt//JTcgaWJJ3RdV2wn6fmThii+oAJrETkQFxasH94i71hEpIzKo7pSQY1Su9sQNblIt3vpzdwyc4vvl4wbd06wM1NGoiMG1ceoPTpY+izizMOgwwEcqN6RXCJhBoEzowQkYSe0uBiO/vElEyZZFB9NTLU3t9qFRDs64lLV+XLvoumrzuKz3ekyc7W2C8xhfnrbzFx8c8MoH2Yw/Hd+04hpltbuMP5maMeEaEwB/ogM089OAr29cD4fu11j5moLmMCKxFJJKVmY/jCXZrnTYjvgNkbT6rmYBhd1pF7wGuRq6chdx9zoA8uF5VIqpvK+VfCJxjx+8+SY4/+Yxq2tY0BUP6Z7upqwYJtabI7fQQAT/QOVw3GEpIzMOZaUquS+SyvTvUAd9MQkVNWH0zXVajLz8sdBcXqD3ag/AFtpHiXM/9Dsi3KlZiSqdh9Vu3ecWcOYfmK1yTHfujcFxOGTARM1wMKrfvYUgvGEpIz8Oqqww5N/4L9PPHefTcxEKF6gbtpiMgpevM19AQiInFZR2nJRs9OFzXi7ppdqdmaS0x+Xu7Itxl7o6IC7J0zEj6lxZLz+778LdLc/GXvo5eYYzN3RHeE+HtLdiWJSa27/shGUmo2AAFxbcMQ264x80SowWEwQkQSru4Xo6eNvd6dLlqS/sjS3BKcX1yGF+7ogCW7zuCZH+fjmd2rpCetXImPAqOQtvFkpccjfn/jlx+AbW6r7YxJ7/Zh6C2Tn0LUkHA3DRFJiKXBXb1+q7abpTIddqX0zSgEHtyL/W8OkAQiWzv2xPqDf6HsnnuxeOdpF42nnP0mG7ldSUQNGWdGiBowpaJmA6MseKJ3OL5w4UNZbfmnsoW9xJyRuHaNMWfzKcXzfEoKsf2zp9Ak/5LkeNzYxcgIbAIsP4ihR85r7uKpLPtdSVyWoYaOwQhRA6W1NbV/pNklwYieNvZaS0MmlCd2XiwokU0gFQA8dEtr3BKufJ9/7lyOF3d8Izk2ccgErIq6Q3Lsx0PVM1uhZ/mKqKHgMg1RA6SnqJkYIKgJ9vWAOVD5HL0dX/V0jZ1x302YL9OdVjRr4wnEztiIoV3Mkus6XfgDp2cOlQQiv7WKQtuXVzsEIjUhM/eqy4vGEdU13NpL1MDobUK3Y1I/vJ9wFJ9tS1O8V7CfJ/51TxRC/L2xMSUTPxxMR07+9SUOV9QZsb9HmVXAnE0nMUslwbR/ZFMcP5OFxbNHo11OuuS1259egDMhjt15a0qovxdy8q/v5GGXXKpPWGeEiGTpL2rWEbM3nlBNZLUvOOaKxnpa99AKpgDgiT2r8eamhZJjb/Qfi6XRQwyNxUhNEVeRK+JGVFexzggRyT7Y9e5cWbzTscKoPTER8/UfknG1uAzmIN9Kd/bV6hqrtg24bfZf2PT5GMmxo03CMeyx2Sh1N/a/uxfuaI9v9/7lki3HRjC5lRoiBiNE9ZTSksdDt7TWdb3eHSUCypvLTfju94r3qMplBrlgyt1ahpVLX0a3jBOS4/eP/wx7/Vs49T4r9vyJN4d2Roi/Fy5cLsS6QxnYkHLeqXvZC/X3lCxn2WNyKzU0TGAlqoeUElQzcgsxa+MJ+Hm5q17vr/G6GmdqaBjpfmvf8O6B3zcg9YO7JYHIzNsfQ/ikH50ORADgfF4Rxi3bj9yrxbi7Wwv0VNkNpEcjb3c8+7d2+OapnpgytLOua1xXf4WoduPMCFE9o6e0ulYp93wDpd7tie/78ve/Y+epbIQ39sMjceHw8pD/3cdI99uE5Ay8tSYFANAi9wJ2zn9C8vpfgU1wx+jPUOTh5fT4bT+H7XLJI3HheHf9UYcCZnpdKSrDp1tS8cOBdDx0Sytd11S2/gpRXcEEVqI6zj4vxCoIePjz32p6WBJuJmD0bRGYPDhSclypOZ5SJ96xS/cDghVffTcVfU4fkFwz7NFZOGzpUCXjXz46FnHtGmPG+hTV3UV6iEmxwX6eyC0oUayrIu5oYs4I1WVMYCVqAORmFYJ9PWtwRPKsAioe4pMHR6LMKmDXH9l4deVh1aZ24qwErv3zkKPbMGfN+5Jz58Q9gA/7PGp4TCYAQb6eunJjxOUSMZhauD3N6RkS8bPZjkOw+xnQrs1CVJ8wGCGqA8TZj8y8QuRcKUKovxfO5hTI1tqo6lLmlbFwexqiWgTjX+uPau5SsU3i9LyQiaTX4iWv53n5IXbcVyjw8jU8DvERP6p3uGq9ElHTAJ+Kv4PI5kH4alQPHMvMw58Xr6KgqBQr96dXjFkPAcClghJMiO+IFXvOSr4LM+uMUAPEYISolpOb/ahu4/u2R4dmjRDWyBsQgAtXijD9xyOqO0LkWAXgn8sPaJ8oEgSEPDESN25LkBx+YMR72N0qytB72xIf+P0jzVix50/VMvTmIB9czC92qG1im9cSH9nMqb+j8DA/7JjUr9K1WYjqOgYjRLWYUk5FdevdPqxii6k4Q3BvtxZY5OLutrYictKxeeEzkmNfRQ/B1P5jK3XfKUM64fHeERUP/KnDIjF26X7F5ZK7ulowbpnj34G4a0jMa+kfaa4IKrIuF2H6uqOaY2ka4KNZV4WoIWAwQlRL6dkVU9Xsm9zJzdK4meB0/oQcn5JCjEv6D57evVJyvMvzK5Dn00h1nIIg4Hxekeosh20gAgADoyyYNzLa4XOZg3wwZUgnTF93VDGvBZAWJ7MN2D7fkaY546LWPJCoIWEwQlRLqVUadRXb2QCtREqlWRpxP96AyKbYkHKhUuOJP/kbpv6yAK1yy4uLbYmIwdt3jMYfjVuqfgZxnABUZzmUkkLtZzbE5RI9fwcZuYWYs+kkno/vWHFMbPznzFiIGiIGI0S1VHUUvBJzJwDIzgyIORFqszTiscoEIi0vZeKtjZ8hPnUPACA9oAnevmM0fu4YB5jUH9j2CZ9KsxxaSaFyyyV6/w5mbTyJG8wBkvurzbgwQZVIisEIUS3lbMEr8dH9dJ8IfLv3L1wqUE4yfX3QjQjyLS93/uH9XQETkHWlyCGRsqpmabxKS/D07pUYn/QdfEqLUeLmjs9vuRcf93oIV720P/+E+I4Y36+9w7KL3CyHM7MQRv4O5HrJuHIsRPUZgxGiWqpHRCgsQT6KeQdKbHeKrD6YAUA5GHnu24OSfA9xh4izMwRG3Ja2H9MS56PtxXMAgF9bd8GU/mORGqavOqkJwIo9ZzG+X3uH1+xnOcRy80YDAvHvQE8gptRLhgmqRNoYjBDVUmLewZil+zXPnRDfEeFhfpIHbVJqNjLz1B+i9omn9jtERK4sS27Oy8KUTQsx5PhOAMAF/xC80+9JeI4YgdSD53TfR28zOSPl5u25u5kwZUgknl2m/XcAsJcMkbMYjBBVMfty7VUxTX+DuZHDg9WZB6NS+3pnZ2lseZSV4om9q/H8zuXwLylEmckNX0UPxazbHsZlb3/MuqEpfjnxP9VlJTn2n9P2+z6dlS9b1Ewp6JIT4q+/zw17yRA5h8EIURWS+6081N8L79wdhcFd1B+CYtKoHnL5Cs4+GOVmHGx3hzij59nDeDtxHm7IOgsA2NuiE6YMGIujTdvajNcbo3pFYNbGE0q3kbX9xP+uXV9enGz6Ou3iY0pBlxy9QV2wnye36hI5icEIURVR2gqbk1+MZ5ftxzN/OTaOs2UkaVRuuaKysxn2D+GBURY83SfCUF+WJlcuYvKWL3Dfkc0AgGzfQLz3t1H4/qY7IJjKu/iaUP4gf/G7g8jMKzI8zu/3p+P7a+XYjdC7zKM3qBvVK4KJqUROYjBCVAX0FCz7bFsaurYMxuAuzWVfN7rMYn++u5sJd3W1ON1l1v4hnJCcgQXb0nQFNu7WMow8sB6Tf/0GPgVXIJhMWNb1Trzf5zHk+gZUnCfW4LhocGnGlbS+Zz1BXbCfp2wiLRHp41bTAyCqj/TOaryxOhllCtMMRpdZlIIHZzT290JMm5CKn41Ug+2efgw/LZ2IaRs/g0/BFSAmBqbffkPjr7+An7mJ5FxzkA+C/Wq2y7DW9ywuUQHSbru23rvvJs6KEFUCZ0aIqoDeWY2c/BLFZQIjyywWu9LieoMH++qgouz8Ytz+weaKHSd6gquQglx8dfIHdEn4vvxAcDDwr38BTz8NuLujv1VAgLcnkv7IAnBtu6sAPLzoN41RVh37702JUgEzvbtyiEgdgxGiKhDWyFv3uUqBi96kURMcS4vrnZkJ8fdCTn6x7Gu2O06KSq3K7y9Y8eDvGzBp61cIKbxcfvDxx4GZM4GmTQHIJ/Ku3P8XBkWZNcdYle7qatE9o8ECZkRVh8s0RFXBQMao2jKB+Bu5JUj+HEuQj+z2VL0zM68P7oRQf/llEvEjvLXmCC4oJJZ2zjyFVV+/jPd+noOQwsvIvyESZVu3IemND7H6XAmSUrOx9vdzGLN0v0NwlJlbiC+qsOuvHmt+z1BcJpMjFjC7u1sLxLVrzECEyEU4M0JUBbLy9e0KCfbV3g5q+xt5Zl4hcq4UIdTfC+YgX8XfzPXmm1wqKEZOvnLyqAAgM68I764/KjkeWHgFL27/GiMP/AR3wYorXr5YFP8YOk6fjLd/PomM3F2a7y1urzW5uOuvEXp20xBR1WMwQlQFdG8H7R2u67droyXFtfJNxBb2wb4Gk0cFAfce2YzXNn+BJgWXAABrOvXBu32fxD1Dbsaz3x02tI1YwPWuv0YM62LG2kOZijkvRrBqKlHNYzBCVElyFVZ7RITCHOijWo49xM8T4/t1qJIx6Wlhf1dXC9796Zjue3b832lMT5yPnn8mAwBSQ1tiSv8xSOsai6lDIjF9nb7dNpVhmzA6pItjHoq/tzusVgFXS5RzXOyxaipRzWMwQmTHSPl2pb4nd3W1oLC0TPE9TABmVPF2ULUW9nd1teiuGeJfVIDndy7HE3tXw0Ow4qqHNz7p9SAW9rgXr97VBY/3jqiyrr5A+TLO473CMSDSLPm7GBhlQb8bm+HrpNPYdjILu9NykF+k/J073Bfl3wWrphLVPAYjRDaMNFVTqrCakVuoWmiskbc7Hry5FYJ8vVBmFao8ILHfARLTJgS3f7BZOxARBAw5tgNvbPoclivZAICfO8Ti7TueRnpQ+S6ZsABvuLuZqnSpQxCAxTtPo6ddUCj3d6WXeBf7XUhEVDMYjBBdoxRcyDVVM1IEzN6VojIs2nkai3aerpY6Ffb5Jkmp2ZoP8IicdExLnI8+pw8AAM4EmzE1/hlsaXeL5DxxiaM6ljps+8go/V3pZWZ9EKJahcEIEdSDC7mmaq5aljDSPdZVElMyFV/zKSnEuKT/4OndK+FdVooid0/Mi70f83rejyLP67VT7Jc4XNHVV4u486VHRKjTgeCjcW0wKMrC+iBEtQzrjBBBu0iYbVM1wHU7MMQH6rS1KYbqXTgrITlDsbZH/MnfkLhoHP6Z9C28y0qxJSIGA56ci9m3PiwJRIDycXdrFYxdf2RXLDVplUx3hQuXCysVCA6KsrA+CFEtxJkRIugPLsTzXLksobd7bGWJsz/2Wl7KxFsbP0N86h4AQHpAE7x9x2j83DGuPHtUwU/JmfgpORPBfp54776bKhJmX111GJeqqPFd0wAfpwNBvaXfiaj6cWaECPqDC/E8cVnClb9fV3W9C/sZBa/SEoz/dQU2LnoW8al7UOLmjnk970f8U/Pw8w29VAMRW5cKSjBm6X4kJGegf6QZPh7G/rcivova25lwPZhwNhBksipR7cWZESLoLxIm/matVsfDWVWdBGob7NyWth/TEuej7cVzAIBfW3fBlP5jkRrWyun7T1ubggBvT2QqlI5XIiaTWq3As8sc+/DY73wxmp9iO3NDRLUTgxGq9/TUDdFTJMz+N2u1Tq53dbVgze8ZunIbqqveRdMAH5jzsjBl00IMOb4TAHDBPwTv9HsSazrdrnsmRElGbuG1jrzaxvdthw7NAhz+Pua7yddFsd35ojcQDPbzxKheERjfrz1nRIhqOZMgOFOMuXrl5eUhKCgIubm5CAwMrOnhUB1ipG6I3vPtg5uYNiHYd+aiQ7AjnpeYkqnZEG5+Ve+mKSmBddYsFE6ZCr/iQpSZ3PBV9FDMuu1hXPb2B3A9KBIEAefzipya7Rnftz3mbD6led7y0bGK+TF6i87J/V2F+nvi3m4tEG9XII2Iaobe5zeDEaq3lGpRiI8npe20ag9Do8FNmVXArTM3qc6QhPh5Yu8b/avuwbl1KzBuHHDkCABgb4tOeHPAWKQ0bVtxiu13AgBjl5Yvlxj9n8PXT/TAKysPaS537ZjUDwB0V7pVYqRaLhFVPwYj1KBpBQG2D0W9Dy9ngpuk1GwMX6jdwVZtpsBpmZnAyy8DS5eW/xwWBrz/PhJiBmDaumOqAZWz1U3Ngd64u1tzLLhWgVZuuUsMeIwEdURUN+l9fjNnhOqdMquAL3em6a4boicIMFoUTWR0y7BLlJYC8+YBb7wB5OWV54I8/TTwr38BoaEYCKB/VHPVGQX7MvKnswowa+MJzbc+n1eEBdvS8HSfCIecGTH3A4DuSrdE1DAwGKF6xehv9GIQoDXdb6Qomm1wY3TLcKXt2gWMHQscPFj+c0xMeWByi7SMu32JeDm25yQkZyDYz1OzfogYmK35PQNbX+7rkEsDALfO3GQ4qCOi+s1wnZFt27Zh2LBhaN68OUwmE/773/9qXrN161bExMTAx8cHbdu2xfz5850ZK5EqcRnFyNJC0wAfJCRn4NaZmzB84S48v+Ighi/chVtnbkJCckbFec7OcGjVI7Gtn1EpWVnA6NFAXFx5IBIcDHz6KfDbbw6BiFHi96q3kJkYmO07cxFx7Rrj7m4tKqqeGq10S0QNg+FgJD8/H127dsWcOXN0nZ+WlobBgwfjtttuw4EDB/Daa6/hueeew8qVKw0PlkiJ0cZ1YhBwMb9INoARlwwSkjNQZhWQdVlf7Qz7GQ61Mumu6BxbVlqG1Hdnobh9B+Dzz8sPPv44cPx4+QyJu7tT9624fyUaAsoFcDWybEVEtZ7hZZpBgwZh0KBBus+fP38+WrdujdmzZwMAOnXqhL179+LDDz/E3//+d6NvTyTLSL8S8bE/ZUgkpq9TzwN5ddVhvLUmBZl56vcWE2KtVgGrD6ZLlnoGRlnwdJ8ILNyeBtt0cZMJGH1bhNP5Eb9+9zMCX3oBUX8eAwAcbRKO2fc+j3v/+SAGNm3q1D3tVaYPTNblIofvotqXrYioTqjynJGkpCQMGDBAcuzOO+/EokWLUFJSAk9Pz6oeAjUARn6TFhMpg3y9NJcMypcm1JcnxMJbV0vK8PCi3yqOW2wSNhdsS3MIeqxC+fHurUOMBSSXLuHM2Ano+e0SuAtWXPHyxaxbH8aXMcNgdXPHBoUkUGe2wTo7Q2ECMH3d0Yqfxe+if6TZUKVbImoYqjwYyczMRLNmzSTHmjVrhtLSUmRlZcFicfyfcFFREYqKrk+L5+XlVfUwqY7T+5v0lCGd8HjvCLi7mbD6YLpL3jvI1wOXrpY65FRk5hZizNL9CPbzVF3m0J2wKQjA119DePlltLlwAQCwplMfvNP3SVwIkCajvv5DMvrd2Axe1/rEGK2PInJ2hsL+82Zc+y4+HRFtuNItEdV/1dIoz2RXZlosbWJ/XDRjxgwEBQVV/GnVyvl+GdQw6E0UFQMRwHVLAXmFpbLHxQetWuKn7oTN5GTgb38DHnsMpgsXkBraEiMefAfP3fWKQyACANn5xYidsREJyRmKib32eTFJqdlYfTAdSanZKLOWj97VDQHHL98Pq1XAvJHRMAdJv39zkA+39RI1UFU+M2I2m5GZmSk5duHCBXh4eKBxY/mthZMnT8bEiRMrfs7Ly2NA0kDpXVpwpreM0YZrSqwuKBuouBxy+TIwbRowezZQVgb4+iLlyedxt09PlLirL3Hm5Jdg7NL9CFKYmRGPTV51GG+tOSJpcGc7ayJ+r65gFYBnlx3A/JHR2DGpH6unEhGAaghG4uLisHbtWsmxDRs24Oabb1bMF/H29oa3t3dVD41qOaNLC0qN6+wbrYmqovOusxxmaQQB+M9/gIkTgfRry0n33APMno3c0kYo0VHVFbDNe1F2Ueb168sq3TG4S3PZ77UyxKUpl1edJaI6yXA5+CtXruDUqfJGWN27d8e///1v9O3bF6GhoWjdujUmT56M9PR0LFmyBED51t6oqCg888wzGD16NJKSkjBmzBgsX75c924aloNveJztKwPob2Rn+14OAUygNwpLrcgtKKnSIEW2LP2JE8D48UBiYvnPbdsCn3wCDB5c8flueXcjcvKLq3Bk5dxMwJzh0RjcxSJp/Pfd3r9wpUi6PNXI28PhmJoqKYFPRLVKlfWm2bJlC/r27etw/LHHHsOXX36Jxx9/HKdPn8aWLVsqXtu6dSsmTJiAI0eOoHnz5pg0aRLGjBnj8g9D9YMr+8ooBRrDe7RGeJi/pDKo/ZJBYkqm0w3jlMat1KtlYJQFKCgoL9n+wQdAcTHg7Q28+iowaRLg6yu511trkvHlr2dcMCp97LsKl1kF7ErNRtIfWQDKK7XeEh6K2z/YrHv25KOHuuHubi2qaMREVBuwUR7VWa5qLqc0u2JPbeknITkDr/2QXOlZiEFRZhw4e1GSlyEGRa1D/dDo5/Xo9cl0+Gf8Vf7iwIHlsyHt28veb9H2PyRbZ6uaxUDwN0ZnfglnRojqP73P72rZTUNkhN7aFj8lZ0h2ftgyUjnUdleJvYFRFkwZ0knXeNTHmgnAhAnxHfHRQ90wIb4jABP+8/12BDxwH/q/9gz8M/5CekATvDpiKhLeX6QYiABAaCP9OVUhfpWv5aO3RPvAKAs+HRENtZjFZSXwiajeYDBCtY7eLbdLks7I9pEBjFUOFQOWaWtTZAMbc5CvwzFnnM8rxOyNJ5ByLhefJhzB/QlfYuOiZxGfugclbu6Y1/N+xD81Dyta3YKx3xyQDY4qxhSof1vyjPtuuhb8VI7eIHFwFwvmDO8u+xpriRCRHAYjVOsYrW0hN7NhtHKoWr0PvePRel249ufokpX46YtxeGn7UviUFuPX1l0wcNQczPzb47jqdT3IUAqOAOBifpHq7ANQnnz66YjuGBhlwfh+7dEswEtjhOqM1GUZ3KU55o+MhoW1RIhIhyrf2ktklNEtt3Kt550taCYXxOgZzzN9IrDm9wzV2RhzXhambFqIIcd3lr+Xfwje6fck1nS6vbxRjd1nEoOjHhGhkuTai/lFGLfsgOb3Iu6CAYDElEwUlTmXHuZsifaBURb0jzSzlggRaWIwQrWSUs0QJbYP77h2jZ0uaKYUxCiNxzb59ZWBnTAr8TjmbE6VXOtRVoon9q7G8zuXw7+kEGUmN3wVPRSzbnsYl739VceTmJKJid8dlLynm0k7QBt6kwUlViuSUrM1g5cgXw88cHMrLNye5vBaZZdV3N1MTFIlIk3cTUO1mljb4qfkDCxJ0t7KartdVNxNA2g/vPVuF9aqCGu/E6jn2cN4O3Eebsg6CwDY26ITpgwYi6NN22p+FldxM6lXiRVribi5wan+NURESvQ+vzkzQrWO3AMfgK5gxHZmQ5zNeGtNCjLzlGdXjPz2r/WbvjgjU5qegclbvsB9RzYDALJ9A/He30bh+5vugGDSl6qlFUTopXWP8hLt+1minYhqDIMRqlXkipQF+3ri8V7hMAf64HyesdbzB85exHmVQARQLhdvVJlVwO6TF/Dm6V/Q+8uPEFhcACtMWN7tTrzf5zHk+gYYup8rAhEjWKKdiGoKgxFyCb0N7dQoFSm7dLUEs385CT8v94pkVT2N8GasT8Fn2xzzIER33NgET93WTvdY1T5jQnIGvp/7PSasmo24C38AAA6Z2+ONAc/ikMXYtlpLkA8GR5mxaOdpQ9dVlm3ODRFRdWIwQpWmNJsxqncExvdrr/tBr1WkrKC4DAAQ5Ocpaf4mN7NRXGrFApVABAA2H/8f5o28Wdf41Jr2eV7MRu74F/H5oQ0AgFxvf3xw+2NY1vVOWN3cNe8NAI/EtkZ0m1CYA30qds9UdzACGN8STUTkCgxGqFKUyn9fulqCWRtPYPGvaXjvvps0l0CMFCnz8XDDN0/1RNaVIsVZmNdWHdJMWrUKwNdJp/HkberJpEozNucvFWDrS//CpG1fIfjqZQDAf6Li8d7fHke2f7CuzyK6OTxU0qdFzD1xVZdcvZzdEk1EVBkMRshpZVYBr646rHrOpYISjFlanhypVnPCyG/kmXlFcDOZFJuslVkFrE/O1HWvMzkFqq8rzdh0zjyFdzbMQ/eM4wCAo03CMWXAWOxt2VnX+9qzDwLE2iZ6+7xUlrO1RIiIXIHBCDltzqZTkuUSNa+uOuywq8V226jR38jVgpfdaTkVSzpa2oT6ORyzzQ3JulwkmZ0ILLyCF7d/jZEHfoK7YMUVL1/MuvVhfBkzDGU6l2TsiX1a7HNS+kea8emIaIxfvt8lyaxP3hqBRTtcX0uEiKiyGIyQJqWttp9tS9W48rryoEUauIhl3OddmzUxsiyhFrzonWUxARjRsw2SUrNtqpsWY/o6mUJrgoD7jmzC5M2L0aTgEgBgTac+eKfvk7gQULmEz6nDIpGYkqmYkzJneHc8u+xApd4DAOI7NcMt4SEO7+Oq3URERM5iMEKqlBI3H7y5le7ZByX2ZdzFkutqkwB6lhP0zrJEtwlGv//bohkAdfzfaUxPnI+efyYDAFJDW2JK/zH4NbybrvdR82TvcACQ/dy2wdp8A9VolVy4XIi7u7VgiXYiqnUYjJAipcTNzNxCzP7lpEvew7aMu1ik7NVVh2WXf/QuJ+gpBe/t4YZ9Zy6pjs2/qADP71yOJ/auhodgxVUPb3zS60Es7HEvStw9r5/n5Y784jJdfXTs9buxGV76/nfZ62yDtR2T+lUEEZl5hZj+4xHk5OtbIhOJQRpLtBNRbcOuvSRLbattVdTiEpdWBkZZsO+N/pgQ3wHBvp6Sc/R2fBWTPwH5TromAL5eKvkdgoAhR7fjl8/H4Ok9P8BDsOLnDrGIf2oePo17QBKIAEB+cRme6RMBs12HWrXJBhPKZ5hggupsh22wJgYR5kAfQ4GI+F5MTiWi2oozIyTLyFZbV7BdWnF3M+H5+I4Y36+DruUEuZwWtcZ2D93SGrM2npAdR0ROOqYlzkef0+U5GmeCzZga/wy2tLtFcewmAGt+z8DWl/ti35mLkvyTccsce+PYzvBkXSnS9f3Y5sE4UwuEyalEVJsxGCFZ1VX8Si0HRM9yglbBNbn8iB8PnXO4j09JIcYl/QdP714J77JSFLl7Yl7s/ZjX834UeXqrjkGcvdh35qLDeOe5OQZEtgmjSanZqvcWhTW6PobTWerbkW2x0R0R1QUMRkhWdRS/En9PnzKkk1MJlWrl49UKrp3Oypf8HH/yN7y18TO0zLsAANgSEYOp/Z/BmZDmhj6PXAA3MMqimjCqJ78FAF787iDeuqu8hslshVkdW8G+npj7cDRi2zbmjAgR1XoMRkiW1kNSnNGYMqQT3v4xBZl5+pYbbJmDfHBXVwumrztquG29nvLxtgXXxHslJGdg1sby5NuWlzLx1sbPEJ+6BwCQHtAEb98xGj93jANMxh/gSgGc2gyPmN8ydul+1QTY83lFGLN0P4L9PHXl7Lz395vQu32YrnETEdU0JrCSLLUkUNuch8FdmmPbK/0Q6u+l+97j+7bD8tGxmDIkEgu2pTnkpohbWhOSMxTvYSSnZdraFJRZBZRZBby15gi8Skvwz53LsXHRs4hP3YMSN3fM63k/4p+ah59v6GU4EKlsgqiY39IsUHk2SgxA9BSZmxDfgcsyRFSncGaEFCklgdoXydp35iJy8ot137dDswD0iAjFrTM3aW5p7R9pll1mMJLTIu5GsVoFdPg9CdMS56PtxfK8kV9bd8GU/mORGtZK9/1suap66cAoCwK8PfHwot+cvocoPMy/0vcgIqpODEZIlVbOA2A82bVpgI/mzIbtlla5JQ6jOS2/bTuIzh9Ow9cp28vH7B+Cd/o9iTWdbndqSUbkyuqlWfnGl7rksNkdEdU1DEZIk9auFiMPP3E5Y83BdF3ni4GO/fbdmDYhusrHe5SV4om9qzH638vhX1KIMpMbvooeilm3PYzL3s7PIDwa1waDoiwurV5a2SCCze6IqK5iMEKGKQUGWjtCgOt9WKasPqLrvbIuF+HttUfw34PnJEtBlmvJrwu2pSm+Z8+zhzF9wzx0zD4LANjbohOmDBiLo03b6npvNYOiLC6vYiomDTtT34XN7oioLjMJglAVBTVdKi8vD0FBQcjNzUVgYGBND6dBU+pVIwYGgPyOkGA/T7x3300AgDFL9+t6LzcTNLvVDu1iwY5TWZLEziZXLmLyli9w35HNAIBs30C897dR+P6mOyCYKpezLc4+7JjUr0oe+gnJGbq/H1usJ0JEtZHe5zeDEdJNqa6H+Eh+uk8E1vyeIS1A5ueJUb3KC5ABQO/3NiEzz7UF1ZoFeKNHRAh+PXYBQ5NW48VtXyOwuABWkwn777wfT3a8D7m+AS55LxOgqyS9LbkKsWqBzEcbT1RsP1YzZUgnhAV4s9kdEdVaep/fXKapZ4w++IzcV61XjVJJdNv3T0rNdnkgAgDnLxfhr5+24Medn8OSdgwAcCWqK3w/X4CSsHbIXbjLJe8T6u+Jf93rWERNjdJMktosxvh+HbB895+K35U4O/N47wgGIERULzAYqUecefDppXf3y9dJpxV/W6+KEvMhBbmYtPUrPHRoAwAg19sfn935JLq8/TIGdm2JHlZBdz6LmlB/L+yafAe8PPQv86h1PR67dL/iDIu7mwlv3VVeCA1Q7mvDQISI6gsGI/WEkQefM7MnegOJ6euOVvyzfSDkyi2nJsGKB3/fgElbv0JI4WUAwH+i4vHe3x5Hjn8wsPx3zHN3x8Aoi64Kp1oeiws3FIjomUlSq6Oit8YLEVF9wGCkHjDy4EtMyXRq9sSZQMI+EOoREQpzoE+ll2o6Z57COxvmoXvGcQDA0SbhmDJgLPa27Fxxju1nVnqwh/p7Iidfu6IpAOReLd/JozeQq2wdFUBfjRciovqAwUg9oPfBN2fTKczeeMLwsgGgv6Gb/fvazwC8dVek5m6RYD9P5BaUOLxPYOEVvLj9a4w88BPcBSuuePli1q0P48uYYShzc5f9zOLDXu7BHtMmBLEzftFVPXb1wXO4uU0opq/TF8jpnUnSOk9P52IiorqOvWnqAb0PvsU75WtyiMfEHi5y1HrVqLENCoDy3/bnj4xGsJ+nw7nBfp6YPzK6Ygvw9ZsIuC/5F/yycAwe278O7oIVazr1Qb+n5mPRLfc4BCK2bL8b8cF+d7cWiGvXGF4ebnjn7ihdnyM7vxjPLtuvu4+O3pkkVkslIuLMSJ0mLhmcPH9F1/mXriovSehdNpBb7tAjMSWz4r7iLMWuP7KRlJoNQEBc2zDEtrve7v7pPhH4bFsaOv7vNKYnzkfPP5MBAKmhLTGl/xj8Gt5N1/tqPewHd7Hgjv1N8Mux/xn6PCKl/A+9XY9ZLZWIiMFIraM3J0Fu54wSE4AgX0/VYESkNctiu9yx89T/MGdzquY9AeCLnafRIyK0YjnD3c2E3u3DZNvcl1kFbNyditc2LcYTe1fDQ7Diqoc3Pun1IBb2uBcl7o6zKvaMPOyfuq2d08EIIB/IiTNJcomz3BFDRCTFYKQW0bs1V2nnjBzxUTeqd7iuQlp6lg3E5Q4jW3W1do9UEASkzvkC3/zfKzBfKV/a+blDLN6+42mkBzXV/V6A+sPeNugLa+QNc6A3zucVVWr7r/33wR0xRET6MBipJfRuzVXbOSNHfPD1jzRjxZ4/nVo2UJqtMZLvoGcZCCdOAOPHo2NiIgDgTLAZU+OfwZZ2t8ieHuzniQdvbulQ9VXrYS8X9AX7eVYsudjPYuj9ruW+D+6IISLSxmCkFjCyNVdr54xocFQzPBIXIXnwObNsoDZb0z/SbHiHjexsSkEB8K9/AR98ABQXw+rljY9vuQ/zet6PIk9vxXvNHR6N3h3C8OKAG/F10mmcySlAm1A/PKJSE0Qp6Mu91tsmyM9T0ucmxN8Td3dtjtW/Z+BifrFT+R/cEUNEpI67aWpYmVXAlzvTdNek0Ls08mtqTsXDMSk1G6sPpiPI1wtzR0TDHCT9Dd4c5CO7rVd8cCvtIElMyazYYaOXw+zBmjVAZCTw7rtAcTEwcCCEw4fx7ZAnUawQiJhQHhDFtmuMhOQM3P7BZkxfdxRLks5g+rqjuP2DzQ67W4Dy7/qtNUdUgz5fT3d882RPPNE7HKH+XsjJL8HiX88gRyUQAZj/QURUGZwZqUFGklABVEzz63Hpagk++eUkluw6I6mjYQnywZQhnRDi7626bKB3tmbHpH6YNzIab605gsy8Is1xXcy/dk5aGvDcc8CPP5b/3KoVMHs2cO+9cDeZMHVYI81ZnMSUTEPl1udsOqU6RjHo23vmIhbvPK1rtof5H0RElceuvTXESBKqaPnoWPSICEXM9ERdO2OU6Ok8m5SajeE6GswtHx2LuHaNUWYV8MkvJzH7F/Uk2db+btgi7IHbjBlAYSHg4QG8+CLKXn8Duy8USQIktWqx/SPNuHXmJsVATlw62TGpH9zdTEhIztAstiYK1th5FOrviSlDO8McyPwPIiI17NpbixlNQhVdzC+Cu5sJo3pHYNbGE06/vwDtnS16l4N2nsqqCCBu0dhG2+ePfZi2cT7cLl5bQunbF5g7FwllwZg25zfZoGPHpH6yyZ9Jqdm6l7Z6RIRi2toUXZ8HUK/HAgA5+SUwB/owD4SIyEUYjNQAvUmo9qasPoL4SDPG92uPxb+mSRItjdLa2aJ3OWjO5lMV/xzsK1//w5yXhSmbFmLI8Z0AgMKwpvD5aBYwfDjWH87As8scZyyUllrKrAKSUrPxk0xOiJwLlwsNfd9asyK29yUiItdgAmsNcPZBlp1fjNgZG5GYkulYMt3JcYgP99UH05GUml1RDl6sIGpkAcL+Ie5RVoqnf1uJXz4fgyHHd6LM5IYvYu7CocRdwIgRWH84E+OXH5C9l1yJ+oTkDNw6cxOGL9yFJUlndI2paYCPoe97VO9w3fclIiLX4MxIDajMgywnv6RixmC+TEEtvb/ZA8DprAKHvAvbImviVmBn9Dx7GNM3zEPH7LMAgL0tOuHNAWNxsUMktka1wUcbT2gWYROXWnalZuNyUYnhHJtgX09YBQFhjZS3B9uaEN8B4/t1cLoeCxEROYcJrDWgzCrg1pmbDNXnsGWbnAlAklNhFQQ8/Plvmvdo5O2B/KJSh/cXZ0LmjYxG/0gzJn3/O77fn657bE2uXMTkLV/gviObAQDZvoF472+jsPKmOyCY3PB0nwisPpiBzDz9sxVBvp4wmeD0spQ50BuFpVbZTsAii12yqxiEye3k0Ur+JSKicnqf3wxGaojSA88IcSeLLTHQ0cqRCLYr7mXLdO11bw83Xdt1AcDdWoaRB9bjxW1fI7C4AFaYsLzbnXi/z2PI9Q2AJcgHd3W1YME2+c7BVcl2e7DSVmH7AENvaX4iIlLGYKQOMFpnxN5HD3XD3d1ayN5XbUljWBcz1h7KdOo95XRPP4Z3NnyKzhf+AAAcMrfHkddnIHxQ34oZm5g2Ibj9g81Of1Y9fD3dcLXEKvuaCeXVVX083CWzMmoBht6mhUREJI9be+sAsW/JrMTjurvf2grzl8+F6B9pxgvxHbB452lJ/kiovyfeuTsKJVbBJcFISEEuJm39Cg8d2gAAyPX2xwe3P4ZlXe+E8Jc75l0trgiWtLbiuoJSIAKUz4ZcKijBN09Gw83NpCvAYBl3IqLqwWDExYz+Nu3uZkLv9k2cCkbktrrINoHz9cSo3hEY3699RY2OyjAJVjz4+wZM2voVQgovAwD+ExWP9/72OLL9gyuGZlvLpLZshc3KL5KdTSIioprDYMSFnM0zELfRGp05yLoizedQbAJ3tQSzN57ADeZGGBhlwcX8IriZAKsTC3SdM0/hnQ3z0D3jOADgaJNwTBkwFntbdpacZ9+lt7Zsha0t4yAiousYjOgkznhk5l5FTn4xQht5S8qBKwUCSsW7bLm7mTBlSCc8u0y+5oYS2wer3l4yViswbtkBw0mkLXIvYOf8Jyp+zvfyxb9vfRhfxgxDmZu74nUbUzIR164xekSEwhzorTsh1ihLkA8EQcD5vCJuySUiqmMYjOiglmha3nguEtPXKQcCgHb59RCF/A85cg9WrSqj4kzFG6uTVQMRN1N5Imh+cXn+hUmw4qvvpqLP6euB0ppOffBO3ydxIUA7n2LRztO4JSIUA6MsGN6jtWZtEWeJ3YO1musxAZWIqPZhBVYN4oyH0oM+I7cQzy5Tft32vN1pOYqvG82pEB++YvXUnaf+p+s62w6+cqwC0KdjUwDA0KPbkPb+XZJAZE7cA3jurld0BSIisYpqeJi/rvP9PKUzLVrxQ7CfJ/pHmjEwyoJ5I6NhDpIuxZiDfFgbhIioFuPMiApnG9opSby2ZCFHby5DY38vvHtvFADoqifijC5u+Zg3c6jkWJ63P2Kf/RIFXr6G7ycGYno/Y0FJGYDyxNv4Tk01i65dKiipyE0RdyhxSy4RUd3BmREVzja0U7L64LmKPiv29PSCCfX3RNLkOwBAdbZGjuna9aoEAXP++x7GPny75PA/RryHLi9861QgIrpwudBwv5vcqyW6q7/aziyJW3Lv7tYCce0aMxAhIqrlGIyocPV21Oz8YsWlGnc3U8XSi/2j03Ttz7/uvQnubianZmsEAD3ClZM3+53ajdPvD8PQ4zsqjn0VPQThk37EnlZRBt/NUdMAH9XPKMfIZ+QuGSKiusupYOTTTz9FREQEfHx8EBMTg+3btyueu2XLFphMJoc/x44dc3rQ1aUqHnBqAY6enIfKzNYkHDnvcCz4ah5OzxyKL1a+LTne5fkVmNp/rFPvY8uE8iRfMdlW6TO66v5ERFT3GM4Z+fbbb/HCCy/g008/Re/evfHZZ59h0KBBSElJQevWrRWvO378uKQUbJMmTZwbcTVytv6HGq0ARyvnwZWzNTN++hjDr1VPFT36j2nY1jbGJfcXZz8euqU1fjx0ruKz2H7Gn5IzsCTpjO77cZcMEVH9YzgY+fe//40nn3wSTz31FABg9uzZ+PnnnzFv3jzMmDFD8bqmTZsiODjY6YFWlzKrgF1/ZF+rUirggZtb4qNfTum6NtTfCxfziytd50KtDLkrZmvizhzC8hWvSY6t7NwXLw6ZCJhc91AP9vOEAGDWxhMVx2yLwMW1a4zdafqqwU6I74AVe/6UBIZmNq4jIqoXDAUjxcXF2LdvH1599VXJ8QEDBuDXX39VvbZ79+4oLCxEZGQk3njjDfTt21fx3KKiIhQVXS+OlZeXZ2SYTktIzsCrqw47dLP183LH1eIy1RwGsd7IuGVVW+dCnK3JzC00nDfSqKgA+z55GN5l0s8XM35pRRn3yrAE+eChW1ojPMwPp7PyZWuK2BaB6x9pxvLdZ3Xdd3y/DhjfrwN3yRAR1UOGgpGsrCyUlZWhWbNmkuPNmjVDZqZ84zWLxYIFCxYgJiYGRUVF+Prrr3HHHXdgy5Yt6NOnj+w1M2bMwLRp04wMrdISkjMwZul+2dcKiss0r3/ollYosVrxQnxHLN99VtIZ1uhv8Gr9bcQkUKWxKnlt0yI8vecHybFn7nkNP9/Qy9B95Iz7WzuE+nsh1N8L5iDfig69cmyrwQb4eOqqyPrQLa0rPj8b1xER1T9O1Rkx2U3lC4LgcEx0ww034IYbbqj4OS4uDn/++Sc+/PBDxWBk8uTJmDhxYsXPeXl5aNWqlTND1aXMKuCtNSma5wX7esDH013yAA32K98uazsLYA70xoT4DggP8zf8G7ye/jb9I80I9vN0mMGR0z39GH5Y+pLkWGL7Hhh93xSXLcl889tZu+7AXqrF1cRqsHob9rUOdX5LMRER1X6GgpGwsDC4u7s7zIJcuHDBYbZETWxsLJYuXar4ure3N7y99ZdHr6zdaTmSmQwll66W4puHY+BmKu9CezqrALM3nnBYLjmfV4TZG09i3shoQ7/JK83O2Pe32Z2WoxmI+JQUYvv8p9Ck4JLkeNzYxcgIdG3ysG0gAmhXeb1O30LT9HVH4evlztwQIqJ6ytDWXi8vL8TExCAxMVFyPDExEb166Z/uP3DgACyW2vNgMbJDJetKEeLaNcbQLs2xYs9ZzX40SkXO7JVZBby66rDsa/b30xrvczuX49i/75cEIhOHTED4pB8lgYi/t7vuAmRVIa5tmK4iaBfzizF26X4kJGdUy7iIiKh6GV6mmThxIh555BHcfPPNiIuLw4IFC3D27FmMGTMGQPkSS3p6OpYsWQKgfLdNeHg4OnfujOLiYixduhQrV67EypUrXftJKsHIDhXxXL2N6cQy5VrmbDqlOtthez+l8Xa68Ad+Wvyc5NhvraIw/KF3YbXrrBvi54l374nCuGUHHBJuq5q4syi2XWNMHRaJsRr5L7Z5JmrNBomIqG4yHIw8+OCDyM7Oxttvv42MjAxERUVh/fr1aNOmDQAgIyMDZ89e3yFRXFyMl156Cenp6fD19UXnzp2xbt06DB482HWfopLK29v7aC7VmAO9K7bm6p1N0XNemVXA4p1puu83tEtzyY4ar9IS/LR4PNrlSEun3/70ApwJae5wDxOAGffdVF6A7FpFV9vAysfTDYUlVl3jMcp+Z5FYBO21Hw4jJ19fMMYkViKi+sUkCEJ1/lLslLy8PAQFBSE3N1dSOM2V1HbTiObbdH5NSs3G8IW7NO+7fHSs5sNT770AYHzf9ujdPgwX84swbtkBjNqzGm9uWig5543+Y7E0egiA8o63titF9smwgOPunR2n/oe5m1N1jUdLqL+nJMiQe38A+OFAOiZ8e1Dzfh891A13d2vhkrEREVHV0vv8ZtfeawZGWTB/ZLRsnZFgP0+8d20mQaRV78NIkTMjOStzNp/CnM2n0LP4f0ibNUry2tEm4Rj93Hz8I7YtPgrzQ9MAH8S0CcG+MxdVa3PYF1mzCoJLghFzoDe2vdJP8/3Lz9W3VMYeNERE9Q+DERtimXLbCqxxbcMQK9P5Vaz3MXapY5EzXPt5yhB9Rc6MPGDdrWVYufQldMuQFhTb9P0v8O3WFVtlHvZioKFWv8RWbNvGurcOqxneozW8PNx0Lau4MrgjIqK6hcGIHXc3E3q3D0Pv9mGa54r5DvY5F6Lp61Lg5gbNLal6c1Ye+H0D3k/4WHJs7p1PYcz6BeinEfToqV8icncz4b37bjJcWM1eeJi/7nPVgjv2oCEiqt+c6tpL1w2MsmDKkE6yr4n1QbS2pCamZKKwVLnKa8vc8zg9c6gkEPkrsAlueHEVPuh2D3an5ajePyE5A2OX7ncImNTGJy5b2S+fWIJ8MCG+g+r7iYwuqejpWkxERPUPZ0YqqcwqYPq6o7Kv6dmSKgYKsksTghVLvn0Tt505KDk+7NFZOGy5HhCo5ZyUWQVMW5uiWA9FbXxKHYQBYMWeP6tkSUWrazEREdU/DEZ0UMu1qEy9EbVAYVjKVnyy9gPJsbmx/8AHtz/mcK7aDERl66EodRCuyiUVta7FRERU/zAY0aCVa1GZeiNygUKTKznYM/dRybE8b3/EPvslCrykPVr0zEDoHd/OU1kVwZaeHThK+TJGmwISERExGFGhtIRi2ytGb16E7XniTMu6w+eunyAImLv6PQw5vlNy3T9GvIc9raIcSqbrnYHQO745m09V/LNSbRL75ZP+kWYuqRARUaUxGFGgN9di68t9DW1JlZtp6XdqN75Y+bbkuq+ih2Bq/7EAgKFdLNh35qJTMxBaW2bl2LfTycwtxJil+x22+yrtxiEiIjKiwQcjSvkgenMt9p25qDt/wn6mJfhqHg5+PMLh3l2eX4E8n0YVP+87cxFbX+6rq3iYPa16KHqI19jXHbHvJkxEROSMBh2MqOWDFJXq681y4XIh7u7WQjN/wn6mZcZPH2P4oQ2Sez36j2nY1jbG4T3EoMdoUqcYaBWVWvFCfEcs331Ws5aJEWxgR0RErtBggxGtfJAXDNbS0NqSKs60xJ35HctXvC65x6rOfTFxyETApPwwN1IyHpAPtMyB3pgQ3wHhYf44ef4y5rig5Dsb2BERUWU1yGBETz7I8t1nYQ70wfk8/bU01Lak5mT8D8c/vAfeZaWS4zHjlyLbP1hzzEYKiCkFWufzijB740nMGxmN3u2buCQYERkNloiIiEQNsgKrnnyQzLwiDO/RWjHHQoD8TpYyq4Ck1GysPpiOpNRslFkF4KWXMOS2TpJA5Jl7XkP4pB91BSKh/p6IaROi/cGgHWgB5csqMW1CEOznqeueerCBHREROatBzozo/S0+92qx6utWu7QS+6WR7unH8MPSlyTnbGx3C576+5uqSzL2cvJLcPsHm3XtXNGbeLtHo4S8XmxgR0REldUgZ0b0/hb/34PnVF8fv3w/1h8qP8e2/4tPSSH2fDLSIRDZkrgHo++faigQEWn1uRFnZH7S6IMjSvojS3dX3pBrMyjO1johIiJS0yBnRvS0qw/x90ROvsbMiAA8u+wAPgUwfd1RCACe27kcE3d8IznvxSET8GvvIdjRLwbzzJmKXX4tQT64XFiKK0WlDq/ZLrHY71yRS1bVpi94GN+3HSb0vwGJKY7jZrVVIiJyhQYZjGjV3hAA3NutBRbtPK3rfm+sTkaztONIWvyc5PhvraIw/KF3YXVzB67tOLHddZOZexU5+cUIbeQNc6APrFYBDy/6TfW9MnILMWfTSTwf3xGAeqM9JW4moGdEKOZs1j63d/smcHczsYEdERFVmQYZjADXe6tM/O53FBSXSV4zmYDzl4t03certATfz3oabS9Kl3Ruf3oBzoQ0lxwTc1WUdt2sPpiu6z1nbTyJG8wB6B9pVkxWVWMVgH1ntHNGLAZ2CxERETmrwQYjAHDg7EWHQAQABAH48VAGvDzcUKxS/OyJPavx5qaFkmNv9B+LpdFDZM/XylU5nVWgY9Tlpq1NQYCPp8Glmeu+/PWM5jlThjAXhIiIql6DDUaKS61YuD1N8xw5bbP/wqbPx0iOHW0SjmGPzUapu/xXaj/LYC8hOQOzN57QGPV1GbmFSErN1n2+vUtXtZNXQ/y9nL4/ERGRXg02GPk66bRDQzgt7tYyrFz6ErplnJQc7//EXJxs0kb12oduaa04y6BWG0Sd8StMAILsGt4pYSEzIiKqDg1yay8AnMnRvyQCAA/+/jNSP7hbEojMvP0xhE/6UTMQAYDwMD/F17Rqgyhxd3ODJch4sbFRvSJ0ncdCZkREVB0abDDSJlQ5OLDVMvc8Ts8cipkJn1Qc+yuwCW54cRXmxf4D90e31HUftXwQZ2cgPv7lJO7qqn9bbbCfJ+aNjMb4fu1hCfJR3NxrgvayEhERkas02GDkkbhwqOVmmgQrvl7xBnbMf1JyfNijs3Dr2MUo8vCCJcgH/7rvJtUHu2j2xhOKBcucnYEQAKz5PQODo8y6zv/kwe4YGGWp2NoMsJAZERHVvAYbjHh5uGH0bfLLFcNStiLt/btw25mDFcfmxv4D4ZN+xGFLeTdfE8of2F4ebpg6LFJX9sa0tSnlvWrsiEXYnJGRW4j1yZm6znVzvx5ciFubzXbvaw7ywbyR0SxkRkRE1abBJrACwOTBkfgjKx+JKRcAAE2u5GDP3Ecl5+R5+SF23Fco8PKtOBbo44H37+9S8cAeGGXBhPgOmLVRmthqS+wJszstx6FWhzhTMWbpfhd9MnlZV6S1U1jIjIiIaoMGHYwUl1qx78wlQBAwd/V7GHJ8p+T1B0a8h92tohyuu7tbc4eZg/Awf13vqZQfMjDKgid7h+uu+uoMueUgFjIjIqKa1mCXaRKSMxA7YyO6/74dp98fJglEvooegvBJP8oGIgAQ3tgx8NCb96F2XnykvtwPZzAhlYiIaqsGOTMi9nMZdGwHPl39nuS1Ls+vQJ5PI9XrmwY6BhR6mu+Z7QKCMqsgWSKJaRMCS5CP01VV1TAhlYiIaqsGF4zYFhiLyLneC+axf0zD1rYxuu7x3PID8HQ3SZZq1Jrv2e5QAYCk1GxsTMnEDwfTkZN/vfiYOdAHzYONBSNyjf5suZmAOcO7MyGViIhqLZMgCMbLeFazvLw8BAUFITc3F4GBgZW6V1JqNoYv3FX+gyCg+eX/4VxAk/LueDqJsxw7JvVzmG1ISM7AtLUpkoDCEuRTEYjYv1bVPh0RjcFdGIgQEVH10/v8bnAzI5IEUpMJ5wKbGr6H2s4YpR0qiSmZGLt0vxMF3PWxnyERAyDOiBARUW3X4IIRV5Y411s51fneM/oJAKYM6YSwAG9u0SUiojqlwQUjWommABDg447LhWWa95ILbOSWaUL9PSW5IVUlLMAbd3drUeXvQ0RE5EoNbmuvVil0E4CZ93VxqneLuEvHPiekOgIRgI3tiIiobmpwwQigXQp9cJfmhnu3VMdSjBpzoDfriBARUZ3U4JZpRFql0MWA5a01KcjMuz7TYVZIDN2dllOtu2TsvXVXZ+aIEBFRndRggxFAbyl06VyH0k5ovcmszhp9Wzj+sy8dlwqkSz7Bfp54776buGuGiIjqrAYdjKgR8z/sQ4/zeUUYu3S/Q2fbqszXeLJ3OF4f0hmvDorErj+ykZSaDUBAXNswxLZrzBkRIiKq0xiMyFDL/xBQnjcybW0K+keaKwKBHhGhCPX3Qk5+scvHI/ascXczoXf7MPRuH+by9yAiIqopDTKBVYtW/odt0TORu5sJ93Rr7tJxKO3aISIiqk8YjMjQm/9hf15/F3bdVdq1Q0REVN80+GUa+865PSJCded/2J8nFlRzZleNmwmw2qwLKe3aISIiqm8adDCi1NRuypBOqlVaxUZ59ssntp17AfVuurb3Aso764b4e8tuMyYiIqrPGuwyjVK11MzcQoxbdgB3dS2fkdBb9EykVFDNEuSDZ/pEwKJSaC2uXWPc3a0F4rhDhoiIGhCToFQ4oxbR24JYrzKrgFtnblJcThFnPqYMicT0dY4zJ3qWT+SWf9zdTIrHiYiI6hu9z+8GuUyjd7dMiL8Xdkzq51TwoFRQTV+hNSIiooajQS7T6N0tk5l7lbMYREREVaxBzozo3S0zfd1RSREzvUs0REREpF+DnBkRt+BqzXHYV1PNzC3E2KX7kZCcUXWDIyIiamAaZDAibsEFHHfLqBEzfaetTUGZtdbn/RIREdUJDTIYAZS34Ib6e6peJ1cKnoiIiJzXIHNGRAOjLOgfaZYkqWbmFWLCtwc1r9WbBEtERETqGnQwAjhutU1KzdZ1nd4kWCIiIlLXYJdplGglt7KTLhERkWs12GCkzCogKTUbqw+mIyk1uyIhVS25lZ10iYiIXK9BLtMoNcgTa4iIya3257CTLhERkes5NTPy6aefIiIiAj4+PoiJicH27dtVz9+6dStiYmLg4+ODtm3bYv78+U4N1hXUGuTZ1hAZGGXBjkn9sHx0LD56qBuWj47Fjkn9GIgQERG5mOFg5Ntvv8ULL7yA119/HQcOHMBtt92GQYMG4ezZs7Lnp6WlYfDgwbjttttw4MABvPbaa3juueewcuXKSg/eqDKrgGlrUyBXIUSuhoiY3MpOukRERFXHcNfenj17Ijo6GvPmzas41qlTJ9xzzz2YMWOGw/mTJk3CmjVrcPTo0YpjY8aMwe+//46kpCRd7+mqrr1JqdkYvnCX5nnLR8eymR0REVEl6X1+G5oZKS4uxr59+zBgwADJ8QEDBuDXX3+VvSYpKcnh/DvvvBN79+5FSUmJ7DVFRUXIy8uT/HEFvbVBWEOEiIio+hgKRrKyslBWVoZmzZpJjjdr1gyZmZmy12RmZsqeX1paiqysLNlrZsyYgaCgoIo/rVq1MjJMRXprg7CGCBERUfVxKoHVZJLmTgiC4HBM63y546LJkycjNze34s+ff/7pzDAdsIYIERFR7WMoGAkLC4O7u7vDLMiFCxccZj9EZrNZ9nwPDw80biyfl+Ht7Y3AwEDJH1dgDREiIqLax1Aw4uXlhZiYGCQmJkqOJyYmolevXrLXxMXFOZy/YcMG3HzzzfD0VG9KVxWUGuSZg3wwb2Q0t+4SERFVM8NFzyZOnIhHHnkEN998M+Li4rBgwQKcPXsWY8aMAVC+xJKeno4lS5YAKN85M2fOHEycOBGjR49GUlISFi1ahOXLl7v2kxgg1yCvR0QoZ0SIiIhqgOFg5MEHH0R2djbefvttZGRkICoqCuvXr0ebNm0AABkZGZKaIxEREVi/fj0mTJiAuXPnonnz5vj444/x97//3XWfwgn2DfKIiIioZhiuM1ITXFVnhIiIiKpPldQZISIiInI1BiNERERUoxiMEBERUY1iMEJEREQ1isEIERER1SgGI0RERFSjGIwQERFRjWIwQkRERDXKcAXWmiDWZcvLy6vhkRAREZFe4nNbq75qnQhGLl++DABo1apVDY+EiIiIjLp8+TKCgoIUX68T5eCtVivOnTuHgIAAmEyua2aXl5eHVq1a4c8//2SZ+SrG77p68HuuHvyeqw+/6+pRVd+zIAi4fPkymjdvDjc35cyQOjEz4ubmhpYtW1bZ/QMDA/kveTXhd109+D1XD37P1YffdfWoiu9ZbUZExARWIiIiqlEMRoiIiKhGNehgxNvbG1OnToW3t3dND6Xe43ddPfg9Vw9+z9WH33X1qOnvuU4ksBIREVH91aBnRoiIiKjmMRghIiKiGsVghIiIiGoUgxEiIiKqUfU+GPn0008REREBHx8fxMTEYPv27arnb926FTExMfDx8UHbtm0xf/78ahpp3Wbke161ahX69++PJk2aIDAwEHFxcfj555+rcbR1m9F/p0U7d+6Eh4cHunXrVrUDrCeMfs9FRUV4/fXX0aZNG3h7e6Ndu3b44osvqmm0dZfR7/mbb75B165d4efnB4vFglGjRiE7O7uaRls3bdu2DcOGDUPz5s1hMpnw3//+V/Oaan8WCvXYihUrBE9PT2HhwoVCSkqK8Pzzzwv+/v7CmTNnZM//448/BD8/P+H5558XUlJShIULFwqenp7C999/X80jr1uMfs/PP/+8MHPmTGH37t3CiRMnhMmTJwuenp7C/v37q3nkdY/R71p06dIloW3btsKAAQOErl27Vs9g6zBnvue77rpL6Nmzp5CYmCikpaUJv/32m7Bz585qHHXdY/R73r59u+Dm5iZ89NFHwh9//CFs375d6Ny5s3DPPfdU88jrlvXr1wuvv/66sHLlSgGA8MMPP6ieXxPPwnodjPTo0UMYM2aM5NiNN94ovPrqq7Lnv/LKK8KNN94oOfbMM88IsbGxVTbG+sDo9ywnMjJSmDZtmquHVu84+10/+OCDwhtvvCFMnTqVwYgORr/nn376SQgKChKys7OrY3j1htHv+YMPPhDatm0rOfbxxx8LLVu2rLIx1jd6gpGaeBbW22Wa4uJi7Nu3DwMGDJAcHzBgAH799VfZa5KSkhzOv/POO7F3716UlJRU2VjrMme+Z3tWqxWXL19GaGhoVQyx3nD2u168eDFSU1MxderUqh5iveDM97xmzRrcfPPNeP/999GiRQt07NgRL730Eq5evVodQ66TnPmee/Xqhb/++gvr16+HIAg4f/48vv/+ewwZMqQ6htxg1MSzsE40ynNGVlYWysrK0KxZM8nxZs2aITMzU/aazMxM2fNLS0uRlZUFi8VSZeOtq5z5nu393//9H/Lz8/HAAw9UxRDrDWe+65MnT+LVV1/F9u3b4eFRb/9zdylnvuc//vgDO3bsgI+PD3744QdkZWXh2WefRU5ODvNGFDjzPffq1QvffPMNHnzwQRQWFqK0tBR33XUXPvnkk+oYcoNRE8/CejszIjKZTJKfBUFwOKZ1vtxxkjL6PYuWL1+Ot956C99++y2aNm1aVcOrV/R+12VlZRgxYgSmTZuGjh07Vtfw6g0j/05brVaYTCZ888036NGjBwYPHox///vf+PLLLzk7osHI95ySkoLnnnsOb775Jvbt24eEhASkpaVhzJgx1THUBqW6n4X19lelsLAwuLu7O0TYFy5ccIj4RGazWfZ8Dw8PNG7cuMrGWpc58z2Lvv32Wzz55JP4z3/+g/j4+KocZr1g9Lu+fPky9u7diwMHDmD8+PEAyh+agiDAw8MDGzZsQL9+/apl7HWJM/9OWywWtGjRQtIqvVOnThAEAX/99Rc6dOhQpWOui5z5nmfMmIHevXvj5ZdfBgB06dIF/v7+uO222/DOO+9w9tpFauJZWG9nRry8vBATE4PExETJ8cTERPTq1Uv2mri4OIfzN2zYgJtvvhmenp5VNta6zJnvGSifEXn88cexbNkyrvfqZPS7DgwMxOHDh3Hw4MGKP2PGjMENN9yAgwcPomfPntU19DrFmX+ne/fujXPnzuHKlSsVx06cOAE3Nze0bNmySsdbVznzPRcUFMDNTfrYcnd3B3D9N3eqvBp5FlZZamwtIG4bW7RokZCSkiK88MILgr+/v3D69GlBEATh1VdfFR555JGK88XtTBMmTBBSUlKERYsWcWuvDka/52XLlgkeHh7C3LlzhYyMjIo/ly5dqqmPUGcY/a7tcTeNPka/58uXLwstW7YU7r//fuHIkSPC1q1bhQ4dOghPPfVUTX2EOsHo97x48WLBw8ND+PTTT4XU1FRhx44dws033yz06NGjpj5CnXD58mXhwIEDwoEDBwQAwr///W/hwIEDFVuoa8OzsF4HI4IgCHPnzhXatGkjeHl5CdHR0cLWrVsrXnvssceE22+/XXL+li1bhO7duwteXl5CeHi4MG/evGoecd1k5Hu+/fbbBQAOfx577LHqH3gdZPTfaVsMRvQz+j0fPXpUiI+PF3x9fYWWLVsKEydOFAoKCqp51HWP0e/5448/FiIjIwVfX1/BYrEIDz/8sPDXX39V86jrls2bN6v+P7c2PAtNgsC5LSIiIqo59TZnhIiIiOoGBiNERERUoxiMEBERUY1iMEJEREQ1isEIERER1SgGI0RERFSjGIwQERFRjWIwQkRERDWKwQgRERHVKAYjREREVKMYjBAREVGNYjBCRERENer/Af2YjmtpIvqFAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x,y)\n",
    "plt.plot(x,y_pred,c='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fe6cc3",
   "metadata": {},
   "source": [
    "## Ablation Studies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9600128f",
   "metadata": {},
   "source": [
    "### BOSTON   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c5794b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = keras.datasets.boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "eb6dfa56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13) (102, 13) (404,) (102,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,x_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7cabcf",
   "metadata": {},
   "source": [
    "###### NORMALIZING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "763a4d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = x_train.mean()\n",
    "x_train = x_train-mean\n",
    "std = x_train.std()\n",
    "x_train = x_train/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "50fc381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test - mean\n",
    "x_test = x_test/std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780e8637",
   "metadata": {},
   "source": [
    "###### MODEL - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3e7a3ccc",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 [==============================] - 1s 17ms/step - loss: 342.5477 - val_loss: 123.6979\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 97.8486 - val_loss: 95.0899\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 83.2447 - val_loss: 77.6845\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 72.2228 - val_loss: 69.0100\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 71.7563 - val_loss: 69.7155\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 69.7097 - val_loss: 70.7962\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.5063 - val_loss: 62.1471\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.7462 - val_loss: 61.9634\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.4854 - val_loss: 64.8519\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.4010 - val_loss: 64.8080\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.1261 - val_loss: 63.8506\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.9091 - val_loss: 64.7577\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.6499 - val_loss: 58.9841\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.2598 - val_loss: 69.4234\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.5122 - val_loss: 58.5471\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.0636 - val_loss: 62.7957\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 64.0045 - val_loss: 62.5052\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.1279 - val_loss: 64.1286\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 60.3646 - val_loss: 57.2260\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.0324 - val_loss: 57.0700\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 59.9341 - val_loss: 57.4553\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.1984 - val_loss: 56.7570\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 59.4441 - val_loss: 59.7302\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.0356 - val_loss: 56.6360\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 59.2386 - val_loss: 56.6090\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 60.0045 - val_loss: 61.9909\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 60.9215 - val_loss: 78.4816\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 70.8555 - val_loss: 87.9911\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 61.6738 - val_loss: 57.3080\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.1820 - val_loss: 60.6553\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 60.2175 - val_loss: 55.4994\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 61.8861 - val_loss: 63.0210\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 60.1995 - val_loss: 59.8539\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 59.0472 - val_loss: 55.0931\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 57.8204 - val_loss: 56.2730\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 57.4974 - val_loss: 60.8028\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 59.2801 - val_loss: 59.1772\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.5186 - val_loss: 64.1670\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.0633 - val_loss: 55.1446\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 57.1005 - val_loss: 55.9398\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 58.2079 - val_loss: 59.7042\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.6060 - val_loss: 54.9170\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 58.1439 - val_loss: 61.6990\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.5678 - val_loss: 60.0841\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 57.9160 - val_loss: 71.7945\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.3514 - val_loss: 54.8274\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 57.6404 - val_loss: 61.7236\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 58.7653 - val_loss: 63.3404\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 61.4736 - val_loss: 54.1927\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 57.2920 - val_loss: 69.2206\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 61.5476 - val_loss: 56.6884\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 60.9544 - val_loss: 55.2289\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 54.2295 - val_loss: 54.7750\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 58.0663 - val_loss: 58.8956\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 59.9827 - val_loss: 58.8770\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 57.0490 - val_loss: 54.5090\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.5515 - val_loss: 56.8124\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.3719 - val_loss: 56.8560\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 57.8010 - val_loss: 54.2689\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.4023 - val_loss: 53.8202\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 57.9460 - val_loss: 54.4942\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.9162 - val_loss: 60.0913\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 58.1541 - val_loss: 54.4928\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.7339 - val_loss: 55.7077\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 54.8255 - val_loss: 55.3616\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 59.0846 - val_loss: 54.9240\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 59.1487 - val_loss: 54.7618\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 56.3205 - val_loss: 60.9065\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 58.1097 - val_loss: 54.9647\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 59.1873 - val_loss: 56.9026\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 55.1118 - val_loss: 52.7821\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 60.3238 - val_loss: 56.1384\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 58.5891 - val_loss: 60.6363\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 56.5762 - val_loss: 74.3895\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 57.7881 - val_loss: 52.2256\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 60.6089 - val_loss: 65.0241\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 56.6525 - val_loss: 68.9891\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 56.9110 - val_loss: 53.5274\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 53.4500 - val_loss: 55.1911\n",
      "Epoch 80/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 57.8962 - val_loss: 52.3482\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 56.3927 - val_loss: 59.3116\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 54.5871 - val_loss: 60.3091\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 55.1797 - val_loss: 53.0330\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 59.9719 - val_loss: 63.3332\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.9702 - val_loss: 56.1084\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 54.5758 - val_loss: 55.5625\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 51.8995 - val_loss: 55.6039\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.2720 - val_loss: 55.6172\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.8603 - val_loss: 68.7837\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.8201 - val_loss: 51.8349\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.8877 - val_loss: 57.4220\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 57.0852 - val_loss: 55.0149\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 54.3362 - val_loss: 52.6936\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.9463 - val_loss: 53.2099\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 59.9733 - val_loss: 54.2133\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 55.9336 - val_loss: 55.4829\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 52.1974 - val_loss: 53.2099\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 54.4320 - val_loss: 128.9925\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 60.8873 - val_loss: 52.1211\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 53.2556 - val_loss: 52.3958\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 55.7207 - val_loss: 54.0074\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 73.1569 - val_loss: 92.8647\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 58.9870 - val_loss: 54.7883\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 55.8617 - val_loss: 64.2015\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 57.4266 - val_loss: 54.7851\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 51.9523 - val_loss: 52.2657\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 51.2272 - val_loss: 50.7414\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 54.9046 - val_loss: 68.3151\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 52.0908 - val_loss: 56.0259\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 55.1204 - val_loss: 54.5629\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 53.7385 - val_loss: 59.2778\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 51.0776 - val_loss: 54.5667\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 56.5625 - val_loss: 51.1454\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 52.5819 - val_loss: 55.7964\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 52.0842 - val_loss: 53.7806\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 57.4583 - val_loss: 97.7086\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 54.2876 - val_loss: 52.1541\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 54.2265 - val_loss: 55.3392\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 57.6457 - val_loss: 66.3908\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 51.9765 - val_loss: 69.3189\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 51.1446 - val_loss: 56.9644\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 50.9039 - val_loss: 55.8585\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 51.1860 - val_loss: 57.0712\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 51.1175 - val_loss: 50.1907\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.6538 - val_loss: 50.9051\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.6296 - val_loss: 54.5369\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 49.5903 - val_loss: 54.8747\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 57.1698 - val_loss: 58.6876\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 62.9755 - val_loss: 49.9650\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 50.9388 - val_loss: 59.0064\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 59.9050 - val_loss: 49.0856\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 55.4188 - val_loss: 52.4399\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 51.0902 - val_loss: 72.4892\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 51.9736 - val_loss: 49.0939\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 52.8083 - val_loss: 49.3833\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 51.0092 - val_loss: 48.9392\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 58.5674 - val_loss: 55.3418\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 53.5607 - val_loss: 86.2673\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 52.3952 - val_loss: 51.1984\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 52.3770 - val_loss: 52.2101\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 54.0663 - val_loss: 53.2811\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 52.1849 - val_loss: 49.6423\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 49.0277 - val_loss: 52.3068\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 51.4050 - val_loss: 49.7339\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 57.6829 - val_loss: 50.9518\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 49.7522 - val_loss: 64.9713\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 52.6653 - val_loss: 49.0512\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 48.3928 - val_loss: 49.5685\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.6213 - val_loss: 48.3651\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 52.7629 - val_loss: 65.4806\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 53.6677 - val_loss: 78.5125\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 54.2936 - val_loss: 71.9202\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 53.3242 - val_loss: 51.6755\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 52.5310 - val_loss: 69.8131\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 56.3138 - val_loss: 48.8149\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 46.7129 - val_loss: 53.7097\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 55.4556 - val_loss: 90.2781\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 59.8060 - val_loss: 49.0616\n",
      "Epoch 159/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 7ms/step - loss: 49.4357 - val_loss: 58.6981\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 48.8775 - val_loss: 48.0652\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 48.4443 - val_loss: 54.6317\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 49.0850 - val_loss: 69.1826\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 48.5422 - val_loss: 58.4557\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.3161 - val_loss: 55.2624\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 48.5401 - val_loss: 71.2924\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 48.4593 - val_loss: 56.6973\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 54.3826 - val_loss: 54.5111\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 50.7672 - val_loss: 49.5127\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 58.0138 - val_loss: 49.5205\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 50.6475 - val_loss: 75.4073\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 48.0857 - val_loss: 47.6385\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 46.8852 - val_loss: 48.1260\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 44.6618 - val_loss: 63.2523\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 44.6486 - val_loss: 47.4615\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 46.9968 - val_loss: 47.6729\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 52.9395 - val_loss: 55.4466\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 55.7986 - val_loss: 53.0791\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 48.7403 - val_loss: 52.5530\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 61.7047 - val_loss: 53.2315\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 48.4114 - val_loss: 51.6392\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 47.8320 - val_loss: 48.4755\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 47.4739 - val_loss: 49.5216\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 55.2420 - val_loss: 47.6693\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 47.3425 - val_loss: 58.8985\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 60.7939 - val_loss: 61.1962\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 48.2321 - val_loss: 46.3884\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 50.1150 - val_loss: 47.5093\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 57.1406 - val_loss: 50.5120\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 49.7483 - val_loss: 82.6450\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 57.5661 - val_loss: 46.8608\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 45.7373 - val_loss: 45.7836\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 51.1568 - val_loss: 50.9760\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 49.2463 - val_loss: 78.9960\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 54.8707 - val_loss: 54.2406\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 48.8777 - val_loss: 53.3227\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 43.9190 - val_loss: 46.3375\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 53.3640 - val_loss: 48.6060\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 47.6910 - val_loss: 45.6860\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 58.5420 - val_loss: 48.4819\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 46.4362 - val_loss: 49.9029\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 48.9350 - val_loss: 71.4476\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 47.4164 - val_loss: 48.7568\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 44.8358 - val_loss: 47.1218\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 44.9384 - val_loss: 46.9491\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 44.2800 - val_loss: 46.5621\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 45.7308 - val_loss: 48.6914\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 49.7037 - val_loss: 45.1242\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 54.5733 - val_loss: 46.5128\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 55.1321 - val_loss: 61.3524\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 50.3158 - val_loss: 49.7611\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.3325 - val_loss: 50.1621\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 45.2484 - val_loss: 56.8094\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 47.8585 - val_loss: 54.3485\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 49.6802 - val_loss: 55.6719\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 44.4714 - val_loss: 46.0290\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 49.9578 - val_loss: 68.4989\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 55.2808 - val_loss: 55.5807\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 50.2391 - val_loss: 68.6028\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 47.7595 - val_loss: 50.0762\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.0576 - val_loss: 47.1097\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 43.6943 - val_loss: 47.2757\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 42.6665 - val_loss: 49.6046\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 46.9957 - val_loss: 44.6578\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 47.1714 - val_loss: 44.5932\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 43.5327 - val_loss: 44.1322\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 41.4057 - val_loss: 43.9732\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 52.4172 - val_loss: 51.1256\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 53.6324 - val_loss: 44.7616\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 45.7317 - val_loss: 73.6605\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 51.0402 - val_loss: 46.0947\n",
      "Epoch 231/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 47.3620 - val_loss: 49.6500\n",
      "Epoch 232/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 45.7955 - val_loss: 48.4006\n",
      "Epoch 233/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 57.3980 - val_loss: 65.6475\n",
      "Epoch 234/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 61.9000 - val_loss: 46.0158\n",
      "Epoch 235/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 46.5052 - val_loss: 58.5539\n",
      "Epoch 236/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 48.4072 - val_loss: 44.8987\n",
      "Epoch 237/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 46.1087 - val_loss: 45.2186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 49.8148 - val_loss: 55.7358\n",
      "Epoch 239/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 46.4314 - val_loss: 44.0276\n",
      "Epoch 240/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 44.5027 - val_loss: 47.9796\n",
      "Epoch 241/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 47.4918 - val_loss: 44.0862\n",
      "Epoch 242/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.7068 - val_loss: 53.0882\n",
      "Epoch 243/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 45.3941 - val_loss: 44.5396\n",
      "Epoch 244/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 40.5369 - val_loss: 42.5870\n",
      "Epoch 245/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 42.0364 - val_loss: 50.5945\n",
      "Epoch 246/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 48.2288 - val_loss: 44.1219\n",
      "Epoch 247/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 56.0811 - val_loss: 51.4523\n",
      "Epoch 248/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 56.0699 - val_loss: 67.3604\n",
      "Epoch 249/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 57.6800 - val_loss: 63.9796\n",
      "Epoch 250/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 49.1921 - val_loss: 54.0069\n",
      "Epoch 251/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 49.4602 - val_loss: 44.9481\n",
      "Epoch 252/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.9034 - val_loss: 51.0297\n",
      "Epoch 253/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 47.9155 - val_loss: 42.8962\n",
      "Epoch 254/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 47.8924 - val_loss: 43.8299\n",
      "Epoch 255/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 49.0447 - val_loss: 96.6196\n",
      "Epoch 256/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 47.3640 - val_loss: 50.4779\n",
      "Epoch 257/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 50.8957 - val_loss: 62.8010\n",
      "Epoch 258/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 48.1689 - val_loss: 43.5566\n",
      "Epoch 259/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 48.9315 - val_loss: 48.4782\n",
      "Epoch 260/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 51.3032 - val_loss: 43.9441\n",
      "Epoch 261/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 50.0659 - val_loss: 81.5584\n",
      "Epoch 262/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 44.6846 - val_loss: 48.4532\n",
      "Epoch 263/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 44.8900 - val_loss: 42.9647\n",
      "Epoch 264/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 45.0198 - val_loss: 59.7233\n",
      "Epoch 265/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 42.3799 - val_loss: 55.3556\n",
      "Epoch 266/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 53.2517 - val_loss: 45.2572\n",
      "Epoch 267/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 49.8325 - val_loss: 49.8872\n",
      "Epoch 268/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 47.8787 - val_loss: 58.1961\n",
      "Epoch 269/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 50.4091 - val_loss: 50.0619\n",
      "Epoch 270/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 42.4375 - val_loss: 108.1869\n",
      "Epoch 271/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 52.4866 - val_loss: 46.9774\n",
      "Epoch 272/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 46.9895 - val_loss: 52.4774\n",
      "Epoch 273/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 43.5753 - val_loss: 44.7391\n",
      "Epoch 274/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 50.6659 - val_loss: 63.5142\n",
      "Epoch 275/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 44.2133 - val_loss: 48.4892\n",
      "Epoch 276/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 41.0014 - val_loss: 55.4791\n",
      "Epoch 277/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 44.9620 - val_loss: 66.1926\n",
      "Epoch 278/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 57.6566 - val_loss: 42.8925\n",
      "Epoch 279/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 48.6110 - val_loss: 66.2082\n",
      "Epoch 280/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 50.2456 - val_loss: 46.5786\n",
      "Epoch 281/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 47.1604 - val_loss: 52.7855\n",
      "Epoch 282/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 44.8268 - val_loss: 45.5816\n",
      "Epoch 283/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 50.1736 - val_loss: 68.1171\n",
      "Epoch 284/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 43.9836 - val_loss: 42.3908\n",
      "Epoch 285/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 40.4835 - val_loss: 43.0026\n",
      "Epoch 286/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 47.4306 - val_loss: 42.6777\n",
      "Epoch 287/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 39.7314 - val_loss: 41.9300\n",
      "Epoch 288/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 41.2055 - val_loss: 41.8213\n",
      "Epoch 289/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 54.6653 - val_loss: 43.9736\n",
      "Epoch 290/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 44.5489 - val_loss: 44.0123\n",
      "Epoch 291/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 46.4182 - val_loss: 42.5357\n",
      "Epoch 292/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 44.6157 - val_loss: 82.2324\n",
      "Epoch 293/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 51.6865 - val_loss: 42.0663\n",
      "Epoch 294/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 47.9052 - val_loss: 41.0345\n",
      "Epoch 295/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 39.5787 - val_loss: 40.6990\n",
      "Epoch 296/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 47.4940 - val_loss: 63.3135\n",
      "Epoch 297/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 44.5107 - val_loss: 51.2142\n",
      "Epoch 298/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 57.7530 - val_loss: 51.6331\n",
      "Epoch 299/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 51.3478 - val_loss: 65.7587\n",
      "Epoch 300/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 44.7861 - val_loss: 41.5583\n",
      "Epoch 301/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 38.6943 - val_loss: 145.0651\n",
      "Epoch 302/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 59.2445 - val_loss: 52.2770\n",
      "Epoch 303/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 45.5277 - val_loss: 41.4595\n",
      "Epoch 304/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.7920 - val_loss: 61.8626\n",
      "Epoch 305/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 44.8171 - val_loss: 41.2805\n",
      "Epoch 306/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 48.6170 - val_loss: 44.0788\n",
      "Epoch 307/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 48.5951 - val_loss: 47.6327\n",
      "Epoch 308/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 41.8156 - val_loss: 54.0273\n",
      "Epoch 309/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 48.5756 - val_loss: 42.0340\n",
      "Epoch 310/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 43.2922 - val_loss: 42.3441\n",
      "Epoch 311/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 42.3216 - val_loss: 44.5448\n",
      "Epoch 312/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 40.9752 - val_loss: 42.1576\n",
      "Epoch 313/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 38.2911 - val_loss: 56.5772\n",
      "Epoch 314/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 50.4302 - val_loss: 76.4711\n",
      "Epoch 315/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 46.2670 - val_loss: 52.4857\n",
      "Epoch 316/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 47.0301 - val_loss: 80.2222\n",
      "Epoch 317/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 51.8241 - val_loss: 42.5248\n",
      "Epoch 318/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 46.3985 - val_loss: 62.2770\n",
      "Epoch 319/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 42.3059 - val_loss: 40.0580\n",
      "Epoch 320/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.7192 - val_loss: 41.0544\n",
      "Epoch 321/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 46.3328 - val_loss: 46.6545\n",
      "Epoch 322/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 41.6910 - val_loss: 40.3515\n",
      "Epoch 323/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 51.8984 - val_loss: 42.0745\n",
      "Epoch 324/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 38.6726 - val_loss: 59.3079\n",
      "Epoch 325/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 49.0690 - val_loss: 54.1160\n",
      "Epoch 326/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 37.8967 - val_loss: 42.6080\n",
      "Epoch 327/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 39.5530 - val_loss: 40.5538\n",
      "Epoch 328/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 46.5156 - val_loss: 52.0000\n",
      "Epoch 329/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 43.0533 - val_loss: 42.0463\n",
      "Epoch 330/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 40.8428 - val_loss: 39.7629\n",
      "Epoch 331/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 48.1436 - val_loss: 48.6692\n",
      "Epoch 332/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 52.2034 - val_loss: 60.7733\n",
      "Epoch 333/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 47.5527 - val_loss: 75.3124\n",
      "Epoch 334/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 41.6940 - val_loss: 51.3688\n",
      "Epoch 335/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 51.3071 - val_loss: 41.8075\n",
      "Epoch 336/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 45.5211 - val_loss: 41.6479\n",
      "Epoch 337/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 41.7636 - val_loss: 40.1695\n",
      "Epoch 338/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 38.5965 - val_loss: 47.3069\n",
      "Epoch 339/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 41.7025 - val_loss: 40.9042\n",
      "Epoch 340/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 37.2515 - val_loss: 79.1837\n",
      "Epoch 341/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 53.0466 - val_loss: 49.5207\n",
      "Epoch 342/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 58.6820 - val_loss: 50.7235\n",
      "Epoch 343/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 40.2402 - val_loss: 46.4835\n",
      "Epoch 344/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 42.6306 - val_loss: 44.1817\n",
      "Epoch 345/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 40.1669 - val_loss: 51.0513\n",
      "Epoch 346/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 42.1284 - val_loss: 100.1498\n",
      "Epoch 347/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 47.7840 - val_loss: 76.3561\n",
      "Epoch 348/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 48.7710 - val_loss: 42.7244\n",
      "Epoch 349/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 48.1260 - val_loss: 40.1637\n",
      "Epoch 350/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 43.4349 - val_loss: 41.8474\n",
      "Epoch 351/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 47.0580 - val_loss: 48.0090\n",
      "Epoch 352/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 38.2441 - val_loss: 40.9386\n",
      "Epoch 353/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 41.7543 - val_loss: 70.4608\n",
      "Epoch 354/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 44.3646 - val_loss: 127.5363\n",
      "Epoch 355/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 49.7654 - val_loss: 39.6999\n",
      "Epoch 356/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 42.5109 - val_loss: 46.6352\n",
      "Epoch 357/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 41.1327 - val_loss: 42.5847\n",
      "Epoch 358/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 44.8932 - val_loss: 39.1288\n",
      "Epoch 359/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 49.6023 - val_loss: 59.4803\n",
      "Epoch 360/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 54.9840 - val_loss: 42.1084\n",
      "Epoch 361/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 37.0856 - val_loss: 46.0029\n",
      "Epoch 362/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 53.4023 - val_loss: 39.9927\n",
      "Epoch 363/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 42.3979 - val_loss: 74.3387\n",
      "Epoch 364/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 49.9381 - val_loss: 46.2930\n",
      "Epoch 365/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 44.5682 - val_loss: 38.9011\n",
      "Epoch 366/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 45.1985 - val_loss: 40.3983\n",
      "Epoch 367/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 35.9707 - val_loss: 52.1701\n",
      "Epoch 368/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 50.1584 - val_loss: 50.0631\n",
      "Epoch 369/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 39.7733 - val_loss: 61.8583\n",
      "Epoch 370/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 42.9624 - val_loss: 52.7812\n",
      "Epoch 371/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 39.1441 - val_loss: 50.1337\n",
      "Epoch 372/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 42.4513 - val_loss: 80.4194\n",
      "Epoch 373/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 40.3740 - val_loss: 51.4639\n",
      "Epoch 374/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.8289 - val_loss: 41.6097\n",
      "Epoch 375/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 45.4464 - val_loss: 80.3085\n",
      "Epoch 376/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 42.6596 - val_loss: 40.3047\n",
      "Epoch 377/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 37.1898 - val_loss: 49.4716\n",
      "Epoch 378/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 48.8478 - val_loss: 85.6409\n",
      "Epoch 379/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 46.8833 - val_loss: 45.7555\n",
      "Epoch 380/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 42.8217 - val_loss: 39.3074\n",
      "Epoch 381/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 45.2467 - val_loss: 58.1494\n",
      "Epoch 382/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 45.9050 - val_loss: 56.1895\n",
      "Epoch 383/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 46.0135 - val_loss: 39.2368\n",
      "Epoch 384/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 51.4658 - val_loss: 49.0284\n",
      "Epoch 385/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 45.9830 - val_loss: 41.7197\n",
      "Epoch 386/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 39.7839 - val_loss: 38.7261\n",
      "Epoch 387/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 40.3163 - val_loss: 38.5729\n",
      "Epoch 388/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 54.9746 - val_loss: 49.0719\n",
      "Epoch 389/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 41.7957 - val_loss: 41.0689\n",
      "Epoch 390/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 44.3433 - val_loss: 39.6870\n",
      "Epoch 391/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 38.3543 - val_loss: 41.6601\n",
      "Epoch 392/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 39.2268 - val_loss: 58.3573\n",
      "Epoch 393/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 42.1010 - val_loss: 41.5629\n",
      "Epoch 394/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 38.0875 - val_loss: 41.7616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 395/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 52.3374 - val_loss: 50.9168\n",
      "Epoch 396/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 58.2112 - val_loss: 44.3303\n",
      "Epoch 397/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 41.7693 - val_loss: 55.6844\n",
      "Epoch 398/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 50.7517 - val_loss: 57.5278\n",
      "Epoch 399/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 45.5008 - val_loss: 43.1666\n",
      "Epoch 400/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 38.1261 - val_loss: 45.7325\n",
      "Epoch 401/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 46.2547 - val_loss: 64.6496\n",
      "Epoch 402/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 47.2014 - val_loss: 56.1430\n",
      "Epoch 403/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 41.2615 - val_loss: 41.5963\n",
      "Epoch 404/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 36.3647 - val_loss: 41.0177\n",
      "Epoch 405/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 45.6347 - val_loss: 38.9810\n",
      "Epoch 406/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 37.1985 - val_loss: 55.3610\n",
      "Epoch 407/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 44.0323 - val_loss: 43.6927\n",
      "Epoch 408/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 36.9359 - val_loss: 41.2280\n",
      "Epoch 409/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 52.2546 - val_loss: 50.0694\n",
      "Epoch 410/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 47.6180 - val_loss: 46.2484\n",
      "Epoch 411/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 38.3938 - val_loss: 37.9898\n",
      "Epoch 412/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 42.6524 - val_loss: 38.6723\n",
      "Epoch 413/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 41.7094 - val_loss: 39.8105\n",
      "Epoch 414/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 36.4365 - val_loss: 37.7437\n",
      "Epoch 415/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 42.6718 - val_loss: 38.8509\n",
      "Epoch 416/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 42.5758 - val_loss: 39.0109\n",
      "Epoch 417/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 44.0248 - val_loss: 38.8197\n",
      "Epoch 418/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 47.7234 - val_loss: 38.4934\n",
      "Epoch 419/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 36.4881 - val_loss: 43.1854\n",
      "Epoch 420/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 34.3795 - val_loss: 38.2919\n",
      "Epoch 421/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 36.8083 - val_loss: 41.9705\n",
      "Epoch 422/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 41.3692 - val_loss: 43.2560\n",
      "Epoch 423/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 46.2591 - val_loss: 37.4948\n",
      "Epoch 424/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 33.6019 - val_loss: 37.6686\n",
      "Epoch 425/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 60.1890 - val_loss: 38.8057\n",
      "Epoch 426/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 39.2710 - val_loss: 46.9196\n",
      "Epoch 427/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 39.3185 - val_loss: 42.4452\n",
      "Epoch 428/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 36.6051 - val_loss: 77.9560\n",
      "Epoch 429/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 50.6580 - val_loss: 66.4413\n",
      "Epoch 430/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 42.3357 - val_loss: 38.7934\n",
      "Epoch 431/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 44.9945 - val_loss: 42.7738\n",
      "Epoch 432/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 36.9502 - val_loss: 37.8619\n",
      "Epoch 433/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 57.7084 - val_loss: 43.5186\n",
      "Epoch 434/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 37.7368 - val_loss: 44.7722\n",
      "Epoch 435/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 35.7293 - val_loss: 45.0218\n",
      "Epoch 436/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 34.8829 - val_loss: 61.5027\n",
      "Epoch 437/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 44.1209 - val_loss: 37.6660\n",
      "Epoch 438/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 46.9124 - val_loss: 53.7427\n",
      "Epoch 439/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 39.3248 - val_loss: 39.2896\n",
      "Epoch 440/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 36.5797 - val_loss: 80.0109\n",
      "Epoch 441/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 45.0696 - val_loss: 52.4879\n",
      "Epoch 442/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 38.8351 - val_loss: 58.6594\n",
      "Epoch 443/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 59.3555 - val_loss: 44.9808\n",
      "Epoch 444/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 45.9501 - val_loss: 39.0872\n",
      "Epoch 445/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 50.1184 - val_loss: 41.8284\n",
      "Epoch 446/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 41.0733 - val_loss: 38.0397\n",
      "Epoch 447/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 47.4904 - val_loss: 42.7278\n",
      "Epoch 448/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 38.1940 - val_loss: 50.6035\n",
      "Epoch 449/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 47.6436 - val_loss: 39.2439\n",
      "Epoch 450/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 38.8449 - val_loss: 37.4554\n",
      "Epoch 451/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 38.8672 - val_loss: 38.0108\n",
      "Epoch 452/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 36.8885 - val_loss: 39.2391\n",
      "Epoch 453/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 42.6488 - val_loss: 44.7589\n",
      "Epoch 454/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 41.6906 - val_loss: 71.4449\n",
      "Epoch 455/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 39.5455 - val_loss: 36.9256\n",
      "Epoch 456/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 40.2980 - val_loss: 47.0108\n",
      "Epoch 457/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 40.4884 - val_loss: 38.4909\n",
      "Epoch 458/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 42.0108 - val_loss: 47.5964\n",
      "Epoch 459/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 39.6840 - val_loss: 49.7927\n",
      "Epoch 460/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 44.7632 - val_loss: 89.4161\n",
      "Epoch 461/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 42.5975 - val_loss: 45.2325\n",
      "Epoch 462/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 48.9296 - val_loss: 38.0674\n",
      "Epoch 463/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 40.1765 - val_loss: 61.2875\n",
      "Epoch 464/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 41.1921 - val_loss: 73.2723\n",
      "Epoch 465/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 50.3819 - val_loss: 52.3851\n",
      "Epoch 466/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 40.2365 - val_loss: 43.2646\n",
      "Epoch 467/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 43.6562 - val_loss: 40.8191\n",
      "Epoch 468/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 45.7181 - val_loss: 40.4710\n",
      "Epoch 469/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 37.3656 - val_loss: 47.9834\n",
      "Epoch 470/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 43.9000 - val_loss: 37.6153\n",
      "Epoch 471/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 45.6949 - val_loss: 46.9663\n",
      "Epoch 472/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 38.6767 - val_loss: 74.0582\n",
      "Epoch 473/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 40.8173 - val_loss: 36.8894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 474/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 39.5339 - val_loss: 49.1427\n",
      "Epoch 475/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 42.1866 - val_loss: 38.9778\n",
      "Epoch 476/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 45.8965 - val_loss: 38.0122\n",
      "Epoch 477/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 49.4714 - val_loss: 38.7632\n",
      "Epoch 478/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 33.4747 - val_loss: 47.2668\n",
      "Epoch 479/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 36.7973 - val_loss: 37.8875\n",
      "Epoch 480/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 37.0346 - val_loss: 52.0035\n",
      "Epoch 481/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 43.5343 - val_loss: 51.1935\n",
      "Epoch 482/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 36.4905 - val_loss: 41.9191\n",
      "Epoch 483/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 47.9119 - val_loss: 38.3801\n",
      "Epoch 484/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 37.2674 - val_loss: 45.7806\n",
      "Epoch 485/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 51.0628 - val_loss: 64.8138\n",
      "Epoch 486/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 39.9855 - val_loss: 37.2825\n",
      "Epoch 487/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 35.9559 - val_loss: 86.5468\n",
      "Epoch 488/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 46.5088 - val_loss: 36.2902\n",
      "Epoch 489/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 37.7856 - val_loss: 39.4254\n",
      "Epoch 490/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 35.1945 - val_loss: 55.0874\n",
      "Epoch 491/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 43.9845 - val_loss: 36.4146\n",
      "Epoch 492/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 41.7416 - val_loss: 52.9339\n",
      "Epoch 493/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 34.6957 - val_loss: 38.5633\n",
      "Epoch 494/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 40.4801 - val_loss: 53.5679\n",
      "Epoch 495/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 36.6080 - val_loss: 38.4828\n",
      "Epoch 496/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 33.0945 - val_loss: 38.4908\n",
      "Epoch 497/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 42.6525 - val_loss: 46.6293\n",
      "Epoch 498/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 43.0298 - val_loss: 56.0099\n",
      "Epoch 499/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 40.3290 - val_loss: 38.4444\n",
      "Epoch 500/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 38.9625 - val_loss: 42.7076\n",
      "Epoch 501/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 45.4904 - val_loss: 37.5667\n",
      "Epoch 502/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 49.0085 - val_loss: 37.0006\n",
      "Epoch 503/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 37.6097 - val_loss: 38.9108\n",
      "Epoch 504/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 34.4671 - val_loss: 63.1105\n",
      "Epoch 505/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 40.5734 - val_loss: 35.8310\n",
      "Epoch 506/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 51.6693 - val_loss: 45.4852\n",
      "Epoch 507/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 32.8326 - val_loss: 36.0881\n",
      "Epoch 508/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 36.8981 - val_loss: 52.3032\n",
      "Epoch 509/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.8459 - val_loss: 39.0096\n",
      "Epoch 510/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 44.7580 - val_loss: 45.7266\n",
      "Epoch 511/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 41.8482 - val_loss: 37.2383\n",
      "Epoch 512/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 35.7770 - val_loss: 43.1934\n",
      "Epoch 513/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 39.8983 - val_loss: 50.0255\n",
      "Epoch 514/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 38.1449 - val_loss: 36.9442\n",
      "Epoch 515/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 40.9185 - val_loss: 41.3421\n",
      "Epoch 516/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 39.6039 - val_loss: 40.8698\n",
      "Epoch 517/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 39.9051 - val_loss: 59.4743\n",
      "Epoch 518/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 43.9493 - val_loss: 37.3201\n",
      "Epoch 519/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 36.6924 - val_loss: 36.8322\n",
      "Epoch 520/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 34.0147 - val_loss: 48.4374\n",
      "Epoch 521/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 41.0869 - val_loss: 50.0793\n",
      "Epoch 522/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 43.9286 - val_loss: 40.8873\n",
      "Epoch 523/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 35.5300 - val_loss: 41.5197\n",
      "Epoch 524/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 39.2534 - val_loss: 37.7079\n",
      "Epoch 525/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 37.6776 - val_loss: 36.3594\n",
      "Epoch 526/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 40.8535 - val_loss: 39.0450\n",
      "Epoch 527/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 33.6093 - val_loss: 35.5781\n",
      "Epoch 528/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 40.9028 - val_loss: 67.1619\n",
      "Epoch 529/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 46.5160 - val_loss: 37.7993\n",
      "Epoch 530/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 40.6476 - val_loss: 36.9035\n",
      "Epoch 531/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 33.9254 - val_loss: 53.2558\n",
      "Epoch 532/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 39.9125 - val_loss: 57.5783\n",
      "Epoch 533/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 35.9265 - val_loss: 37.0730\n",
      "Epoch 534/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 44.0938 - val_loss: 41.5720\n",
      "Epoch 535/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 42.6542 - val_loss: 56.1680\n",
      "Epoch 536/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 35.7043 - val_loss: 36.5020\n",
      "Epoch 537/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 39.6458 - val_loss: 61.3491\n",
      "Epoch 538/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 41.0794 - val_loss: 35.5635\n",
      "Epoch 539/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 35.5628 - val_loss: 36.3372\n",
      "Epoch 540/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 52.1326 - val_loss: 40.2540\n",
      "Epoch 541/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 37.8294 - val_loss: 38.5689\n",
      "Epoch 542/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 42.4178 - val_loss: 37.8072\n",
      "Epoch 543/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 42.7049 - val_loss: 46.5582\n",
      "Epoch 544/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 41.7612 - val_loss: 37.6192\n",
      "Epoch 545/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 38.0954 - val_loss: 41.3010\n",
      "Epoch 546/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 48.5182 - val_loss: 42.9344\n",
      "Epoch 547/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 37.0904 - val_loss: 45.3370\n",
      "Epoch 548/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 32.5174 - val_loss: 39.8644\n",
      "Epoch 549/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 33.5032 - val_loss: 46.6273\n",
      "Epoch 550/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 38.4731 - val_loss: 72.5083\n",
      "Epoch 551/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 37.3068 - val_loss: 59.6333\n",
      "Epoch 552/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 45.7535 - val_loss: 45.1834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 553/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 31.0019 - val_loss: 34.7287\n",
      "Epoch 554/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 36.9340 - val_loss: 38.1890\n",
      "Epoch 555/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 51.4367 - val_loss: 77.4225\n",
      "Epoch 556/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 35.4757 - val_loss: 38.3278\n",
      "Epoch 557/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 41.0770 - val_loss: 42.8035\n",
      "Epoch 558/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 36.9706 - val_loss: 46.7914\n",
      "Epoch 559/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 42.9480 - val_loss: 45.0344\n",
      "Epoch 560/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 32.2498 - val_loss: 36.2343\n",
      "Epoch 561/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 38.9725 - val_loss: 35.8892\n",
      "Epoch 562/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 39.0092 - val_loss: 48.2402\n",
      "Epoch 563/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 38.1414 - val_loss: 37.1026\n",
      "Epoch 564/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 31.3611 - val_loss: 38.7926\n",
      "Epoch 565/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 50.6543 - val_loss: 87.8007\n",
      "Epoch 566/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 41.2211 - val_loss: 42.4342\n",
      "Epoch 567/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 49.3682 - val_loss: 36.5153\n",
      "Epoch 568/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 49.1691 - val_loss: 51.5451\n",
      "Epoch 569/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 34.5821 - val_loss: 35.1860\n",
      "Epoch 570/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 33.9380 - val_loss: 36.6588\n",
      "Epoch 571/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 36.4454 - val_loss: 47.7192\n",
      "Epoch 572/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 34.4637 - val_loss: 40.2421\n",
      "Epoch 573/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 46.4426 - val_loss: 39.4190\n",
      "Epoch 574/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 45.4747 - val_loss: 47.3267\n",
      "Epoch 575/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 43.7709 - val_loss: 39.5998\n",
      "Epoch 576/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 33.0291 - val_loss: 35.1535\n",
      "Epoch 577/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 35.8595 - val_loss: 36.4640\n",
      "Epoch 578/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 47.5321 - val_loss: 38.9526\n",
      "Epoch 579/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 43.6456 - val_loss: 40.4547\n",
      "Epoch 580/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 41.1702 - val_loss: 42.3053\n",
      "Epoch 581/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 36.5147 - val_loss: 88.1338\n",
      "Epoch 582/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 42.6895 - val_loss: 79.3555\n",
      "Epoch 583/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 35.9271 - val_loss: 39.4181\n",
      "Epoch 584/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 35.0797 - val_loss: 50.0752\n",
      "Epoch 585/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 38.0211 - val_loss: 62.1721\n",
      "Epoch 586/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 41.6757 - val_loss: 40.3761\n",
      "Epoch 587/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 39.9068 - val_loss: 45.4034\n",
      "Epoch 588/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 41.5754 - val_loss: 35.3481\n",
      "Epoch 589/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.7526 - val_loss: 35.5358\n",
      "Epoch 590/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 31.9413 - val_loss: 34.9171\n",
      "Epoch 591/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 38.6280 - val_loss: 39.2467\n",
      "Epoch 592/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 41.3888 - val_loss: 35.2327\n",
      "Epoch 593/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 35.7128 - val_loss: 35.0373\n",
      "Epoch 594/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 39.0140 - val_loss: 43.0858\n",
      "Epoch 595/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 39.1097 - val_loss: 36.4173\n",
      "Epoch 596/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 53.1679 - val_loss: 46.5403\n",
      "Epoch 597/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 42.9903 - val_loss: 43.0585\n",
      "Epoch 598/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 53.0724 - val_loss: 40.7398\n",
      "Epoch 599/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 34.2541 - val_loss: 36.7276\n",
      "Epoch 600/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 35.1673 - val_loss: 41.6451\n",
      "Epoch 601/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 33.4391 - val_loss: 41.2145\n",
      "Epoch 602/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 40.9859 - val_loss: 39.1054\n",
      "Epoch 603/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 31.8894 - val_loss: 58.4552\n",
      "Epoch 604/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 47.1352 - val_loss: 35.5209\n",
      "Epoch 605/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.7166 - val_loss: 47.6475\n",
      "Epoch 606/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 43.0551 - val_loss: 35.2219\n",
      "Epoch 607/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 40.6451 - val_loss: 36.3236\n",
      "Epoch 608/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 32.7563 - val_loss: 36.1575\n",
      "Epoch 609/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 31.8039 - val_loss: 35.8547\n",
      "Epoch 610/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 47.4401 - val_loss: 38.6898\n",
      "Epoch 611/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 34.9425 - val_loss: 45.0015\n",
      "Epoch 612/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 32.6457 - val_loss: 39.3325\n",
      "Epoch 613/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 54.9247 - val_loss: 36.2346\n",
      "Epoch 614/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 34.0072 - val_loss: 35.0684\n",
      "Epoch 615/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 54.3841 - val_loss: 39.0315\n",
      "Epoch 616/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 36.7154 - val_loss: 42.2912\n",
      "Epoch 617/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 35.5007 - val_loss: 68.8491\n",
      "Epoch 618/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 38.9884 - val_loss: 37.1679\n",
      "Epoch 619/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 36.6468 - val_loss: 48.7527\n",
      "Epoch 620/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 40.9231 - val_loss: 60.8563\n",
      "Epoch 621/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 36.9816 - val_loss: 43.8483\n",
      "Epoch 622/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 35.2879 - val_loss: 36.4724\n",
      "Epoch 623/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 38.6704 - val_loss: 35.2954\n",
      "Epoch 624/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 32.2932 - val_loss: 35.1660\n",
      "Epoch 625/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 37.7382 - val_loss: 48.9376\n",
      "Epoch 626/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 53.2167 - val_loss: 41.0710\n",
      "Epoch 627/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 35.6081 - val_loss: 35.0180\n",
      "Epoch 628/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 37.2226 - val_loss: 34.9116\n",
      "Epoch 629/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 37.2132 - val_loss: 36.6355\n",
      "Epoch 630/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 38.2807 - val_loss: 49.6072\n",
      "Epoch 631/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 34.1860 - val_loss: 36.3085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 632/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 40.4768 - val_loss: 36.4238\n",
      "Epoch 633/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 32.5967 - val_loss: 38.9258\n",
      "Epoch 634/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 43.5548 - val_loss: 47.6431\n",
      "Epoch 635/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 38.4791 - val_loss: 39.2564\n",
      "Epoch 636/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 40.4697 - val_loss: 51.1361\n",
      "Epoch 637/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.2041 - val_loss: 34.1317\n",
      "Epoch 638/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 32.4169 - val_loss: 43.6611\n",
      "Epoch 639/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 35.9536 - val_loss: 50.8693\n",
      "Epoch 640/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.8799 - val_loss: 34.3673\n",
      "Epoch 641/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 50.1565 - val_loss: 36.9930\n",
      "Epoch 642/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 34.0815 - val_loss: 34.8717\n",
      "Epoch 643/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 36.6775 - val_loss: 35.8061\n",
      "Epoch 644/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 36.5768 - val_loss: 39.3057\n",
      "Epoch 645/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 42.8162 - val_loss: 39.7569\n",
      "Epoch 646/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 33.8109 - val_loss: 47.4749\n",
      "Epoch 647/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 43.5890 - val_loss: 48.1072\n",
      "Epoch 648/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 36.5214 - val_loss: 35.0282\n",
      "Epoch 649/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 50.1042 - val_loss: 40.0517\n",
      "Epoch 650/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 32.3603 - val_loss: 34.6859\n",
      "Epoch 651/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 37.1530 - val_loss: 52.0966\n",
      "Epoch 652/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 36.7778 - val_loss: 37.3435\n",
      "Epoch 653/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 41.9605 - val_loss: 37.5919\n",
      "Epoch 654/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 44.6472 - val_loss: 54.7448\n",
      "Epoch 655/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 38.9203 - val_loss: 44.2536\n",
      "Epoch 656/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 38.2518 - val_loss: 34.8350\n",
      "Epoch 657/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 32.7905 - val_loss: 40.4698\n",
      "Epoch 658/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 39.0333 - val_loss: 35.1769\n",
      "Epoch 659/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 45.6917 - val_loss: 40.4854\n",
      "Epoch 660/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 33.0291 - val_loss: 39.4239\n",
      "Epoch 661/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 34.7883 - val_loss: 55.0771\n",
      "Epoch 662/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 34.2123 - val_loss: 37.3426\n",
      "Epoch 663/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 32.2829 - val_loss: 42.4758\n",
      "Epoch 664/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 38.5770 - val_loss: 48.3533\n",
      "Epoch 665/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 51.5559 - val_loss: 53.0162\n",
      "Epoch 666/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 35.4499 - val_loss: 37.5378\n",
      "Epoch 667/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 36.7387 - val_loss: 56.4613\n",
      "Epoch 668/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 34.5426 - val_loss: 40.5766\n",
      "Epoch 669/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 47.8465 - val_loss: 39.2118\n",
      "Epoch 670/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 42.9514 - val_loss: 81.2172\n",
      "Epoch 671/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 38.9262 - val_loss: 37.0458\n",
      "Epoch 672/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 40.4211 - val_loss: 47.7328\n",
      "Epoch 673/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 41.0878 - val_loss: 45.1369\n",
      "Epoch 674/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 38.2328 - val_loss: 61.6534\n",
      "Epoch 675/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 37.8036 - val_loss: 39.2679\n",
      "Epoch 676/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 33.2209 - val_loss: 62.6671\n",
      "Epoch 677/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 35.1233 - val_loss: 35.9919\n",
      "Epoch 678/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 34.0111 - val_loss: 47.2266\n",
      "Epoch 679/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 50.0903 - val_loss: 41.2144\n",
      "Epoch 680/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 42.6114 - val_loss: 36.4765\n",
      "Epoch 681/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 44.9587 - val_loss: 37.1735\n",
      "Epoch 682/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 44.6785 - val_loss: 49.8413\n",
      "Epoch 683/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 34.6104 - val_loss: 54.4568\n",
      "Epoch 684/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 34.0889 - val_loss: 47.1566\n",
      "Epoch 685/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 38.3189 - val_loss: 36.1627\n",
      "Epoch 686/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 38.1302 - val_loss: 36.1176\n",
      "Epoch 687/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 32.8691 - val_loss: 59.2172\n",
      "Epoch 688/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 33.9350 - val_loss: 97.1602\n",
      "Epoch 689/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 46.2142 - val_loss: 36.7385\n",
      "Epoch 690/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 33.0923 - val_loss: 34.5664\n",
      "Epoch 691/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8637 - val_loss: 36.2456\n",
      "Epoch 692/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 41.3744 - val_loss: 36.2461\n",
      "Epoch 693/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 40.5084 - val_loss: 50.6119\n",
      "Epoch 694/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 35.9989 - val_loss: 62.6540\n",
      "Epoch 695/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 38.9658 - val_loss: 35.4540\n",
      "Epoch 696/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.1189 - val_loss: 35.3396\n",
      "Epoch 697/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 35.2906 - val_loss: 106.3925\n",
      "Epoch 698/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 42.3188 - val_loss: 56.3624\n",
      "Epoch 699/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 42.0551 - val_loss: 36.7307\n",
      "Epoch 700/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 33.6972 - val_loss: 35.2889\n",
      "Epoch 701/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 35.4338 - val_loss: 35.0947\n",
      "Epoch 702/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 43.5715 - val_loss: 41.4752\n",
      "Epoch 703/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 34.9185 - val_loss: 35.6390\n",
      "Epoch 704/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 40.1991 - val_loss: 34.4876\n",
      "Epoch 705/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 33.3595 - val_loss: 34.5646\n",
      "Epoch 706/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 38.8989 - val_loss: 35.1091\n",
      "Epoch 707/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 36.4520 - val_loss: 48.1082\n",
      "Epoch 708/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 38.5063 - val_loss: 35.0297\n",
      "Epoch 709/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 31.3486 - val_loss: 57.4431\n",
      "Epoch 710/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 45.3931 - val_loss: 53.3234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 711/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 34.7407 - val_loss: 39.6815\n",
      "Epoch 712/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 49.4831 - val_loss: 37.5430\n",
      "Epoch 713/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 31.2185 - val_loss: 36.6179\n",
      "Epoch 714/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 32.1655 - val_loss: 39.3813\n",
      "Epoch 715/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.7188 - val_loss: 36.1054\n",
      "Epoch 716/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 36.5187 - val_loss: 34.6142\n",
      "Epoch 717/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 42.9265 - val_loss: 37.5209\n",
      "Epoch 718/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 41.1828 - val_loss: 43.0035\n",
      "Epoch 719/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 41.9318 - val_loss: 58.6141\n",
      "Epoch 720/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 35.6946 - val_loss: 40.3308\n",
      "Epoch 721/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 32.6150 - val_loss: 44.3422\n",
      "Epoch 722/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 37.7295 - val_loss: 41.1441\n",
      "Epoch 723/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 33.3552 - val_loss: 35.6862\n",
      "Epoch 724/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 28.3200 - val_loss: 44.5094\n",
      "Epoch 725/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 43.0224 - val_loss: 36.9202\n",
      "Epoch 726/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 32.0520 - val_loss: 41.4971\n",
      "Epoch 727/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 31.3428 - val_loss: 41.3744\n",
      "Epoch 728/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 28.8490 - val_loss: 50.1134\n",
      "Epoch 729/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 38.6015 - val_loss: 34.8475\n",
      "Epoch 730/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 33.8660 - val_loss: 54.7825\n",
      "Epoch 731/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 31.4412 - val_loss: 45.8438\n",
      "Epoch 732/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 38.3955 - val_loss: 39.9922\n",
      "Epoch 733/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 35.2527 - val_loss: 46.4295\n",
      "Epoch 734/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 42.0010 - val_loss: 38.0703\n",
      "Epoch 735/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 33.9940 - val_loss: 35.6994\n",
      "Epoch 736/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 34.0785 - val_loss: 35.7676\n",
      "Epoch 737/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 36.8488 - val_loss: 38.8213\n",
      "Epoch 738/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 32.4211 - val_loss: 41.2182\n",
      "Epoch 739/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 36.5093 - val_loss: 50.2316\n",
      "Epoch 740/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 37.0037 - val_loss: 52.5725\n",
      "Epoch 741/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 36.8060 - val_loss: 37.6231\n",
      "Epoch 742/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 39.6182 - val_loss: 34.0611\n",
      "Epoch 743/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 31.9811 - val_loss: 42.4716\n",
      "Epoch 744/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 37.3742 - val_loss: 111.3228\n",
      "Epoch 745/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 42.7118 - val_loss: 41.2450\n",
      "Epoch 746/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 38.5764 - val_loss: 50.3073\n",
      "Epoch 747/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 34.5616 - val_loss: 80.3325\n",
      "Epoch 748/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 35.0959 - val_loss: 49.0043\n",
      "Epoch 749/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 41.4802 - val_loss: 50.8153\n",
      "Epoch 750/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 41.4768 - val_loss: 52.4444\n",
      "Epoch 751/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 31.2303 - val_loss: 37.3411\n",
      "Epoch 752/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 36.5430 - val_loss: 52.9497\n",
      "Epoch 753/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.5611 - val_loss: 34.0071\n",
      "Epoch 754/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 46.4076 - val_loss: 36.6997\n",
      "Epoch 755/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 33.3173 - val_loss: 43.7468\n",
      "Epoch 756/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 43.3058 - val_loss: 35.1204\n",
      "Epoch 757/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 47.7436 - val_loss: 36.4416\n",
      "Epoch 758/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 31.3806 - val_loss: 33.9052\n",
      "Epoch 759/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.3213 - val_loss: 46.9894\n",
      "Epoch 760/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 41.5207 - val_loss: 53.9475\n",
      "Epoch 761/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 37.0009 - val_loss: 76.1541\n",
      "Epoch 762/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 34.2440 - val_loss: 40.8993\n",
      "Epoch 763/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 35.8560 - val_loss: 34.4361\n",
      "Epoch 764/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 45.8692 - val_loss: 39.2671\n",
      "Epoch 765/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 34.5419 - val_loss: 39.8513\n",
      "Epoch 766/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 40.4922 - val_loss: 42.8067\n",
      "Epoch 767/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 32.1050 - val_loss: 34.3272\n",
      "Epoch 768/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 37.1802 - val_loss: 105.5295\n",
      "Epoch 769/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 37.4955 - val_loss: 40.1417\n",
      "Epoch 770/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 29.6474 - val_loss: 33.8410\n",
      "Epoch 771/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 38.5932 - val_loss: 55.0854\n",
      "Epoch 772/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 38.3568 - val_loss: 60.5701\n",
      "Epoch 773/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.9114 - val_loss: 41.2497\n",
      "Epoch 774/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 47.5761 - val_loss: 40.5733\n",
      "Epoch 775/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 34.8698 - val_loss: 35.9271\n",
      "Epoch 776/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 31.6566 - val_loss: 36.8873\n",
      "Epoch 777/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 34.6749 - val_loss: 35.8693\n",
      "Epoch 778/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 35.4524 - val_loss: 36.2648\n",
      "Epoch 779/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 33.7446 - val_loss: 49.2267\n",
      "Epoch 780/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 31.5280 - val_loss: 47.7933\n",
      "Epoch 781/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 44.4130 - val_loss: 37.2767\n",
      "Epoch 782/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 39.9200 - val_loss: 40.8481\n",
      "Epoch 783/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 33.8715 - val_loss: 35.7232\n",
      "Epoch 784/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 29.1678 - val_loss: 35.1277\n",
      "Epoch 785/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 35.4160 - val_loss: 37.4290\n",
      "Epoch 786/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 31.0579 - val_loss: 33.5666\n",
      "Epoch 787/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 32.9462 - val_loss: 45.7025\n",
      "Epoch 788/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 31.9026 - val_loss: 65.7177\n",
      "Epoch 789/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 48.0482 - val_loss: 41.5001\n",
      "Epoch 790/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 37.4757 - val_loss: 73.7864\n",
      "Epoch 791/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 40.6133 - val_loss: 90.5245\n",
      "Epoch 792/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 39.8670 - val_loss: 34.8674\n",
      "Epoch 793/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 31.3014 - val_loss: 40.4738\n",
      "Epoch 794/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 33.7213 - val_loss: 152.1839\n",
      "Epoch 795/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 47.4335 - val_loss: 35.1394\n",
      "Epoch 796/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 35.4341 - val_loss: 83.9226\n",
      "Epoch 797/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 39.4499 - val_loss: 35.0084\n",
      "Epoch 798/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 33.0665 - val_loss: 33.6143\n",
      "Epoch 799/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 29.5247 - val_loss: 55.4134\n",
      "Epoch 800/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 36.9707 - val_loss: 58.7045\n",
      "Epoch 801/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 40.7566 - val_loss: 34.5207\n",
      "Epoch 802/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 45.4529 - val_loss: 36.9292\n",
      "Epoch 803/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 32.0759 - val_loss: 37.6052\n",
      "Epoch 804/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 42.1307 - val_loss: 62.4379\n",
      "Epoch 805/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 41.7350 - val_loss: 59.4711\n",
      "Epoch 806/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 35.2167 - val_loss: 81.3834\n",
      "Epoch 807/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 36.7666 - val_loss: 57.7059\n",
      "Epoch 808/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 36.7113 - val_loss: 116.8223\n",
      "Epoch 809/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 46.6125 - val_loss: 98.9136\n",
      "Epoch 810/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 35.2057 - val_loss: 36.2823\n",
      "Epoch 811/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 32.2963 - val_loss: 34.2020\n",
      "Epoch 812/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 37.6639 - val_loss: 54.3739\n",
      "Epoch 813/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 31.6894 - val_loss: 34.8173\n",
      "Epoch 814/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 35.8315 - val_loss: 74.5370\n",
      "Epoch 815/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 34.8903 - val_loss: 49.4547\n",
      "Epoch 816/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 51.7196 - val_loss: 41.3359\n",
      "Epoch 817/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 37.3362 - val_loss: 45.1500\n",
      "Epoch 818/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 33.3634 - val_loss: 43.5908\n",
      "Epoch 819/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 39.2968 - val_loss: 35.8474\n",
      "Epoch 820/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 32.2264 - val_loss: 36.2906\n",
      "Epoch 821/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 37.1822 - val_loss: 40.6972\n",
      "Epoch 822/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 29.9199 - val_loss: 33.7930\n",
      "Epoch 823/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 34.9295 - val_loss: 36.1270\n",
      "Epoch 824/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 41.5073 - val_loss: 35.6478\n",
      "Epoch 825/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 36.2328 - val_loss: 41.5358\n",
      "Epoch 826/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 29.7635 - val_loss: 40.7346\n",
      "Epoch 827/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 38.4160 - val_loss: 34.8015\n",
      "Epoch 828/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 31.4300 - val_loss: 38.5816\n",
      "Epoch 829/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 31.6878 - val_loss: 34.3050\n",
      "Epoch 830/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 28.8755 - val_loss: 35.4951\n",
      "Epoch 831/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 40.5931 - val_loss: 63.1672\n",
      "Epoch 832/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 32.1425 - val_loss: 33.6195\n",
      "Epoch 833/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 40.0972 - val_loss: 52.9576\n",
      "Epoch 834/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 33.5884 - val_loss: 40.5869\n",
      "Epoch 835/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 39.9865 - val_loss: 48.0307\n",
      "Epoch 836/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 41.3974 - val_loss: 42.8915\n",
      "Epoch 837/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 38.7931 - val_loss: 34.9104\n",
      "Epoch 838/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 33.2351 - val_loss: 48.5051\n",
      "Epoch 839/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 37.1999 - val_loss: 34.7063\n",
      "Epoch 840/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 35.6539 - val_loss: 47.3404\n",
      "Epoch 841/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 38.2062 - val_loss: 50.9827\n",
      "Epoch 842/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 37.1288 - val_loss: 125.0814\n",
      "Epoch 843/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 41.8240 - val_loss: 45.6179\n",
      "Epoch 844/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 38.3385 - val_loss: 77.2180\n",
      "Epoch 845/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 35.8372 - val_loss: 37.1034\n",
      "Epoch 846/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 38.1836 - val_loss: 53.9235\n",
      "Epoch 847/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 35.3014 - val_loss: 35.7718\n",
      "Epoch 848/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 49.3176 - val_loss: 46.4747\n",
      "Epoch 849/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 29.9769 - val_loss: 34.4092\n",
      "Epoch 850/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 31.3595 - val_loss: 57.7861\n",
      "Epoch 851/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 38.3311 - val_loss: 156.8654\n",
      "Epoch 852/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 47.1930 - val_loss: 34.6704\n",
      "Epoch 853/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 31.2751 - val_loss: 78.0761\n",
      "Epoch 854/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 37.1312 - val_loss: 40.5717\n",
      "Epoch 855/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 33.3158 - val_loss: 35.4750\n",
      "Epoch 856/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 36.8835 - val_loss: 35.3372\n",
      "Epoch 857/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 34.6208 - val_loss: 66.9363\n",
      "Epoch 858/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 37.3750 - val_loss: 34.1190\n",
      "Epoch 859/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8862 - val_loss: 34.4933\n",
      "Epoch 860/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 47.4606 - val_loss: 35.4547\n",
      "Epoch 861/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 33.5784 - val_loss: 45.5722\n",
      "Epoch 862/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 31.2830 - val_loss: 39.2144\n",
      "Epoch 863/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 46.1498 - val_loss: 58.3159\n",
      "Epoch 864/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 33.9554 - val_loss: 61.1203\n",
      "Epoch 865/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 38.9307 - val_loss: 34.1011\n",
      "Epoch 866/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 28.6382 - val_loss: 33.3402\n",
      "Epoch 867/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 38.9020 - val_loss: 54.9409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 868/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 32.8086 - val_loss: 37.6408\n",
      "Epoch 869/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.4678 - val_loss: 36.2653\n",
      "Epoch 870/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 34.3651 - val_loss: 34.7768\n",
      "Epoch 871/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 39.9210 - val_loss: 55.3496\n",
      "Epoch 872/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 33.9015 - val_loss: 63.9752\n",
      "Epoch 873/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 40.5765 - val_loss: 33.9140\n",
      "Epoch 874/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 37.3698 - val_loss: 44.8934\n",
      "Epoch 875/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 39.6466 - val_loss: 40.0737\n",
      "Epoch 876/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 32.1944 - val_loss: 34.3396\n",
      "Epoch 877/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 38.7889 - val_loss: 35.4780\n",
      "Epoch 878/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 35.4374 - val_loss: 34.5595\n",
      "Epoch 879/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 39.1003 - val_loss: 51.9055\n",
      "Epoch 880/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 32.3345 - val_loss: 39.0631\n",
      "Epoch 881/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 31.5700 - val_loss: 37.5675\n",
      "Epoch 882/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 40.6137 - val_loss: 37.4902\n",
      "Epoch 883/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 37.6618 - val_loss: 34.0410\n",
      "Epoch 884/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 37.9698 - val_loss: 39.7989\n",
      "Epoch 885/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 34.4268 - val_loss: 36.7262\n",
      "Epoch 886/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8006 - val_loss: 48.9095\n",
      "Epoch 887/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 31.0151 - val_loss: 33.2708\n",
      "Epoch 888/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 32.9342 - val_loss: 34.0112\n",
      "Epoch 889/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 33.8745 - val_loss: 39.1378\n",
      "Epoch 890/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 33.5616 - val_loss: 35.2616\n",
      "Epoch 891/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 31.2543 - val_loss: 50.8515\n",
      "Epoch 892/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 40.6804 - val_loss: 66.3400\n",
      "Epoch 893/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 39.8922 - val_loss: 68.7420\n",
      "Epoch 894/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.1472 - val_loss: 40.5761\n",
      "Epoch 895/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 39.3643 - val_loss: 35.1166\n",
      "Epoch 896/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 32.7030 - val_loss: 35.0157\n",
      "Epoch 897/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 43.3427 - val_loss: 36.9184\n",
      "Epoch 898/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 33.8670 - val_loss: 37.9370\n",
      "Epoch 899/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 32.6436 - val_loss: 51.5220\n",
      "Epoch 900/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 46.3848 - val_loss: 35.8758\n",
      "Epoch 901/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 32.2460 - val_loss: 60.0043\n",
      "Epoch 902/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 45.2119 - val_loss: 34.2154\n",
      "Epoch 903/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 32.6639 - val_loss: 39.9173\n",
      "Epoch 904/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 38.1126 - val_loss: 66.7341\n",
      "Epoch 905/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 37.6481 - val_loss: 36.0386\n",
      "Epoch 906/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 39.5923 - val_loss: 40.9746\n",
      "Epoch 907/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 31.4919 - val_loss: 34.8822\n",
      "Epoch 908/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 34.0165 - val_loss: 35.1543\n",
      "Epoch 909/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 39.6297 - val_loss: 79.6634\n",
      "Epoch 910/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 35.8459 - val_loss: 42.7638\n",
      "Epoch 911/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 31.7305 - val_loss: 33.8162\n",
      "Epoch 912/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.4518 - val_loss: 36.1032\n",
      "Epoch 913/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 32.3388 - val_loss: 47.3722\n",
      "Epoch 914/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 38.5076 - val_loss: 94.2832\n",
      "Epoch 915/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 41.9526 - val_loss: 39.4276\n",
      "Epoch 916/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 34.5680 - val_loss: 100.2583\n",
      "Epoch 917/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 40.2206 - val_loss: 49.4742\n",
      "Epoch 918/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 44.0337 - val_loss: 50.2013\n",
      "Epoch 919/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 30.0025 - val_loss: 36.2681\n",
      "Epoch 920/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 37.6940 - val_loss: 34.4041\n",
      "Epoch 921/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 29.5598 - val_loss: 49.9669\n",
      "Epoch 922/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 35.8517 - val_loss: 36.9113\n",
      "Epoch 923/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 44.2026 - val_loss: 42.5021\n",
      "Epoch 924/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.9165 - val_loss: 61.4092\n",
      "Epoch 925/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 44.1508 - val_loss: 37.4006\n",
      "Epoch 926/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 38.2457 - val_loss: 81.6782\n",
      "Epoch 927/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 43.9586 - val_loss: 62.1201\n",
      "Epoch 928/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 42.6434 - val_loss: 38.4792\n",
      "Epoch 929/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 43.1818 - val_loss: 38.1828\n",
      "Epoch 930/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 36.3918 - val_loss: 35.6514\n",
      "Epoch 931/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 28.3959 - val_loss: 45.5150\n",
      "Epoch 932/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 42.8444 - val_loss: 37.7723\n",
      "Epoch 933/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 32.9265 - val_loss: 100.3715\n",
      "Epoch 934/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 35.2304 - val_loss: 34.5007\n",
      "Epoch 935/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 37.7905 - val_loss: 73.4654\n",
      "Epoch 936/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 35.5228 - val_loss: 34.6180\n",
      "Epoch 937/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 29.1943 - val_loss: 106.1883\n",
      "Epoch 938/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 40.4794 - val_loss: 44.8007\n",
      "Epoch 939/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 49.6742 - val_loss: 41.6805\n",
      "Epoch 940/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 37.8488 - val_loss: 36.3778\n",
      "Epoch 941/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.7945 - val_loss: 37.4102\n",
      "Epoch 942/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 32.8937 - val_loss: 62.6674\n",
      "Epoch 943/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 43.0895 - val_loss: 39.2196\n",
      "Epoch 944/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 33.6989 - val_loss: 47.6695\n",
      "Epoch 945/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 33.2502 - val_loss: 33.9662\n",
      "Epoch 946/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 48.6060 - val_loss: 41.2438\n",
      "Epoch 947/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 45.6915 - val_loss: 47.6187\n",
      "Epoch 948/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 38.3488 - val_loss: 56.2809\n",
      "Epoch 949/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 37.7435 - val_loss: 39.5433\n",
      "Epoch 950/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 41.6687 - val_loss: 37.2724\n",
      "Epoch 951/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 40.2546 - val_loss: 38.2487\n",
      "Epoch 952/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 33.2126 - val_loss: 35.4122\n",
      "Epoch 953/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 31.0434 - val_loss: 47.2770\n",
      "Epoch 954/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 36.6940 - val_loss: 33.8801\n",
      "Epoch 955/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 26.6351 - val_loss: 45.5047\n",
      "Epoch 956/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 31.4755 - val_loss: 71.5180\n",
      "Epoch 957/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 42.2506 - val_loss: 50.4442\n",
      "Epoch 958/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 34.3938 - val_loss: 37.9445\n",
      "Epoch 959/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 43.8001 - val_loss: 50.5394\n",
      "Epoch 960/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 41.2226 - val_loss: 41.2127\n",
      "Epoch 961/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 42.9843 - val_loss: 34.9913\n",
      "Epoch 962/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 37.6176 - val_loss: 35.4054\n",
      "Epoch 963/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.7834 - val_loss: 57.5375\n",
      "Epoch 964/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 31.3933 - val_loss: 34.4108\n",
      "Epoch 965/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 34.8195 - val_loss: 52.2918\n",
      "Epoch 966/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 31.1295 - val_loss: 74.1176\n",
      "Epoch 967/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 39.3348 - val_loss: 34.6338\n",
      "Epoch 968/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 43.4765 - val_loss: 40.5962\n",
      "Epoch 969/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 29.9335 - val_loss: 80.4329\n",
      "Epoch 970/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 33.6168 - val_loss: 42.8240\n",
      "Epoch 971/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 38.9003 - val_loss: 39.4274\n",
      "Epoch 972/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 43.5629 - val_loss: 37.2863\n",
      "Epoch 973/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 35.5225 - val_loss: 48.1088\n",
      "Epoch 974/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 28.5981 - val_loss: 37.9555\n",
      "Epoch 975/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 45.9228 - val_loss: 36.2997\n",
      "Epoch 976/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 28.4790 - val_loss: 35.1930\n",
      "Epoch 977/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 31.0444 - val_loss: 51.0659\n",
      "Epoch 978/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 39.8308 - val_loss: 48.7129\n",
      "Epoch 979/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 34.1855 - val_loss: 37.3677\n",
      "Epoch 980/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 57.8091 - val_loss: 47.3147\n",
      "Epoch 981/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 37.8044 - val_loss: 42.5789\n",
      "Epoch 982/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 39.6838 - val_loss: 39.6423\n",
      "Epoch 983/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 36.4847 - val_loss: 47.0336\n",
      "Epoch 984/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 39.5689 - val_loss: 43.7299\n",
      "Epoch 985/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 32.5806 - val_loss: 34.7185\n",
      "Epoch 986/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 32.0280 - val_loss: 34.2899\n",
      "Epoch 987/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 34.4568 - val_loss: 35.5222\n",
      "Epoch 988/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 29.4197 - val_loss: 46.6588\n",
      "Epoch 989/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 45.1841 - val_loss: 37.5640\n",
      "Epoch 990/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.5363 - val_loss: 38.5234\n",
      "Epoch 991/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 42.5124 - val_loss: 35.8980\n",
      "Epoch 992/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 45.4056 - val_loss: 45.9186\n",
      "Epoch 993/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 35.9152 - val_loss: 35.7786\n",
      "Epoch 994/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.1619 - val_loss: 42.8964\n",
      "Epoch 995/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 44.3766 - val_loss: 41.4595\n",
      "Epoch 996/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 34.5149 - val_loss: 42.4927\n",
      "Epoch 997/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 33.2594 - val_loss: 34.4245\n",
      "Epoch 998/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 34.4837 - val_loss: 48.9598\n",
      "Epoch 999/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 49.3363 - val_loss: 39.8112\n",
      "Epoch 1000/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 36.3311 - val_loss: 38.3929\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(256,activation='relu',input_shape=(x_train.shape[1],)))\n",
    "model1.add(Dense(32,activation='relu'))\n",
    "model1.add(Dense(1))\n",
    "\n",
    "opt = keras.optimizers.SGD(learning_rate=0.001)\n",
    "\n",
    "model1.compile (optimizer=opt,loss='MSE')\n",
    "hist1 = model1.fit(x_train,y_train,epochs=1000,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "be5b511e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 612.0408 - val_loss: 634.2659\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 597.5132 - val_loss: 619.5246\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 583.5808 - val_loss: 605.3167\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 570.1252 - val_loss: 591.6021\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 557.1129 - val_loss: 578.2451\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 544.3864 - val_loss: 565.0349\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 531.7666 - val_loss: 552.0160\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 519.3136 - val_loss: 539.2358\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 507.0583 - val_loss: 526.4456\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 494.7681 - val_loss: 513.7014\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 482.5135 - val_loss: 500.9453\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 470.2310 - val_loss: 488.1620\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 457.9117 - val_loss: 475.3271\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 445.5231 - val_loss: 462.4026\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 433.0844 - val_loss: 449.4490\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 420.5765 - val_loss: 436.4897\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 408.0374 - val_loss: 423.4344\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 395.3963 - val_loss: 410.1938\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 382.5780 - val_loss: 396.8937\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 369.6901 - val_loss: 383.4004\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 356.6299 - val_loss: 369.8784\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 343.5421 - val_loss: 356.2573\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 330.3797 - val_loss: 342.7444\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 317.3350 - val_loss: 329.3493\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 304.4021 - val_loss: 316.0809\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 291.6078 - val_loss: 303.0333\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 279.0363 - val_loss: 290.0345\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 266.5343 - val_loss: 277.4539\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 254.4588 - val_loss: 265.2939\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 242.8071 - val_loss: 253.5305\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 231.5433 - val_loss: 242.3385\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 220.8207 - val_loss: 231.6595\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 210.6253 - val_loss: 221.4438\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 200.9026 - val_loss: 211.8742\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 191.7769 - val_loss: 203.0880\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 183.4117 - val_loss: 194.8992\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 175.6245 - val_loss: 187.3368\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 168.4482 - val_loss: 180.5419\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 162.0025 - val_loss: 174.3537\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 156.1311 - val_loss: 168.8661\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 150.9200 - val_loss: 163.8651\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 146.1824 - val_loss: 159.3990\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 141.9221 - val_loss: 155.3969\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 138.1119 - val_loss: 151.8787\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 134.7660 - val_loss: 148.7919\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 131.8123 - val_loss: 146.1511\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 129.2916 - val_loss: 143.7852\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 127.0276 - val_loss: 141.7511\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 125.0895 - val_loss: 139.8752\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 123.2892 - val_loss: 138.2519\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 121.7248 - val_loss: 136.7264\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 120.2428 - val_loss: 135.4538\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 119.0449 - val_loss: 134.2925\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 117.9163 - val_loss: 133.2462\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 116.9209 - val_loss: 132.2853\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 116.0483 - val_loss: 131.3721\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 115.1650 - val_loss: 130.5451\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 114.3825 - val_loss: 129.7905\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 113.6737 - val_loss: 129.0541\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 112.9885 - val_loss: 128.3398\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 112.3668 - val_loss: 127.6570\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 111.7314 - val_loss: 127.0063\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 111.1640 - val_loss: 126.3775\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 110.6156 - val_loss: 125.7538\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 110.0357 - val_loss: 125.1446\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 109.5136 - val_loss: 124.5500\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 109.0046 - val_loss: 123.9683\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 108.5215 - val_loss: 123.3975\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 108.0220 - val_loss: 122.8308\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 107.5243 - val_loss: 122.2707\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 107.0991 - val_loss: 121.7152\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 106.5974 - val_loss: 121.1647\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 106.1463 - val_loss: 120.6133\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 105.6685 - val_loss: 120.0733\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 105.2379 - val_loss: 119.5319\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 104.8075 - val_loss: 119.0190\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 104.3657 - val_loss: 118.4903\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 103.9704 - val_loss: 117.9820\n",
      "Epoch 79/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 7ms/step - loss: 103.5430 - val_loss: 117.4744\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 103.1290 - val_loss: 116.9689\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 102.7190 - val_loss: 116.4742\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 102.3265 - val_loss: 115.9872\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 101.9377 - val_loss: 115.4975\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 101.5484 - val_loss: 115.0109\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 101.1376 - val_loss: 114.5344\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 100.7753 - val_loss: 114.0581\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 100.3638 - val_loss: 113.5852\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 100.0070 - val_loss: 113.1148\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 99.6425 - val_loss: 112.6504\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 99.2626 - val_loss: 112.1994\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 98.9015 - val_loss: 111.7482\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 98.5333 - val_loss: 111.2942\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 98.1935 - val_loss: 110.8434\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 97.8503 - val_loss: 110.3920\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 97.4901 - val_loss: 109.9422\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 97.1577 - val_loss: 109.5068\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 96.7945 - val_loss: 109.0713\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 96.4573 - val_loss: 108.6488\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 96.1154 - val_loss: 108.2206\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 95.7898 - val_loss: 107.7971\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 95.4523 - val_loss: 107.3777\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 95.1358 - val_loss: 106.9668\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 94.8174 - val_loss: 106.5608\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 94.5099 - val_loss: 106.1502\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 94.1608 - val_loss: 105.7381\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 93.8554 - val_loss: 105.3412\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 93.5655 - val_loss: 104.9431\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 93.2654 - val_loss: 104.5525\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 92.9477 - val_loss: 104.1625\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 92.6803 - val_loss: 103.7832\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 92.3670 - val_loss: 103.3851\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 92.0780 - val_loss: 102.9970\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 91.7899 - val_loss: 102.6206\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 91.5339 - val_loss: 102.2426\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 91.2169 - val_loss: 101.8687\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 90.9527 - val_loss: 101.4954\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 90.6642 - val_loss: 101.1321\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 90.3942 - val_loss: 100.7662\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 90.1022 - val_loss: 100.4109\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 89.8492 - val_loss: 100.0564\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 89.5994 - val_loss: 99.7083\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 89.3195 - val_loss: 99.3599\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 89.0635 - val_loss: 99.0080\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 88.8048 - val_loss: 98.6633\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 88.5632 - val_loss: 98.3421\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 88.3228 - val_loss: 98.0059\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 88.1076 - val_loss: 97.6628\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 87.8299 - val_loss: 97.3243\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 87.5563 - val_loss: 97.0003\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 87.3362 - val_loss: 96.6632\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 87.0911 - val_loss: 96.3454\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 86.8513 - val_loss: 96.0290\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 86.6240 - val_loss: 95.7173\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 86.4086 - val_loss: 95.4106\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 86.1801 - val_loss: 95.1029\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 85.9714 - val_loss: 94.7925\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 85.7391 - val_loss: 94.4955\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 85.5143 - val_loss: 94.1975\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 85.3071 - val_loss: 93.9007\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 85.0942 - val_loss: 93.5985\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 84.8735 - val_loss: 93.2979\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 84.6663 - val_loss: 93.0116\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 84.4635 - val_loss: 92.7165\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 84.2659 - val_loss: 92.4288\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 84.0496 - val_loss: 92.1389\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 83.8500 - val_loss: 91.8574\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 83.6474 - val_loss: 91.5841\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 83.4745 - val_loss: 91.3068\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 83.2597 - val_loss: 91.0349\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 83.0775 - val_loss: 90.7646\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 82.8956 - val_loss: 90.4990\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 82.7175 - val_loss: 90.2414\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 82.5185 - val_loss: 89.9791\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 82.3526 - val_loss: 89.7209\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 82.1644 - val_loss: 89.4696\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 82.0056 - val_loss: 89.2030\n",
      "Epoch 157/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 4ms/step - loss: 81.8108 - val_loss: 88.9541\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 81.6402 - val_loss: 88.7035\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 81.4757 - val_loss: 88.4571\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 81.3101 - val_loss: 88.2043\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 81.1407 - val_loss: 87.9656\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 80.9821 - val_loss: 87.7260\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 80.8208 - val_loss: 87.4889\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 80.6459 - val_loss: 87.2559\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 80.4907 - val_loss: 87.0283\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 80.3362 - val_loss: 86.7963\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 80.1832 - val_loss: 86.5673\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 80.0334 - val_loss: 86.3352\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 79.8731 - val_loss: 86.1174\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 79.7455 - val_loss: 85.8891\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 79.5786 - val_loss: 85.6698\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 79.4376 - val_loss: 85.4488\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 79.3051 - val_loss: 85.2332\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 79.1469 - val_loss: 85.0213\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 79.0263 - val_loss: 84.8073\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 78.8801 - val_loss: 84.6019\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 78.7337 - val_loss: 84.3931\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 78.6023 - val_loss: 84.1937\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 78.4575 - val_loss: 83.9845\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 78.3177 - val_loss: 83.7812\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 78.2064 - val_loss: 83.5861\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 78.0663 - val_loss: 83.3832\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 77.9278 - val_loss: 83.1853\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 77.8239 - val_loss: 82.9974\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 77.6845 - val_loss: 82.8010\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 77.5855 - val_loss: 82.6084\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 77.4448 - val_loss: 82.4220\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 77.3237 - val_loss: 82.2257\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 77.1960 - val_loss: 82.0377\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 77.0823 - val_loss: 81.8529\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 76.9647 - val_loss: 81.6695\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 76.8420 - val_loss: 81.4841\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 76.7540 - val_loss: 81.3080\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 76.6306 - val_loss: 81.1398\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 76.5140 - val_loss: 80.9645\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 76.4034 - val_loss: 80.7921\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 76.2985 - val_loss: 80.6262\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 76.1772 - val_loss: 80.4568\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 76.0980 - val_loss: 80.2856\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 76.0031 - val_loss: 80.1221\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 75.8877 - val_loss: 79.9617\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 75.7743 - val_loss: 79.8013\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 75.6777 - val_loss: 79.6444\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 75.5849 - val_loss: 79.4887\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 75.4822 - val_loss: 79.3317\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 75.4030 - val_loss: 79.1808\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 75.3245 - val_loss: 79.0279\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 75.2057 - val_loss: 78.8748\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 75.1410 - val_loss: 78.7244\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 75.0200 - val_loss: 78.5764\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 74.9419 - val_loss: 78.4307\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 74.8543 - val_loss: 78.2831\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 74.7457 - val_loss: 78.1413\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 74.6612 - val_loss: 77.9976\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 74.6000 - val_loss: 77.8619\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 74.4954 - val_loss: 77.7245\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 74.4164 - val_loss: 77.5885\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 74.3397 - val_loss: 77.4470\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 74.2792 - val_loss: 77.3036\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 74.2050 - val_loss: 77.1667\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 74.0782 - val_loss: 77.0344\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 74.0177 - val_loss: 76.9047\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 73.9349 - val_loss: 76.7787\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 73.8826 - val_loss: 76.6560\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 73.7794 - val_loss: 76.5242\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 73.7178 - val_loss: 76.3977\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 73.6371 - val_loss: 76.2694\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 73.5835 - val_loss: 76.1452\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 73.5189 - val_loss: 76.0221\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 73.4167 - val_loss: 75.9016\n",
      "Epoch 231/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 73.3676 - val_loss: 75.7780\n",
      "Epoch 232/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 73.2718 - val_loss: 75.6555\n",
      "Epoch 233/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 73.2376 - val_loss: 75.5359\n",
      "Epoch 234/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 73.1526 - val_loss: 75.4223\n",
      "Epoch 235/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 73.0764 - val_loss: 75.3057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 73.0114 - val_loss: 75.1923\n",
      "Epoch 237/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 72.9443 - val_loss: 75.0745\n",
      "Epoch 238/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 72.8711 - val_loss: 74.9578\n",
      "Epoch 239/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 72.8055 - val_loss: 74.8492\n",
      "Epoch 240/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 72.7730 - val_loss: 74.7371\n",
      "Epoch 241/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 72.6795 - val_loss: 74.6321\n",
      "Epoch 242/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 72.6314 - val_loss: 74.5174\n",
      "Epoch 243/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 72.5646 - val_loss: 74.4090\n",
      "Epoch 244/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 72.5056 - val_loss: 74.2988\n",
      "Epoch 245/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 72.4488 - val_loss: 74.1869\n",
      "Epoch 246/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 72.3674 - val_loss: 74.0855\n",
      "Epoch 247/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 72.3184 - val_loss: 73.9870\n",
      "Epoch 248/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 72.2669 - val_loss: 73.8842\n",
      "Epoch 249/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 72.2188 - val_loss: 73.7796\n",
      "Epoch 250/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 72.1806 - val_loss: 73.6818\n",
      "Epoch 251/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 72.1147 - val_loss: 73.5853\n",
      "Epoch 252/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 72.0359 - val_loss: 73.4884\n",
      "Epoch 253/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 72.0047 - val_loss: 73.3917\n",
      "Epoch 254/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 71.9215 - val_loss: 73.2936\n",
      "Epoch 255/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 71.8691 - val_loss: 73.1934\n",
      "Epoch 256/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 71.8181 - val_loss: 73.1007\n",
      "Epoch 257/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 71.7717 - val_loss: 73.0120\n",
      "Epoch 258/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 71.7130 - val_loss: 72.9254\n",
      "Epoch 259/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 71.6697 - val_loss: 72.8325\n",
      "Epoch 260/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 71.6372 - val_loss: 72.7406\n",
      "Epoch 261/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 71.5703 - val_loss: 72.6514\n",
      "Epoch 262/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 71.5257 - val_loss: 72.5587\n",
      "Epoch 263/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 71.4664 - val_loss: 72.4695\n",
      "Epoch 264/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 71.4149 - val_loss: 72.3733\n",
      "Epoch 265/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 71.3764 - val_loss: 72.2890\n",
      "Epoch 266/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 71.3234 - val_loss: 72.2019\n",
      "Epoch 267/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 71.2748 - val_loss: 72.1187\n",
      "Epoch 268/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 71.2264 - val_loss: 72.0338\n",
      "Epoch 269/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 71.1878 - val_loss: 71.9518\n",
      "Epoch 270/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 71.1369 - val_loss: 71.8699\n",
      "Epoch 271/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 71.1019 - val_loss: 71.7849\n",
      "Epoch 272/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 71.0406 - val_loss: 71.7008\n",
      "Epoch 273/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 70.9855 - val_loss: 71.6131\n",
      "Epoch 274/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 70.9509 - val_loss: 71.5338\n",
      "Epoch 275/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 70.9043 - val_loss: 71.4587\n",
      "Epoch 276/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 70.8626 - val_loss: 71.3835\n",
      "Epoch 277/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 70.8389 - val_loss: 71.3104\n",
      "Epoch 278/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 70.7929 - val_loss: 71.2279\n",
      "Epoch 279/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 70.7345 - val_loss: 71.1537\n",
      "Epoch 280/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 70.7073 - val_loss: 71.0802\n",
      "Epoch 281/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 70.6854 - val_loss: 71.0070\n",
      "Epoch 282/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 70.6247 - val_loss: 70.9299\n",
      "Epoch 283/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 70.5769 - val_loss: 70.8540\n",
      "Epoch 284/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 70.5299 - val_loss: 70.7878\n",
      "Epoch 285/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 70.4981 - val_loss: 70.7153\n",
      "Epoch 286/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 70.4728 - val_loss: 70.6441\n",
      "Epoch 287/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 70.4253 - val_loss: 70.5778\n",
      "Epoch 288/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 70.3760 - val_loss: 70.5055\n",
      "Epoch 289/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 70.3469 - val_loss: 70.4403\n",
      "Epoch 290/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 70.3311 - val_loss: 70.3717\n",
      "Epoch 291/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 70.2664 - val_loss: 70.3055\n",
      "Epoch 292/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 70.2234 - val_loss: 70.2322\n",
      "Epoch 293/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 70.2018 - val_loss: 70.1699\n",
      "Epoch 294/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 70.1549 - val_loss: 70.0987\n",
      "Epoch 295/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 70.1324 - val_loss: 70.0375\n",
      "Epoch 296/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 70.0953 - val_loss: 69.9742\n",
      "Epoch 297/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 70.0550 - val_loss: 69.9088\n",
      "Epoch 298/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 70.0298 - val_loss: 69.8405\n",
      "Epoch 299/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 69.9742 - val_loss: 69.7695\n",
      "Epoch 300/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 69.9545 - val_loss: 69.7050\n",
      "Epoch 301/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 69.9044 - val_loss: 69.6443\n",
      "Epoch 302/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 69.8995 - val_loss: 69.5895\n",
      "Epoch 303/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 69.8425 - val_loss: 69.5296\n",
      "Epoch 304/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 69.8235 - val_loss: 69.4743\n",
      "Epoch 305/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 69.7811 - val_loss: 69.4173\n",
      "Epoch 306/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 69.7443 - val_loss: 69.3611\n",
      "Epoch 307/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 69.7153 - val_loss: 69.2926\n",
      "Epoch 308/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 69.6798 - val_loss: 69.2370\n",
      "Epoch 309/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 69.6661 - val_loss: 69.1791\n",
      "Epoch 310/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 69.6167 - val_loss: 69.1165\n",
      "Epoch 311/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 69.5812 - val_loss: 69.0525\n",
      "Epoch 312/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 69.5449 - val_loss: 68.9855\n",
      "Epoch 313/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 69.5203 - val_loss: 68.9336\n",
      "Epoch 314/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 69.4878 - val_loss: 68.8776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 315/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 69.4626 - val_loss: 68.8158\n",
      "Epoch 316/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 69.4318 - val_loss: 68.7498\n",
      "Epoch 317/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 69.3898 - val_loss: 68.6967\n",
      "Epoch 318/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 69.3509 - val_loss: 68.6423\n",
      "Epoch 319/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 69.3455 - val_loss: 68.5861\n",
      "Epoch 320/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 69.3144 - val_loss: 68.5367\n",
      "Epoch 321/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 69.2814 - val_loss: 68.4822\n",
      "Epoch 322/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 69.2500 - val_loss: 68.4357\n",
      "Epoch 323/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 69.2435 - val_loss: 68.3869\n",
      "Epoch 324/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 69.2005 - val_loss: 68.3408\n",
      "Epoch 325/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 69.1506 - val_loss: 68.2849\n",
      "Epoch 326/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 69.1419 - val_loss: 68.2367\n",
      "Epoch 327/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 69.1248 - val_loss: 68.1812\n",
      "Epoch 328/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 69.0717 - val_loss: 68.1313\n",
      "Epoch 329/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 69.0405 - val_loss: 68.0840\n",
      "Epoch 330/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 69.0136 - val_loss: 68.0325\n",
      "Epoch 331/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.9869 - val_loss: 67.9806\n",
      "Epoch 332/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.9616 - val_loss: 67.9317\n",
      "Epoch 333/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.9334 - val_loss: 67.8863\n",
      "Epoch 334/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.9125 - val_loss: 67.8435\n",
      "Epoch 335/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.9024 - val_loss: 67.7962\n",
      "Epoch 336/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.8626 - val_loss: 67.7555\n",
      "Epoch 337/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 68.8441 - val_loss: 67.7122\n",
      "Epoch 338/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.8133 - val_loss: 67.6648\n",
      "Epoch 339/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.7790 - val_loss: 67.6133\n",
      "Epoch 340/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.7500 - val_loss: 67.5711\n",
      "Epoch 341/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.7390 - val_loss: 67.5263\n",
      "Epoch 342/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 68.7219 - val_loss: 67.4804\n",
      "Epoch 343/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.6921 - val_loss: 67.4398\n",
      "Epoch 344/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.6599 - val_loss: 67.3948\n",
      "Epoch 345/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.6364 - val_loss: 67.3541\n",
      "Epoch 346/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.6092 - val_loss: 67.3085\n",
      "Epoch 347/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.5753 - val_loss: 67.2709\n",
      "Epoch 348/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.5565 - val_loss: 67.2260\n",
      "Epoch 349/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.5382 - val_loss: 67.1742\n",
      "Epoch 350/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.5304 - val_loss: 67.1330\n",
      "Epoch 351/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.4989 - val_loss: 67.0914\n",
      "Epoch 352/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.4623 - val_loss: 67.0455\n",
      "Epoch 353/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.4645 - val_loss: 67.0078\n",
      "Epoch 354/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.4249 - val_loss: 66.9717\n",
      "Epoch 355/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.3887 - val_loss: 66.9338\n",
      "Epoch 356/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.3758 - val_loss: 66.8977\n",
      "Epoch 357/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.3548 - val_loss: 66.8593\n",
      "Epoch 358/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.3267 - val_loss: 66.8213\n",
      "Epoch 359/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.2981 - val_loss: 66.7825\n",
      "Epoch 360/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.2860 - val_loss: 66.7418\n",
      "Epoch 361/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.2523 - val_loss: 66.6997\n",
      "Epoch 362/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.2469 - val_loss: 66.6699\n",
      "Epoch 363/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.2281 - val_loss: 66.6247\n",
      "Epoch 364/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.2030 - val_loss: 66.5872\n",
      "Epoch 365/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.1959 - val_loss: 66.5504\n",
      "Epoch 366/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.1494 - val_loss: 66.5085\n",
      "Epoch 367/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.1270 - val_loss: 66.4753\n",
      "Epoch 368/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.1141 - val_loss: 66.4351\n",
      "Epoch 369/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.0905 - val_loss: 66.4042\n",
      "Epoch 370/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.0783 - val_loss: 66.3604\n",
      "Epoch 371/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.0395 - val_loss: 66.3231\n",
      "Epoch 372/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.0256 - val_loss: 66.2944\n",
      "Epoch 373/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.0010 - val_loss: 66.2620\n",
      "Epoch 374/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 67.9848 - val_loss: 66.2296\n",
      "Epoch 375/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 67.9949 - val_loss: 66.1933\n",
      "Epoch 376/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 67.9303 - val_loss: 66.1655\n",
      "Epoch 377/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 67.9196 - val_loss: 66.1301\n",
      "Epoch 378/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 67.9008 - val_loss: 66.0924\n",
      "Epoch 379/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 67.8852 - val_loss: 66.0606\n",
      "Epoch 380/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 67.9033 - val_loss: 66.0219\n",
      "Epoch 381/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 67.8401 - val_loss: 65.9934\n",
      "Epoch 382/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 67.8278 - val_loss: 65.9605\n",
      "Epoch 383/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 67.7961 - val_loss: 65.9286\n",
      "Epoch 384/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 67.7899 - val_loss: 65.8885\n",
      "Epoch 385/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 67.7613 - val_loss: 65.8481\n",
      "Epoch 386/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 67.7296 - val_loss: 65.8145\n",
      "Epoch 387/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 67.7217 - val_loss: 65.7869\n",
      "Epoch 388/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 67.6907 - val_loss: 65.7587\n",
      "Epoch 389/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 67.6740 - val_loss: 65.7334\n",
      "Epoch 390/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 67.6563 - val_loss: 65.6882\n",
      "Epoch 391/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 67.6534 - val_loss: 65.6599\n",
      "Epoch 392/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 67.6227 - val_loss: 65.6248\n",
      "Epoch 393/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 67.6131 - val_loss: 65.5854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 394/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 67.5776 - val_loss: 65.5579\n",
      "Epoch 395/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 67.5558 - val_loss: 65.5270\n",
      "Epoch 396/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 67.5381 - val_loss: 65.4959\n",
      "Epoch 397/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 67.5193 - val_loss: 65.4627\n",
      "Epoch 398/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 67.5102 - val_loss: 65.4302\n",
      "Epoch 399/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 67.4962 - val_loss: 65.4013\n",
      "Epoch 400/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 67.4699 - val_loss: 65.3674\n",
      "Epoch 401/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 67.4637 - val_loss: 65.3382\n",
      "Epoch 402/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 67.4203 - val_loss: 65.3100\n",
      "Epoch 403/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 67.4046 - val_loss: 65.2752\n",
      "Epoch 404/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 67.3888 - val_loss: 65.2457\n",
      "Epoch 405/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 67.3638 - val_loss: 65.2266\n",
      "Epoch 406/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 67.3392 - val_loss: 65.2020\n",
      "Epoch 407/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 67.3334 - val_loss: 65.1728\n",
      "Epoch 408/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 67.3221 - val_loss: 65.1313\n",
      "Epoch 409/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 67.2910 - val_loss: 65.0958\n",
      "Epoch 410/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 67.2820 - val_loss: 65.0692\n",
      "Epoch 411/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 67.2590 - val_loss: 65.0434\n",
      "Epoch 412/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 67.2410 - val_loss: 65.0209\n",
      "Epoch 413/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 67.2178 - val_loss: 64.9973\n",
      "Epoch 414/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 67.2268 - val_loss: 64.9738\n",
      "Epoch 415/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 67.1950 - val_loss: 64.9520\n",
      "Epoch 416/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 67.1610 - val_loss: 64.9256\n",
      "Epoch 417/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 67.1559 - val_loss: 64.8969\n",
      "Epoch 418/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 67.1299 - val_loss: 64.8656\n",
      "Epoch 419/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 67.1402 - val_loss: 64.8337\n",
      "Epoch 420/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 67.0853 - val_loss: 64.8082\n",
      "Epoch 421/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 67.0806 - val_loss: 64.7817\n",
      "Epoch 422/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 67.0745 - val_loss: 64.7562\n",
      "Epoch 423/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 67.0370 - val_loss: 64.7266\n",
      "Epoch 424/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 67.0254 - val_loss: 64.7062\n",
      "Epoch 425/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 67.0104 - val_loss: 64.6751\n",
      "Epoch 426/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 66.9770 - val_loss: 64.6486\n",
      "Epoch 427/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 66.9959 - val_loss: 64.6244\n",
      "Epoch 428/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.9380 - val_loss: 64.5973\n",
      "Epoch 429/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.9382 - val_loss: 64.5821\n",
      "Epoch 430/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.9013 - val_loss: 64.5542\n",
      "Epoch 431/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.8961 - val_loss: 64.5325\n",
      "Epoch 432/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.8719 - val_loss: 64.5088\n",
      "Epoch 433/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.8404 - val_loss: 64.4878\n",
      "Epoch 434/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.8534 - val_loss: 64.4599\n",
      "Epoch 435/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.8300 - val_loss: 64.4413\n",
      "Epoch 436/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.8231 - val_loss: 64.4211\n",
      "Epoch 437/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 66.7838 - val_loss: 64.3875\n",
      "Epoch 438/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 66.7623 - val_loss: 64.3617\n",
      "Epoch 439/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 66.7516 - val_loss: 64.3343\n",
      "Epoch 440/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 66.7450 - val_loss: 64.3033\n",
      "Epoch 441/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 66.7483 - val_loss: 64.2791\n",
      "Epoch 442/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 66.7210 - val_loss: 64.2563\n",
      "Epoch 443/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 66.7124 - val_loss: 64.2367\n",
      "Epoch 444/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 66.6804 - val_loss: 64.2166\n",
      "Epoch 445/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.6508 - val_loss: 64.1932\n",
      "Epoch 446/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.6499 - val_loss: 64.1805\n",
      "Epoch 447/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.6252 - val_loss: 64.1575\n",
      "Epoch 448/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.6020 - val_loss: 64.1340\n",
      "Epoch 449/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.5838 - val_loss: 64.1076\n",
      "Epoch 450/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.5837 - val_loss: 64.0711\n",
      "Epoch 451/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.5602 - val_loss: 64.0468\n",
      "Epoch 452/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.5307 - val_loss: 64.0255\n",
      "Epoch 453/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 66.5285 - val_loss: 64.0044\n",
      "Epoch 454/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 66.5147 - val_loss: 63.9750\n",
      "Epoch 455/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 66.5006 - val_loss: 63.9535\n",
      "Epoch 456/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 66.4814 - val_loss: 63.9230\n",
      "Epoch 457/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 66.4550 - val_loss: 63.8976\n",
      "Epoch 458/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 66.4399 - val_loss: 63.8863\n",
      "Epoch 459/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.4401 - val_loss: 63.8569\n",
      "Epoch 460/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.4122 - val_loss: 63.8417\n",
      "Epoch 461/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.3915 - val_loss: 63.8169\n",
      "Epoch 462/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.3685 - val_loss: 63.8027\n",
      "Epoch 463/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.3603 - val_loss: 63.7761\n",
      "Epoch 464/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.3491 - val_loss: 63.7546\n",
      "Epoch 465/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.3280 - val_loss: 63.7402\n",
      "Epoch 466/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.3101 - val_loss: 63.7230\n",
      "Epoch 467/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.3219 - val_loss: 63.7046\n",
      "Epoch 468/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.3107 - val_loss: 63.6757\n",
      "Epoch 469/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.2809 - val_loss: 63.6646\n",
      "Epoch 470/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.2627 - val_loss: 63.6437\n",
      "Epoch 471/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.2379 - val_loss: 63.6113\n",
      "Epoch 472/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.2533 - val_loss: 63.5910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 473/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.2293 - val_loss: 63.5592\n",
      "Epoch 474/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.1805 - val_loss: 63.5361\n",
      "Epoch 475/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.1721 - val_loss: 63.5032\n",
      "Epoch 476/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.1590 - val_loss: 63.4894\n",
      "Epoch 477/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.1374 - val_loss: 63.4718\n",
      "Epoch 478/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.1270 - val_loss: 63.4517\n",
      "Epoch 479/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.1287 - val_loss: 63.4364\n",
      "Epoch 480/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.1099 - val_loss: 63.4102\n",
      "Epoch 481/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.1028 - val_loss: 63.3970\n",
      "Epoch 482/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 66.0909 - val_loss: 63.3770\n",
      "Epoch 483/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.0548 - val_loss: 63.3581\n",
      "Epoch 484/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.0403 - val_loss: 63.3435\n",
      "Epoch 485/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.0438 - val_loss: 63.3223\n",
      "Epoch 486/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.0146 - val_loss: 63.3092\n",
      "Epoch 487/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.9972 - val_loss: 63.2826\n",
      "Epoch 488/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.9933 - val_loss: 63.2610\n",
      "Epoch 489/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.9752 - val_loss: 63.2378\n",
      "Epoch 490/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.9738 - val_loss: 63.2032\n",
      "Epoch 491/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.9315 - val_loss: 63.1908\n",
      "Epoch 492/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.9315 - val_loss: 63.1758\n",
      "Epoch 493/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.9124 - val_loss: 63.1634\n",
      "Epoch 494/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.8964 - val_loss: 63.1428\n",
      "Epoch 495/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.8867 - val_loss: 63.1308\n",
      "Epoch 496/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.8817 - val_loss: 63.1198\n",
      "Epoch 497/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.8602 - val_loss: 63.1083\n",
      "Epoch 498/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.8496 - val_loss: 63.0764\n",
      "Epoch 499/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 65.8248 - val_loss: 63.0475\n",
      "Epoch 500/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.8252 - val_loss: 63.0379\n",
      "Epoch 501/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.8016 - val_loss: 63.0203\n",
      "Epoch 502/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.8257 - val_loss: 63.0085\n",
      "Epoch 503/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.7773 - val_loss: 62.9865\n",
      "Epoch 504/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.7608 - val_loss: 62.9619\n",
      "Epoch 505/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.7624 - val_loss: 62.9416\n",
      "Epoch 506/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.7505 - val_loss: 62.9265\n",
      "Epoch 507/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.7144 - val_loss: 62.9096\n",
      "Epoch 508/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.7197 - val_loss: 62.8915\n",
      "Epoch 509/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.7250 - val_loss: 62.8773\n",
      "Epoch 510/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.6892 - val_loss: 62.8570\n",
      "Epoch 511/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.7057 - val_loss: 62.8546\n",
      "Epoch 512/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.6644 - val_loss: 62.8328\n",
      "Epoch 513/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.6781 - val_loss: 62.8190\n",
      "Epoch 514/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.6436 - val_loss: 62.7995\n",
      "Epoch 515/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.6197 - val_loss: 62.7827\n",
      "Epoch 516/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.6188 - val_loss: 62.7737\n",
      "Epoch 517/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.5998 - val_loss: 62.7552\n",
      "Epoch 518/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.6034 - val_loss: 62.7359\n",
      "Epoch 519/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.5737 - val_loss: 62.7209\n",
      "Epoch 520/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.5820 - val_loss: 62.7074\n",
      "Epoch 521/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.5506 - val_loss: 62.7028\n",
      "Epoch 522/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.5330 - val_loss: 62.6797\n",
      "Epoch 523/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.5290 - val_loss: 62.6602\n",
      "Epoch 524/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.5303 - val_loss: 62.6391\n",
      "Epoch 525/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.5062 - val_loss: 62.6289\n",
      "Epoch 526/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.4873 - val_loss: 62.6075\n",
      "Epoch 527/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.4730 - val_loss: 62.5900\n",
      "Epoch 528/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.4706 - val_loss: 62.5828\n",
      "Epoch 529/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.4532 - val_loss: 62.5532\n",
      "Epoch 530/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.4467 - val_loss: 62.5338\n",
      "Epoch 531/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.4319 - val_loss: 62.5256\n",
      "Epoch 532/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.4101 - val_loss: 62.5046\n",
      "Epoch 533/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.4009 - val_loss: 62.4893\n",
      "Epoch 534/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.4121 - val_loss: 62.4787\n",
      "Epoch 535/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.4043 - val_loss: 62.4592\n",
      "Epoch 536/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.3817 - val_loss: 62.4420\n",
      "Epoch 537/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.3644 - val_loss: 62.4369\n",
      "Epoch 538/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.3782 - val_loss: 62.4253\n",
      "Epoch 539/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.3584 - val_loss: 62.4084\n",
      "Epoch 540/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.3324 - val_loss: 62.3987\n",
      "Epoch 541/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.3257 - val_loss: 62.3885\n",
      "Epoch 542/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.3041 - val_loss: 62.3717\n",
      "Epoch 543/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.3074 - val_loss: 62.3552\n",
      "Epoch 544/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.2994 - val_loss: 62.3429\n",
      "Epoch 545/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.2778 - val_loss: 62.3298\n",
      "Epoch 546/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.2708 - val_loss: 62.3123\n",
      "Epoch 547/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 65.2691 - val_loss: 62.2993\n",
      "Epoch 548/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.2578 - val_loss: 62.2845\n",
      "Epoch 549/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.2577 - val_loss: 62.2631\n",
      "Epoch 550/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 65.2360 - val_loss: 62.2537\n",
      "Epoch 551/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 65.2106 - val_loss: 62.2324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 552/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 65.1945 - val_loss: 62.2241\n",
      "Epoch 553/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 65.1978 - val_loss: 62.2132\n",
      "Epoch 554/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 65.1798 - val_loss: 62.2007\n",
      "Epoch 555/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 65.1723 - val_loss: 62.1889\n",
      "Epoch 556/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 65.1439 - val_loss: 62.1732\n",
      "Epoch 557/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.1415 - val_loss: 62.1626\n",
      "Epoch 558/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.1350 - val_loss: 62.1506\n",
      "Epoch 559/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.1369 - val_loss: 62.1268\n",
      "Epoch 560/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.1085 - val_loss: 62.1170\n",
      "Epoch 561/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.1150 - val_loss: 62.0995\n",
      "Epoch 562/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.1003 - val_loss: 62.0912\n",
      "Epoch 563/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 65.0856 - val_loss: 62.0747\n",
      "Epoch 564/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 65.0745 - val_loss: 62.0647\n",
      "Epoch 565/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 65.0762 - val_loss: 62.0525\n",
      "Epoch 566/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 65.0479 - val_loss: 62.0383\n",
      "Epoch 567/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 65.0463 - val_loss: 62.0171\n",
      "Epoch 568/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.0376 - val_loss: 62.0065\n",
      "Epoch 569/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.0361 - val_loss: 62.0002\n",
      "Epoch 570/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 65.0036 - val_loss: 61.9908\n",
      "Epoch 571/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.9898 - val_loss: 61.9742\n",
      "Epoch 572/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.9753 - val_loss: 61.9693\n",
      "Epoch 573/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.9890 - val_loss: 61.9493\n",
      "Epoch 574/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.9549 - val_loss: 61.9298\n",
      "Epoch 575/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.9385 - val_loss: 61.9241\n",
      "Epoch 576/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.9287 - val_loss: 61.9051\n",
      "Epoch 577/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.9282 - val_loss: 61.8836\n",
      "Epoch 578/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.9254 - val_loss: 61.8745\n",
      "Epoch 579/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.9200 - val_loss: 61.8525\n",
      "Epoch 580/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.8909 - val_loss: 61.8349\n",
      "Epoch 581/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.8776 - val_loss: 61.8154\n",
      "Epoch 582/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.8745 - val_loss: 61.7911\n",
      "Epoch 583/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.8680 - val_loss: 61.7801\n",
      "Epoch 584/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.8435 - val_loss: 61.7704\n",
      "Epoch 585/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.8664 - val_loss: 61.7575\n",
      "Epoch 586/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.8323 - val_loss: 61.7541\n",
      "Epoch 587/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.8137 - val_loss: 61.7426\n",
      "Epoch 588/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.8030 - val_loss: 61.7334\n",
      "Epoch 589/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.7947 - val_loss: 61.7279\n",
      "Epoch 590/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.7974 - val_loss: 61.7218\n",
      "Epoch 591/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.8063 - val_loss: 61.7067\n",
      "Epoch 592/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.7574 - val_loss: 61.6905\n",
      "Epoch 593/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.7496 - val_loss: 61.6811\n",
      "Epoch 594/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.7594 - val_loss: 61.6585\n",
      "Epoch 595/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.7312 - val_loss: 61.6435\n",
      "Epoch 596/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.7281 - val_loss: 61.6322\n",
      "Epoch 597/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.7111 - val_loss: 61.6311\n",
      "Epoch 598/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.6917 - val_loss: 61.6166\n",
      "Epoch 599/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.7023 - val_loss: 61.6062\n",
      "Epoch 600/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.7087 - val_loss: 61.6020\n",
      "Epoch 601/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.6748 - val_loss: 61.5972\n",
      "Epoch 602/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.6556 - val_loss: 61.5900\n",
      "Epoch 603/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.6575 - val_loss: 61.5710\n",
      "Epoch 604/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.6422 - val_loss: 61.5713\n",
      "Epoch 605/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.6344 - val_loss: 61.5578\n",
      "Epoch 606/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.6082 - val_loss: 61.5505\n",
      "Epoch 607/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.6129 - val_loss: 61.5306\n",
      "Epoch 608/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.6030 - val_loss: 61.4995\n",
      "Epoch 609/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.5781 - val_loss: 61.4844\n",
      "Epoch 610/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 64.5803 - val_loss: 61.4765\n",
      "Epoch 611/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.5719 - val_loss: 61.4552\n",
      "Epoch 612/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.5650 - val_loss: 61.4455\n",
      "Epoch 613/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.5562 - val_loss: 61.4466\n",
      "Epoch 614/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.5358 - val_loss: 61.4368\n",
      "Epoch 615/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.5390 - val_loss: 61.4241\n",
      "Epoch 616/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.5319 - val_loss: 61.4131\n",
      "Epoch 617/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.5170 - val_loss: 61.3956\n",
      "Epoch 618/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.4958 - val_loss: 61.3946\n",
      "Epoch 619/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.5133 - val_loss: 61.3728\n",
      "Epoch 620/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.4892 - val_loss: 61.3793\n",
      "Epoch 621/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.4638 - val_loss: 61.3684\n",
      "Epoch 622/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.4572 - val_loss: 61.3508\n",
      "Epoch 623/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.4418 - val_loss: 61.3431\n",
      "Epoch 624/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.4638 - val_loss: 61.3260\n",
      "Epoch 625/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.4344 - val_loss: 61.3041\n",
      "Epoch 626/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.4259 - val_loss: 61.3006\n",
      "Epoch 627/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.4042 - val_loss: 61.2855\n",
      "Epoch 628/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.4025 - val_loss: 61.2763\n",
      "Epoch 629/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.3821 - val_loss: 61.2683\n",
      "Epoch 630/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.3790 - val_loss: 61.2465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 631/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.3679 - val_loss: 61.2357\n",
      "Epoch 632/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.3461 - val_loss: 61.2191\n",
      "Epoch 633/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.3477 - val_loss: 61.2059\n",
      "Epoch 634/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.3409 - val_loss: 61.1986\n",
      "Epoch 635/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.3199 - val_loss: 61.1706\n",
      "Epoch 636/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.3420 - val_loss: 61.1725\n",
      "Epoch 637/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.3203 - val_loss: 61.1516\n",
      "Epoch 638/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.2810 - val_loss: 61.1479\n",
      "Epoch 639/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.2779 - val_loss: 61.1413\n",
      "Epoch 640/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.2731 - val_loss: 61.1253\n",
      "Epoch 641/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.2668 - val_loss: 61.1183\n",
      "Epoch 642/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.2462 - val_loss: 61.1080\n",
      "Epoch 643/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.2247 - val_loss: 61.0928\n",
      "Epoch 644/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.2411 - val_loss: 61.0913\n",
      "Epoch 645/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.2186 - val_loss: 61.0756\n",
      "Epoch 646/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.2035 - val_loss: 61.0604\n",
      "Epoch 647/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.1914 - val_loss: 61.0577\n",
      "Epoch 648/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.1761 - val_loss: 61.0463\n",
      "Epoch 649/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.1782 - val_loss: 61.0368\n",
      "Epoch 650/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.1598 - val_loss: 61.0257\n",
      "Epoch 651/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.1496 - val_loss: 61.0131\n",
      "Epoch 652/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.1394 - val_loss: 61.0000\n",
      "Epoch 653/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.1401 - val_loss: 60.9953\n",
      "Epoch 654/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.1330 - val_loss: 60.9867\n",
      "Epoch 655/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.1129 - val_loss: 60.9768\n",
      "Epoch 656/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.1093 - val_loss: 60.9654\n",
      "Epoch 657/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.1069 - val_loss: 60.9385\n",
      "Epoch 658/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.1058 - val_loss: 60.9362\n",
      "Epoch 659/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.0809 - val_loss: 60.9258\n",
      "Epoch 660/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.0799 - val_loss: 60.9181\n",
      "Epoch 661/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.0801 - val_loss: 60.9142\n",
      "Epoch 662/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.0652 - val_loss: 60.9174\n",
      "Epoch 663/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.0452 - val_loss: 60.9201\n",
      "Epoch 664/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.0511 - val_loss: 60.8978\n",
      "Epoch 665/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.0257 - val_loss: 60.8885\n",
      "Epoch 666/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.0285 - val_loss: 60.8847\n",
      "Epoch 667/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.0229 - val_loss: 60.8728\n",
      "Epoch 668/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.9936 - val_loss: 60.8620\n",
      "Epoch 669/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.9933 - val_loss: 60.8604\n",
      "Epoch 670/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.9912 - val_loss: 60.8466\n",
      "Epoch 671/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.9758 - val_loss: 60.8391\n",
      "Epoch 672/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.9858 - val_loss: 60.8287\n",
      "Epoch 673/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.9725 - val_loss: 60.8231\n",
      "Epoch 674/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.9497 - val_loss: 60.8064\n",
      "Epoch 675/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.9499 - val_loss: 60.7898\n",
      "Epoch 676/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.9250 - val_loss: 60.7830\n",
      "Epoch 677/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.9263 - val_loss: 60.7794\n",
      "Epoch 678/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.9355 - val_loss: 60.7746\n",
      "Epoch 679/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.8978 - val_loss: 60.7605\n",
      "Epoch 680/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.8895 - val_loss: 60.7401\n",
      "Epoch 681/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.9028 - val_loss: 60.7461\n",
      "Epoch 682/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.8935 - val_loss: 60.7346\n",
      "Epoch 683/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.8698 - val_loss: 60.7186\n",
      "Epoch 684/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.8800 - val_loss: 60.6993\n",
      "Epoch 685/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.8512 - val_loss: 60.6943\n",
      "Epoch 686/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.8673 - val_loss: 60.6877\n",
      "Epoch 687/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.8587 - val_loss: 60.6879\n",
      "Epoch 688/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.8332 - val_loss: 60.6713\n",
      "Epoch 689/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.8212 - val_loss: 60.6725\n",
      "Epoch 690/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.8106 - val_loss: 60.6590\n",
      "Epoch 691/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.8088 - val_loss: 60.6277\n",
      "Epoch 692/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.8234 - val_loss: 60.6118\n",
      "Epoch 693/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.8018 - val_loss: 60.5974\n",
      "Epoch 694/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.7822 - val_loss: 60.5966\n",
      "Epoch 695/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.7673 - val_loss: 60.5850\n",
      "Epoch 696/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.7686 - val_loss: 60.5833\n",
      "Epoch 697/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.7910 - val_loss: 60.5657\n",
      "Epoch 698/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.7400 - val_loss: 60.5593\n",
      "Epoch 699/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.7409 - val_loss: 60.5406\n",
      "Epoch 700/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.7327 - val_loss: 60.5232\n",
      "Epoch 701/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.7338 - val_loss: 60.5213\n",
      "Epoch 702/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.7155 - val_loss: 60.5180\n",
      "Epoch 703/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 63.7186 - val_loss: 60.5022\n",
      "Epoch 704/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.6915 - val_loss: 60.4992\n",
      "Epoch 705/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 63.7031 - val_loss: 60.5065\n",
      "Epoch 706/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 63.6777 - val_loss: 60.4899\n",
      "Epoch 707/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 63.6685 - val_loss: 60.4776\n",
      "Epoch 708/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 63.6860 - val_loss: 60.4790\n",
      "Epoch 709/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.6619 - val_loss: 60.4693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 710/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.6502 - val_loss: 60.4703\n",
      "Epoch 711/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.6551 - val_loss: 60.4641\n",
      "Epoch 712/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.6305 - val_loss: 60.4441\n",
      "Epoch 713/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.6299 - val_loss: 60.4316\n",
      "Epoch 714/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.6149 - val_loss: 60.4302\n",
      "Epoch 715/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.6015 - val_loss: 60.4049\n",
      "Epoch 716/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.6199 - val_loss: 60.4065\n",
      "Epoch 717/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.5851 - val_loss: 60.4104\n",
      "Epoch 718/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.5914 - val_loss: 60.4099\n",
      "Epoch 719/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.5751 - val_loss: 60.4015\n",
      "Epoch 720/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.5781 - val_loss: 60.3776\n",
      "Epoch 721/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.5557 - val_loss: 60.3596\n",
      "Epoch 722/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.5549 - val_loss: 60.3560\n",
      "Epoch 723/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.5284 - val_loss: 60.3388\n",
      "Epoch 724/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.5258 - val_loss: 60.3362\n",
      "Epoch 725/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.5232 - val_loss: 60.3214\n",
      "Epoch 726/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.5130 - val_loss: 60.3192\n",
      "Epoch 727/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.4989 - val_loss: 60.3136\n",
      "Epoch 728/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.4863 - val_loss: 60.3096\n",
      "Epoch 729/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.4824 - val_loss: 60.2975\n",
      "Epoch 730/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.4883 - val_loss: 60.2777\n",
      "Epoch 731/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.4735 - val_loss: 60.2577\n",
      "Epoch 732/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.4583 - val_loss: 60.2466\n",
      "Epoch 733/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.4602 - val_loss: 60.2341\n",
      "Epoch 734/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.4481 - val_loss: 60.2285\n",
      "Epoch 735/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 63.4315 - val_loss: 60.2150\n",
      "Epoch 736/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.4263 - val_loss: 60.2134\n",
      "Epoch 737/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.4347 - val_loss: 60.2177\n",
      "Epoch 738/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.4039 - val_loss: 60.2101\n",
      "Epoch 739/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.4244 - val_loss: 60.2055\n",
      "Epoch 740/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.3897 - val_loss: 60.1956\n",
      "Epoch 741/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.3885 - val_loss: 60.1839\n",
      "Epoch 742/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.3834 - val_loss: 60.1706\n",
      "Epoch 743/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.4028 - val_loss: 60.1677\n",
      "Epoch 744/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.3574 - val_loss: 60.1611\n",
      "Epoch 745/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.3610 - val_loss: 60.1423\n",
      "Epoch 746/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.3510 - val_loss: 60.1301\n",
      "Epoch 747/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.3415 - val_loss: 60.1270\n",
      "Epoch 748/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.3247 - val_loss: 60.1218\n",
      "Epoch 749/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.3475 - val_loss: 60.1109\n",
      "Epoch 750/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.3280 - val_loss: 60.1153\n",
      "Epoch 751/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.3058 - val_loss: 60.1027\n",
      "Epoch 752/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.3291 - val_loss: 60.0999\n",
      "Epoch 753/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.2978 - val_loss: 60.0884\n",
      "Epoch 754/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.2747 - val_loss: 60.0875\n",
      "Epoch 755/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.2867 - val_loss: 60.0887\n",
      "Epoch 756/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.2862 - val_loss: 60.0701\n",
      "Epoch 757/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.2733 - val_loss: 60.0649\n",
      "Epoch 758/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.2734 - val_loss: 60.0545\n",
      "Epoch 759/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.2718 - val_loss: 60.0569\n",
      "Epoch 760/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.2566 - val_loss: 60.0518\n",
      "Epoch 761/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.2426 - val_loss: 60.0321\n",
      "Epoch 762/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.2300 - val_loss: 60.0220\n",
      "Epoch 763/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.2092 - val_loss: 60.0034\n",
      "Epoch 764/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.2369 - val_loss: 59.9974\n",
      "Epoch 765/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.2137 - val_loss: 59.9966\n",
      "Epoch 766/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.1913 - val_loss: 59.9804\n",
      "Epoch 767/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.1809 - val_loss: 59.9659\n",
      "Epoch 768/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.1828 - val_loss: 59.9626\n",
      "Epoch 769/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.1792 - val_loss: 59.9554\n",
      "Epoch 770/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.1850 - val_loss: 59.9492\n",
      "Epoch 771/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.1578 - val_loss: 59.9517\n",
      "Epoch 772/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.1426 - val_loss: 59.9413\n",
      "Epoch 773/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.1520 - val_loss: 59.9380\n",
      "Epoch 774/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.1463 - val_loss: 59.9341\n",
      "Epoch 775/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.1283 - val_loss: 59.9156\n",
      "Epoch 776/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.1158 - val_loss: 59.9073\n",
      "Epoch 777/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.1035 - val_loss: 59.9024\n",
      "Epoch 778/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.1183 - val_loss: 59.9006\n",
      "Epoch 779/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.1032 - val_loss: 59.8896\n",
      "Epoch 780/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.0962 - val_loss: 59.8690\n",
      "Epoch 781/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.1006 - val_loss: 59.8591\n",
      "Epoch 782/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.0916 - val_loss: 59.8431\n",
      "Epoch 783/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.0732 - val_loss: 59.8426\n",
      "Epoch 784/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.0826 - val_loss: 59.8485\n",
      "Epoch 785/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.0563 - val_loss: 59.8355\n",
      "Epoch 786/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.0449 - val_loss: 59.8314\n",
      "Epoch 787/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.0452 - val_loss: 59.8268\n",
      "Epoch 788/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.0373 - val_loss: 59.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 789/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.0283 - val_loss: 59.8365\n",
      "Epoch 790/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.0292 - val_loss: 59.8038\n",
      "Epoch 791/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.0284 - val_loss: 59.8007\n",
      "Epoch 792/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.0115 - val_loss: 59.7979\n",
      "Epoch 793/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.0134 - val_loss: 59.7733\n",
      "Epoch 794/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.0051 - val_loss: 59.7696\n",
      "Epoch 795/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.0206 - val_loss: 59.7682\n",
      "Epoch 796/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.9966 - val_loss: 59.7556\n",
      "Epoch 797/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 62.9856 - val_loss: 59.7464\n",
      "Epoch 798/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.9716 - val_loss: 59.7520\n",
      "Epoch 799/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.9727 - val_loss: 59.7423\n",
      "Epoch 800/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.9567 - val_loss: 59.7504\n",
      "Epoch 801/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.9558 - val_loss: 59.7433\n",
      "Epoch 802/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.9397 - val_loss: 59.7214\n",
      "Epoch 803/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.9376 - val_loss: 59.6889\n",
      "Epoch 804/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.9296 - val_loss: 59.6816\n",
      "Epoch 805/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.9336 - val_loss: 59.6787\n",
      "Epoch 806/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.9073 - val_loss: 59.6870\n",
      "Epoch 807/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.9152 - val_loss: 59.6910\n",
      "Epoch 808/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.9088 - val_loss: 59.6910\n",
      "Epoch 809/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.8996 - val_loss: 59.6887\n",
      "Epoch 810/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.8933 - val_loss: 59.6665\n",
      "Epoch 811/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.8864 - val_loss: 59.6643\n",
      "Epoch 812/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.8908 - val_loss: 59.6540\n",
      "Epoch 813/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.8601 - val_loss: 59.6436\n",
      "Epoch 814/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.8562 - val_loss: 59.6316\n",
      "Epoch 815/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.8420 - val_loss: 59.6179\n",
      "Epoch 816/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.8507 - val_loss: 59.6178\n",
      "Epoch 817/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.8375 - val_loss: 59.6082\n",
      "Epoch 818/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.8334 - val_loss: 59.6022\n",
      "Epoch 819/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.8173 - val_loss: 59.5977\n",
      "Epoch 820/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.8258 - val_loss: 59.5825\n",
      "Epoch 821/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.8196 - val_loss: 59.5760\n",
      "Epoch 822/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.8044 - val_loss: 59.5662\n",
      "Epoch 823/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.8021 - val_loss: 59.5486\n",
      "Epoch 824/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.7967 - val_loss: 59.5456\n",
      "Epoch 825/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.7724 - val_loss: 59.5563\n",
      "Epoch 826/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.7859 - val_loss: 59.5437\n",
      "Epoch 827/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.7803 - val_loss: 59.5435\n",
      "Epoch 828/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.7616 - val_loss: 59.5351\n",
      "Epoch 829/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.7672 - val_loss: 59.5207\n",
      "Epoch 830/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.7412 - val_loss: 59.5072\n",
      "Epoch 831/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.7464 - val_loss: 59.5102\n",
      "Epoch 832/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 62.7584 - val_loss: 59.5043\n",
      "Epoch 833/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.7222 - val_loss: 59.5062\n",
      "Epoch 834/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.7270 - val_loss: 59.5105\n",
      "Epoch 835/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.7231 - val_loss: 59.4964\n",
      "Epoch 836/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.7081 - val_loss: 59.4811\n",
      "Epoch 837/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.7153 - val_loss: 59.4823\n",
      "Epoch 838/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.6998 - val_loss: 59.4662\n",
      "Epoch 839/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 62.6795 - val_loss: 59.4597\n",
      "Epoch 840/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.6956 - val_loss: 59.4547\n",
      "Epoch 841/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 62.6787 - val_loss: 59.4331\n",
      "Epoch 842/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 62.6864 - val_loss: 59.4272\n",
      "Epoch 843/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.6572 - val_loss: 59.4258\n",
      "Epoch 844/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 62.6449 - val_loss: 59.4096\n",
      "Epoch 845/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.6364 - val_loss: 59.4015\n",
      "Epoch 846/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.6382 - val_loss: 59.4010\n",
      "Epoch 847/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.6598 - val_loss: 59.3933\n",
      "Epoch 848/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.6334 - val_loss: 59.3845\n",
      "Epoch 849/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.6395 - val_loss: 59.3755\n",
      "Epoch 850/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.6127 - val_loss: 59.3693\n",
      "Epoch 851/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.6025 - val_loss: 59.3674\n",
      "Epoch 852/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.5909 - val_loss: 59.3646\n",
      "Epoch 853/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.6126 - val_loss: 59.3411\n",
      "Epoch 854/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.5978 - val_loss: 59.3433\n",
      "Epoch 855/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.5817 - val_loss: 59.3529\n",
      "Epoch 856/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.6045 - val_loss: 59.3335\n",
      "Epoch 857/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.5765 - val_loss: 59.3320\n",
      "Epoch 858/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.5670 - val_loss: 59.3347\n",
      "Epoch 859/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.5573 - val_loss: 59.3243\n",
      "Epoch 860/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.5421 - val_loss: 59.3238\n",
      "Epoch 861/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.5501 - val_loss: 59.3044\n",
      "Epoch 862/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.5298 - val_loss: 59.2984\n",
      "Epoch 863/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.5364 - val_loss: 59.2781\n",
      "Epoch 864/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.5541 - val_loss: 59.2836\n",
      "Epoch 865/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.5123 - val_loss: 59.2806\n",
      "Epoch 866/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.5034 - val_loss: 59.2824\n",
      "Epoch 867/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.4953 - val_loss: 59.2734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 868/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.4977 - val_loss: 59.2650\n",
      "Epoch 869/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.4813 - val_loss: 59.2574\n",
      "Epoch 870/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.5035 - val_loss: 59.2661\n",
      "Epoch 871/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.4703 - val_loss: 59.2580\n",
      "Epoch 872/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.4671 - val_loss: 59.2488\n",
      "Epoch 873/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.4693 - val_loss: 59.2467\n",
      "Epoch 874/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.4630 - val_loss: 59.2445\n",
      "Epoch 875/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.4558 - val_loss: 59.2340\n",
      "Epoch 876/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.4477 - val_loss: 59.2349\n",
      "Epoch 877/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.4414 - val_loss: 59.2264\n",
      "Epoch 878/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.4309 - val_loss: 59.2083\n",
      "Epoch 879/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.4411 - val_loss: 59.2038\n",
      "Epoch 880/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.4227 - val_loss: 59.2207\n",
      "Epoch 881/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.4133 - val_loss: 59.2151\n",
      "Epoch 882/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.4091 - val_loss: 59.1964\n",
      "Epoch 883/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.3963 - val_loss: 59.1825\n",
      "Epoch 884/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.3878 - val_loss: 59.1717\n",
      "Epoch 885/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.4212 - val_loss: 59.1662\n",
      "Epoch 886/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.3720 - val_loss: 59.1533\n",
      "Epoch 887/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.3680 - val_loss: 59.1509\n",
      "Epoch 888/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.3798 - val_loss: 59.1473\n",
      "Epoch 889/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.3707 - val_loss: 59.1295\n",
      "Epoch 890/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.3484 - val_loss: 59.1244\n",
      "Epoch 891/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.3666 - val_loss: 59.1174\n",
      "Epoch 892/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.3429 - val_loss: 59.1070\n",
      "Epoch 893/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.3308 - val_loss: 59.1041\n",
      "Epoch 894/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.3309 - val_loss: 59.0973\n",
      "Epoch 895/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.3344 - val_loss: 59.0753\n",
      "Epoch 896/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.3213 - val_loss: 59.0785\n",
      "Epoch 897/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.3003 - val_loss: 59.0628\n",
      "Epoch 898/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.3092 - val_loss: 59.0581\n",
      "Epoch 899/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 62.2948 - val_loss: 59.0577\n",
      "Epoch 900/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.3054 - val_loss: 59.0639\n",
      "Epoch 901/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 62.2853 - val_loss: 59.0665\n",
      "Epoch 902/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 62.2884 - val_loss: 59.0744\n",
      "Epoch 903/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.2802 - val_loss: 59.0713\n",
      "Epoch 904/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.2612 - val_loss: 59.0588\n",
      "Epoch 905/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 62.2577 - val_loss: 59.0414\n",
      "Epoch 906/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 62.2492 - val_loss: 59.0460\n",
      "Epoch 907/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 62.2512 - val_loss: 59.0239\n",
      "Epoch 908/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 62.2476 - val_loss: 59.0157\n",
      "Epoch 909/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.2457 - val_loss: 59.0112\n",
      "Epoch 910/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.2252 - val_loss: 58.9987\n",
      "Epoch 911/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.2287 - val_loss: 58.9790\n",
      "Epoch 912/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.2215 - val_loss: 58.9761\n",
      "Epoch 913/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.2179 - val_loss: 58.9844\n",
      "Epoch 914/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.2121 - val_loss: 58.9795\n",
      "Epoch 915/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.1992 - val_loss: 58.9680\n",
      "Epoch 916/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.1982 - val_loss: 58.9611\n",
      "Epoch 917/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.1745 - val_loss: 58.9425\n",
      "Epoch 918/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.1936 - val_loss: 58.9214\n",
      "Epoch 919/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.1942 - val_loss: 58.9335\n",
      "Epoch 920/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.1731 - val_loss: 58.9168\n",
      "Epoch 921/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.1796 - val_loss: 58.9308\n",
      "Epoch 922/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.1681 - val_loss: 58.9177\n",
      "Epoch 923/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.1580 - val_loss: 58.9278\n",
      "Epoch 924/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.1396 - val_loss: 58.9205\n",
      "Epoch 925/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.1417 - val_loss: 58.9132\n",
      "Epoch 926/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.1407 - val_loss: 58.8947\n",
      "Epoch 927/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.1171 - val_loss: 58.8918\n",
      "Epoch 928/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.1138 - val_loss: 58.8875\n",
      "Epoch 929/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.1094 - val_loss: 58.8835\n",
      "Epoch 930/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.1064 - val_loss: 58.8735\n",
      "Epoch 931/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.0967 - val_loss: 58.8603\n",
      "Epoch 932/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.0989 - val_loss: 58.8525\n",
      "Epoch 933/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.1016 - val_loss: 58.8554\n",
      "Epoch 934/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.0943 - val_loss: 58.8647\n",
      "Epoch 935/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.0927 - val_loss: 58.8568\n",
      "Epoch 936/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.0879 - val_loss: 58.8424\n",
      "Epoch 937/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 62.0720 - val_loss: 58.8313\n",
      "Epoch 938/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.0638 - val_loss: 58.8320\n",
      "Epoch 939/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.0671 - val_loss: 58.8210\n",
      "Epoch 940/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.0547 - val_loss: 58.7878\n",
      "Epoch 941/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.0391 - val_loss: 58.7838\n",
      "Epoch 942/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.0809 - val_loss: 58.7890\n",
      "Epoch 943/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.0548 - val_loss: 58.7982\n",
      "Epoch 944/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.0451 - val_loss: 58.7976\n",
      "Epoch 945/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.0305 - val_loss: 58.7783\n",
      "Epoch 946/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.0210 - val_loss: 58.7835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 947/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.9965 - val_loss: 58.7849\n",
      "Epoch 948/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.0133 - val_loss: 58.7810\n",
      "Epoch 949/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.0093 - val_loss: 58.7726\n",
      "Epoch 950/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.9961 - val_loss: 58.7764\n",
      "Epoch 951/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.9893 - val_loss: 58.7577\n",
      "Epoch 952/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.9956 - val_loss: 58.7549\n",
      "Epoch 953/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.9779 - val_loss: 58.7432\n",
      "Epoch 954/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.9609 - val_loss: 58.7351\n",
      "Epoch 955/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.9663 - val_loss: 58.7239\n",
      "Epoch 956/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.9588 - val_loss: 58.7145\n",
      "Epoch 957/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.9457 - val_loss: 58.6937\n",
      "Epoch 958/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.9502 - val_loss: 58.7034\n",
      "Epoch 959/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.9620 - val_loss: 58.6880\n",
      "Epoch 960/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.9307 - val_loss: 58.6962\n",
      "Epoch 961/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.9407 - val_loss: 58.7046\n",
      "Epoch 962/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.9461 - val_loss: 58.6960\n",
      "Epoch 963/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.9157 - val_loss: 58.6853\n",
      "Epoch 964/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.9091 - val_loss: 58.6808\n",
      "Epoch 965/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.9187 - val_loss: 58.6721\n",
      "Epoch 966/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.9009 - val_loss: 58.6707\n",
      "Epoch 967/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.9049 - val_loss: 58.6646\n",
      "Epoch 968/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.8816 - val_loss: 58.6504\n",
      "Epoch 969/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.8742 - val_loss: 58.6364\n",
      "Epoch 970/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.8664 - val_loss: 58.6368\n",
      "Epoch 971/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.8920 - val_loss: 58.6278\n",
      "Epoch 972/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.8628 - val_loss: 58.6199\n",
      "Epoch 973/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.8598 - val_loss: 58.6227\n",
      "Epoch 974/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.8585 - val_loss: 58.6034\n",
      "Epoch 975/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.8498 - val_loss: 58.6006\n",
      "Epoch 976/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.8498 - val_loss: 58.5840\n",
      "Epoch 977/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.8473 - val_loss: 58.5878\n",
      "Epoch 978/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.8405 - val_loss: 58.5980\n",
      "Epoch 979/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.8242 - val_loss: 58.5942\n",
      "Epoch 980/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.8123 - val_loss: 58.5888\n",
      "Epoch 981/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.8294 - val_loss: 58.5779\n",
      "Epoch 982/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.8005 - val_loss: 58.5691\n",
      "Epoch 983/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 61.7927 - val_loss: 58.5567\n",
      "Epoch 984/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 61.7859 - val_loss: 58.5426\n",
      "Epoch 985/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 61.7963 - val_loss: 58.5417\n",
      "Epoch 986/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 61.7974 - val_loss: 58.5563\n",
      "Epoch 987/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.7671 - val_loss: 58.5504\n",
      "Epoch 988/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.7829 - val_loss: 58.5464\n",
      "Epoch 989/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.7739 - val_loss: 58.5383\n",
      "Epoch 990/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.7591 - val_loss: 58.5339\n",
      "Epoch 991/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.7641 - val_loss: 58.5266\n",
      "Epoch 992/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.7627 - val_loss: 58.5349\n",
      "Epoch 993/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.7351 - val_loss: 58.5402\n",
      "Epoch 994/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.7515 - val_loss: 58.5325\n",
      "Epoch 995/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.7458 - val_loss: 58.5200\n",
      "Epoch 996/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.7371 - val_loss: 58.5135\n",
      "Epoch 997/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.7258 - val_loss: 58.5117\n",
      "Epoch 998/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.7098 - val_loss: 58.4947\n",
      "Epoch 999/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.7086 - val_loss: 58.4865\n",
      "Epoch 1000/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 61.7066 - val_loss: 58.4658\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(256,activation='relu',input_shape=(x_train.shape[1],)))\n",
    "model2.add(Dense(32,activation='linear'))\n",
    "model2.add(Dense(1))\n",
    "\n",
    "opt = keras.optimizers.SGD(learning_rate=1e-5)\n",
    "\n",
    "model2.compile (optimizer=opt,loss='MSE')\n",
    "hist2 = model2.fit(x_train,y_train,epochs=1000,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c0b520ca",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 379.1604 - val_loss: 156.9340\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 112.4667 - val_loss: 113.9103\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 95.9280 - val_loss: 100.7505\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 86.9140 - val_loss: 90.9771\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 81.6877 - val_loss: 84.8293\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 77.6155 - val_loss: 78.9327\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 74.9725 - val_loss: 78.0173\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 73.8480 - val_loss: 73.5895\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 72.1107 - val_loss: 71.2635\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 70.7679 - val_loss: 69.0771\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 69.7155 - val_loss: 69.2305\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 70.1443 - val_loss: 66.2790\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.2666 - val_loss: 65.6983\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 67.8654 - val_loss: 66.3025\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 67.3237 - val_loss: 63.9374\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.6548 - val_loss: 63.5160\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.4415 - val_loss: 63.0529\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.6242 - val_loss: 62.6708\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 65.3621 - val_loss: 62.1765\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 65.1940 - val_loss: 61.8600\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.9954 - val_loss: 61.5107\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 64.7969 - val_loss: 60.9274\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 64.2540 - val_loss: 60.5491\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.9995 - val_loss: 60.2154\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.4440 - val_loss: 60.0928\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.9661 - val_loss: 60.4929\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.3332 - val_loss: 60.8964\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.2717 - val_loss: 60.5418\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.1589 - val_loss: 59.9123\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.2746 - val_loss: 59.9802\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.3354 - val_loss: 59.4016\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.7172 - val_loss: 59.6898\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.3866 - val_loss: 59.3917\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 62.4262 - val_loss: 60.4172\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 61.9585 - val_loss: 58.7764\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.7293 - val_loss: 58.9178\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 61.8841 - val_loss: 58.8874\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 61.5288 - val_loss: 58.7754\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 60.8661 - val_loss: 61.2613\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 60.9610 - val_loss: 58.2707\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 61.6649 - val_loss: 58.1611\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 60.7678 - val_loss: 57.8176\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 61.1882 - val_loss: 58.9183\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 60.7311 - val_loss: 57.9137\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 60.7492 - val_loss: 57.5904\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 60.8912 - val_loss: 58.5973\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 60.7509 - val_loss: 57.8107\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 60.9244 - val_loss: 58.4001\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 60.5547 - val_loss: 57.9517\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 60.0139 - val_loss: 59.7863\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 61.0979 - val_loss: 59.2321\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.1058 - val_loss: 60.1198\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 60.4107 - val_loss: 57.5430\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 60.3685 - val_loss: 57.9392\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 59.9588 - val_loss: 56.9236\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 59.7401 - val_loss: 56.7713\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 59.5713 - val_loss: 58.9199\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 59.7750 - val_loss: 57.3477\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 59.0824 - val_loss: 56.4790\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 59.3450 - val_loss: 58.5974\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 59.1538 - val_loss: 56.3873\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 59.1258 - val_loss: 56.2693\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 59.0255 - val_loss: 56.3791\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 59.0734 - val_loss: 57.0104\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 59.1357 - val_loss: 57.0667\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 58.7190 - val_loss: 58.3813\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 58.7314 - val_loss: 56.6679\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 59.0890 - val_loss: 56.1328\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 58.4214 - val_loss: 56.7682\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 59.2287 - val_loss: 56.6263\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 58.2109 - val_loss: 59.3149\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 58.7740 - val_loss: 56.0350\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 58.6991 - val_loss: 57.4261\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 58.5878 - val_loss: 59.7836\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 59.1602 - val_loss: 56.6403\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 58.6704 - val_loss: 56.4238\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 58.2394 - val_loss: 55.9155\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 57.9569 - val_loss: 55.9588\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 58.2008 - val_loss: 56.9204\n",
      "Epoch 80/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 58.4539 - val_loss: 55.6409\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 57.8261 - val_loss: 55.6399\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 58.2412 - val_loss: 55.8159\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 57.9278 - val_loss: 56.0593\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 58.5930 - val_loss: 55.9820\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 58.2348 - val_loss: 58.2828\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 58.1848 - val_loss: 56.4792\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 58.9524 - val_loss: 56.1714\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 58.1398 - val_loss: 55.6341\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 57.6878 - val_loss: 55.5984\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 57.5787 - val_loss: 55.3759\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 57.6311 - val_loss: 57.1866\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 57.9665 - val_loss: 55.6459\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 57.5179 - val_loss: 57.0466\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 57.4729 - val_loss: 55.6179\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 57.2236 - val_loss: 56.7515\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 57.2369 - val_loss: 55.9083\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 57.5053 - val_loss: 55.3378\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 57.2072 - val_loss: 55.4097\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.8457 - val_loss: 55.3195\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.8266 - val_loss: 55.1529\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.7886 - val_loss: 55.6250\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.7094 - val_loss: 56.0048\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 57.0337 - val_loss: 54.8514\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.7664 - val_loss: 55.7031\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.8880 - val_loss: 54.8053\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.6612 - val_loss: 55.0943\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.5476 - val_loss: 57.0378\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.7789 - val_loss: 55.3811\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 57.6541 - val_loss: 54.8005\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.2420 - val_loss: 56.0084\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.4795 - val_loss: 54.7764\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.2850 - val_loss: 54.7817\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.4702 - val_loss: 54.7664\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.9956 - val_loss: 56.2696\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.2916 - val_loss: 55.3592\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.3644 - val_loss: 55.1029\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.4532 - val_loss: 56.1310\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.8689 - val_loss: 56.1275\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.6030 - val_loss: 54.7378\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.5002 - val_loss: 54.6970\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.1953 - val_loss: 54.7617\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.7777 - val_loss: 54.5360\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.4594 - val_loss: 54.8911\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.4841 - val_loss: 56.9524\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.7643 - val_loss: 56.9392\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.0928 - val_loss: 55.1386\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.6226 - val_loss: 54.2656\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.8170 - val_loss: 54.3847\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.7820 - val_loss: 55.6576\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.7693 - val_loss: 54.2643\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.7317 - val_loss: 54.0278\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 55.4955 - val_loss: 54.2423\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.7779 - val_loss: 54.4870\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.5558 - val_loss: 54.3737\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 54.9844 - val_loss: 54.5344\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.5185 - val_loss: 53.9377\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 54.8742 - val_loss: 53.9767\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.4789 - val_loss: 54.1365\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.1897 - val_loss: 53.9274\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 54.8535 - val_loss: 54.4914\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.8715 - val_loss: 54.7967\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.6776 - val_loss: 54.2594\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 54.5581 - val_loss: 54.7213\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.3017 - val_loss: 53.5632\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.5353 - val_loss: 53.8277\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 54.4409 - val_loss: 53.7613\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 54.6417 - val_loss: 54.6633\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 54.9744 - val_loss: 53.7333\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.5713 - val_loss: 54.5043\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.1085 - val_loss: 54.0620\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 54.0076 - val_loss: 59.8020\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.6740 - val_loss: 53.8161\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 54.9889 - val_loss: 53.5977\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 54.6506 - val_loss: 55.4627\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.0468 - val_loss: 54.6192\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.5154 - val_loss: 57.5921\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 54.4185 - val_loss: 53.4231\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 54.7649 - val_loss: 53.7114\n",
      "Epoch 159/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 4ms/step - loss: 54.6267 - val_loss: 54.2216\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 54.1278 - val_loss: 53.2286\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 54.2530 - val_loss: 53.1641\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 53.6773 - val_loss: 63.2236\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 55.7815 - val_loss: 54.3349\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.0296 - val_loss: 54.2942\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 54.4782 - val_loss: 53.4846\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 54.0736 - val_loss: 53.6122\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.9462 - val_loss: 53.3494\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 54.6061 - val_loss: 54.2145\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.3160 - val_loss: 53.9500\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 54.4938 - val_loss: 56.3112\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.7909 - val_loss: 53.2930\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.4962 - val_loss: 56.2555\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.7682 - val_loss: 53.0095\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.5759 - val_loss: 53.0271\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.4927 - val_loss: 53.5962\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.6906 - val_loss: 53.5765\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 53.7421 - val_loss: 52.7375\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 53.6291 - val_loss: 52.8786\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 53.0800 - val_loss: 53.5278\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 53.6961 - val_loss: 52.4297\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 54.0895 - val_loss: 56.7508\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.3667 - val_loss: 54.7368\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.2382 - val_loss: 53.2709\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.8795 - val_loss: 53.4059\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.4312 - val_loss: 53.4580\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.5605 - val_loss: 52.7929\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.4612 - val_loss: 53.7375\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 52.5039 - val_loss: 52.7528\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.2656 - val_loss: 53.1678\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.4397 - val_loss: 52.8916\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.1825 - val_loss: 52.7934\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.2175 - val_loss: 55.8949\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 53.2132 - val_loss: 52.4289\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 52.6287 - val_loss: 53.3033\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.7759 - val_loss: 55.9798\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.5946 - val_loss: 56.5175\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 52.7264 - val_loss: 52.3256\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.4924 - val_loss: 54.7057\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.4804 - val_loss: 52.6383\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 52.5366 - val_loss: 52.6107\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 52.3572 - val_loss: 52.2726\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 51.7830 - val_loss: 53.1267\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 52.6478 - val_loss: 52.1471\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 54.4924 - val_loss: 52.6225\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 52.2768 - val_loss: 52.5115\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.0832 - val_loss: 55.3754\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 52.4979 - val_loss: 52.2662\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 52.3080 - val_loss: 52.3697\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.2478 - val_loss: 54.6974\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 52.3309 - val_loss: 55.3175\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 52.4731 - val_loss: 53.3126\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 52.1912 - val_loss: 51.9248\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 52.4036 - val_loss: 53.4493\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 52.3237 - val_loss: 54.9421\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 51.9466 - val_loss: 53.0165\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 52.4657 - val_loss: 54.8238\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 52.0437 - val_loss: 54.1808\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 52.2232 - val_loss: 54.8537\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 52.3819 - val_loss: 55.2601\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 52.0772 - val_loss: 55.4622\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 52.4662 - val_loss: 51.7598\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 51.6251 - val_loss: 51.5037\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 51.5195 - val_loss: 51.3536\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 51.3106 - val_loss: 52.1452\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 51.3152 - val_loss: 54.2748\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 52.2499 - val_loss: 52.8189\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 51.3535 - val_loss: 51.4604\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 51.0541 - val_loss: 58.0571\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 52.1346 - val_loss: 51.7345\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 51.2477 - val_loss: 52.0675\n",
      "Epoch 231/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 52.2422 - val_loss: 52.1736\n",
      "Epoch 232/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 51.3315 - val_loss: 55.0480\n",
      "Epoch 233/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 51.0504 - val_loss: 57.2603\n",
      "Epoch 234/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 51.0927 - val_loss: 52.2315\n",
      "Epoch 235/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 50.7573 - val_loss: 51.5184\n",
      "Epoch 236/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 52.4208 - val_loss: 51.4924\n",
      "Epoch 237/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 50.7923 - val_loss: 51.2224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 51.6425 - val_loss: 52.2509\n",
      "Epoch 239/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 52.1703 - val_loss: 52.9359\n",
      "Epoch 240/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 50.8451 - val_loss: 52.7986\n",
      "Epoch 241/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 50.8300 - val_loss: 51.3299\n",
      "Epoch 242/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 50.5606 - val_loss: 52.9271\n",
      "Epoch 243/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 50.6599 - val_loss: 53.4397\n",
      "Epoch 244/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 50.5577 - val_loss: 53.1223\n",
      "Epoch 245/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 51.4370 - val_loss: 51.0132\n",
      "Epoch 246/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 52.9234 - val_loss: 52.9165\n",
      "Epoch 247/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 51.2193 - val_loss: 51.5313\n",
      "Epoch 248/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 50.6346 - val_loss: 50.7305\n",
      "Epoch 249/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 50.1069 - val_loss: 51.2975\n",
      "Epoch 250/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 51.0721 - val_loss: 54.8330\n",
      "Epoch 251/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 51.0841 - val_loss: 51.7352\n",
      "Epoch 252/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 50.8370 - val_loss: 51.2655\n",
      "Epoch 253/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 51.7429 - val_loss: 50.7010\n",
      "Epoch 254/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 50.7739 - val_loss: 50.9068\n",
      "Epoch 255/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 51.4268 - val_loss: 52.2544\n",
      "Epoch 256/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 50.6423 - val_loss: 50.4610\n",
      "Epoch 257/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 50.2312 - val_loss: 50.8962\n",
      "Epoch 258/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 51.3607 - val_loss: 50.6321\n",
      "Epoch 259/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 52.3324 - val_loss: 51.0505\n",
      "Epoch 260/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 49.8189 - val_loss: 55.1617\n",
      "Epoch 261/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 50.7529 - val_loss: 51.4022\n",
      "Epoch 262/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 50.0676 - val_loss: 51.1504\n",
      "Epoch 263/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 50.4260 - val_loss: 51.7750\n",
      "Epoch 264/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 49.6815 - val_loss: 50.4762\n",
      "Epoch 265/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 49.3338 - val_loss: 55.9543\n",
      "Epoch 266/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 50.4577 - val_loss: 49.8464\n",
      "Epoch 267/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 50.0175 - val_loss: 50.5526\n",
      "Epoch 268/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 50.8082 - val_loss: 52.1226\n",
      "Epoch 269/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 50.1719 - val_loss: 50.2678\n",
      "Epoch 270/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 49.6148 - val_loss: 50.6300\n",
      "Epoch 271/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 50.4326 - val_loss: 53.2812\n",
      "Epoch 272/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 50.3706 - val_loss: 50.9471\n",
      "Epoch 273/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 50.8913 - val_loss: 49.9364\n",
      "Epoch 274/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 49.2077 - val_loss: 50.8911\n",
      "Epoch 275/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 49.8914 - val_loss: 50.2275\n",
      "Epoch 276/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 49.3644 - val_loss: 50.1050\n",
      "Epoch 277/1000\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 51.0742 - val_loss: 52.5789\n",
      "Epoch 278/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 49.4550 - val_loss: 49.7505\n",
      "Epoch 279/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 49.4962 - val_loss: 49.7573\n",
      "Epoch 280/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 49.6608 - val_loss: 50.0396\n",
      "Epoch 281/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 48.9836 - val_loss: 51.1781\n",
      "Epoch 282/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 50.0946 - val_loss: 50.2004\n",
      "Epoch 283/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 48.3860 - val_loss: 50.9578\n",
      "Epoch 284/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 50.7728 - val_loss: 55.8771\n",
      "Epoch 285/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 49.5943 - val_loss: 50.3147\n",
      "Epoch 286/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 48.3560 - val_loss: 49.3218\n",
      "Epoch 287/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 48.3936 - val_loss: 49.1725\n",
      "Epoch 288/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 48.7168 - val_loss: 50.0139\n",
      "Epoch 289/1000\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 48.4629 - val_loss: 51.4342\n",
      "Epoch 290/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 49.6895 - val_loss: 49.0639\n",
      "Epoch 291/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 48.8979 - val_loss: 49.5132\n",
      "Epoch 292/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 48.3810 - val_loss: 52.9298\n",
      "Epoch 293/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 49.5867 - val_loss: 52.6278\n",
      "Epoch 294/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 48.4625 - val_loss: 53.6647\n",
      "Epoch 295/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 49.1291 - val_loss: 54.6722\n",
      "Epoch 296/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 47.7182 - val_loss: 49.3774\n",
      "Epoch 297/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 47.7924 - val_loss: 48.8042\n",
      "Epoch 298/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 49.3899 - val_loss: 53.1717\n",
      "Epoch 299/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 48.0948 - val_loss: 51.4668\n",
      "Epoch 300/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 49.6321 - val_loss: 50.0312\n",
      "Epoch 301/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 48.8693 - val_loss: 48.8206\n",
      "Epoch 302/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 48.4900 - val_loss: 49.4612\n",
      "Epoch 303/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 47.6370 - val_loss: 53.2785\n",
      "Epoch 304/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 49.4193 - val_loss: 49.1151\n",
      "Epoch 305/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 47.4243 - val_loss: 49.6017\n",
      "Epoch 306/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 47.7580 - val_loss: 51.1525\n",
      "Epoch 307/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 49.7665 - val_loss: 48.9345\n",
      "Epoch 308/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 47.6137 - val_loss: 50.1878\n",
      "Epoch 309/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 48.5290 - val_loss: 52.4097\n",
      "Epoch 310/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 47.4725 - val_loss: 48.2384\n",
      "Epoch 311/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 48.4955 - val_loss: 51.5629\n",
      "Epoch 312/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 47.3284 - val_loss: 48.6443\n",
      "Epoch 313/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 49.4509 - val_loss: 48.6834\n",
      "Epoch 314/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 48.7747 - val_loss: 50.7770\n",
      "Epoch 315/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 48.2310 - val_loss: 50.0962\n",
      "Epoch 316/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 49.6550 - val_loss: 50.3384\n",
      "Epoch 317/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 47.4184 - val_loss: 50.7093\n",
      "Epoch 318/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 49.1164 - val_loss: 49.8278\n",
      "Epoch 319/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 47.7649 - val_loss: 48.1441\n",
      "Epoch 320/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 47.1456 - val_loss: 48.5121\n",
      "Epoch 321/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 47.2761 - val_loss: 48.2394\n",
      "Epoch 322/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 50.3664 - val_loss: 49.9346\n",
      "Epoch 323/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 48.7883 - val_loss: 53.4003\n",
      "Epoch 324/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 48.5114 - val_loss: 47.7787\n",
      "Epoch 325/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 46.5186 - val_loss: 48.2810\n",
      "Epoch 326/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 46.5774 - val_loss: 48.3108\n",
      "Epoch 327/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 46.8431 - val_loss: 55.4884\n",
      "Epoch 328/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 48.6724 - val_loss: 49.5197\n",
      "Epoch 329/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 48.4669 - val_loss: 47.4926\n",
      "Epoch 330/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 48.2786 - val_loss: 48.8942\n",
      "Epoch 331/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 47.0687 - val_loss: 48.9415\n",
      "Epoch 332/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 46.6028 - val_loss: 47.7831\n",
      "Epoch 333/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 48.8779 - val_loss: 47.1868\n",
      "Epoch 334/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 46.9139 - val_loss: 51.2252\n",
      "Epoch 335/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 47.3409 - val_loss: 52.1053\n",
      "Epoch 336/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 47.5498 - val_loss: 47.6883\n",
      "Epoch 337/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 46.1854 - val_loss: 49.7591\n",
      "Epoch 338/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 46.0834 - val_loss: 47.1913\n",
      "Epoch 339/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 45.8089 - val_loss: 47.2958\n",
      "Epoch 340/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 46.9003 - val_loss: 47.6435\n",
      "Epoch 341/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 45.7968 - val_loss: 47.7491\n",
      "Epoch 342/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 46.3087 - val_loss: 50.5525\n",
      "Epoch 343/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 46.9193 - val_loss: 50.3108\n",
      "Epoch 344/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 45.8815 - val_loss: 46.9578\n",
      "Epoch 345/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 46.2810 - val_loss: 47.1051\n",
      "Epoch 346/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 45.5826 - val_loss: 49.7415\n",
      "Epoch 347/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 47.5347 - val_loss: 54.3114\n",
      "Epoch 348/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 47.1538 - val_loss: 48.7532\n",
      "Epoch 349/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 45.8246 - val_loss: 47.1765\n",
      "Epoch 350/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 46.0525 - val_loss: 48.6258\n",
      "Epoch 351/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 47.6621 - val_loss: 50.7671\n",
      "Epoch 352/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 48.7435 - val_loss: 46.5519\n",
      "Epoch 353/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 47.4796 - val_loss: 47.1093\n",
      "Epoch 354/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 47.2105 - val_loss: 50.3681\n",
      "Epoch 355/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 46.2446 - val_loss: 48.0905\n",
      "Epoch 356/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 46.7992 - val_loss: 46.0832\n",
      "Epoch 357/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 46.7769 - val_loss: 47.7923\n",
      "Epoch 358/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 44.6940 - val_loss: 52.3632\n",
      "Epoch 359/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 47.6784 - val_loss: 59.7277\n",
      "Epoch 360/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 47.2539 - val_loss: 47.0893\n",
      "Epoch 361/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 45.0484 - val_loss: 54.6090\n",
      "Epoch 362/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 48.4465 - val_loss: 49.3668\n",
      "Epoch 363/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 46.3290 - val_loss: 55.9307\n",
      "Epoch 364/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 48.5020 - val_loss: 46.4406\n",
      "Epoch 365/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 46.7749 - val_loss: 45.8528\n",
      "Epoch 366/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 46.3231 - val_loss: 46.0215\n",
      "Epoch 367/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 48.5390 - val_loss: 50.0259\n",
      "Epoch 368/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 47.2407 - val_loss: 46.2208\n",
      "Epoch 369/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 47.8409 - val_loss: 46.7252\n",
      "Epoch 370/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 45.9372 - val_loss: 48.2804\n",
      "Epoch 371/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 46.2567 - val_loss: 46.2754\n",
      "Epoch 372/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 49.0238 - val_loss: 54.6336\n",
      "Epoch 373/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 46.6606 - val_loss: 46.0310\n",
      "Epoch 374/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 44.7931 - val_loss: 50.3498\n",
      "Epoch 375/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 50.6250 - val_loss: 48.8343\n",
      "Epoch 376/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 45.9797 - val_loss: 47.1926\n",
      "Epoch 377/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 49.8185 - val_loss: 46.4307\n",
      "Epoch 378/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 44.5138 - val_loss: 46.3661\n",
      "Epoch 379/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 44.3119 - val_loss: 50.9148\n",
      "Epoch 380/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 44.5330 - val_loss: 45.3686\n",
      "Epoch 381/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 45.6830 - val_loss: 47.0614\n",
      "Epoch 382/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 45.8171 - val_loss: 47.1797\n",
      "Epoch 383/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 44.0820 - val_loss: 52.9704\n",
      "Epoch 384/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 45.7885 - val_loss: 45.2282\n",
      "Epoch 385/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 44.9568 - val_loss: 45.2513\n",
      "Epoch 386/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 43.8898 - val_loss: 45.0319\n",
      "Epoch 387/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 45.2895 - val_loss: 50.2209\n",
      "Epoch 388/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 43.3167 - val_loss: 44.9628\n",
      "Epoch 389/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 44.1724 - val_loss: 46.6015\n",
      "Epoch 390/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 43.6514 - val_loss: 46.0041\n",
      "Epoch 391/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 44.7914 - val_loss: 48.2854\n",
      "Epoch 392/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 45.6040 - val_loss: 44.9039\n",
      "Epoch 393/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 46.2470 - val_loss: 49.0241\n",
      "Epoch 394/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 44.8897 - val_loss: 49.4064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 395/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 47.7448 - val_loss: 55.3002\n",
      "Epoch 396/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 43.8358 - val_loss: 45.5945\n",
      "Epoch 397/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 43.6398 - val_loss: 45.4266\n",
      "Epoch 398/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 47.4135 - val_loss: 50.9473\n",
      "Epoch 399/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 43.7370 - val_loss: 47.9219\n",
      "Epoch 400/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 44.9225 - val_loss: 53.4808\n",
      "Epoch 401/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 43.7886 - val_loss: 46.1467\n",
      "Epoch 402/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 44.3511 - val_loss: 46.0317\n",
      "Epoch 403/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 43.9163 - val_loss: 44.4019\n",
      "Epoch 404/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 42.7040 - val_loss: 47.4858\n",
      "Epoch 405/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 42.8943 - val_loss: 45.1065\n",
      "Epoch 406/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 43.7211 - val_loss: 57.9036\n",
      "Epoch 407/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 43.4622 - val_loss: 47.2240\n",
      "Epoch 408/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 43.3125 - val_loss: 44.4823\n",
      "Epoch 409/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 43.1463 - val_loss: 45.3546\n",
      "Epoch 410/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 45.1897 - val_loss: 44.8505\n",
      "Epoch 411/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 41.5347 - val_loss: 79.1196\n",
      "Epoch 412/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 44.9184 - val_loss: 46.0801\n",
      "Epoch 413/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 44.2595 - val_loss: 47.1113\n",
      "Epoch 414/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 44.9907 - val_loss: 44.6659\n",
      "Epoch 415/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 42.2872 - val_loss: 43.5645\n",
      "Epoch 416/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 44.2452 - val_loss: 46.6528\n",
      "Epoch 417/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 43.3144 - val_loss: 43.9232\n",
      "Epoch 418/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 43.9171 - val_loss: 43.6029\n",
      "Epoch 419/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 43.8775 - val_loss: 43.9128\n",
      "Epoch 420/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 42.4258 - val_loss: 43.0515\n",
      "Epoch 421/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 42.7941 - val_loss: 54.5136\n",
      "Epoch 422/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 45.0542 - val_loss: 49.7165\n",
      "Epoch 423/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 48.3105 - val_loss: 43.2267\n",
      "Epoch 424/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 42.9634 - val_loss: 49.4815\n",
      "Epoch 425/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 44.3711 - val_loss: 44.8138\n",
      "Epoch 426/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 41.6959 - val_loss: 50.8517\n",
      "Epoch 427/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 44.8712 - val_loss: 46.8015\n",
      "Epoch 428/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 47.2438 - val_loss: 49.3158\n",
      "Epoch 429/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 44.7248 - val_loss: 43.2284\n",
      "Epoch 430/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 41.7317 - val_loss: 51.7784\n",
      "Epoch 431/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 42.8660 - val_loss: 51.4992\n",
      "Epoch 432/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 42.7467 - val_loss: 43.0557\n",
      "Epoch 433/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 42.4787 - val_loss: 56.6520\n",
      "Epoch 434/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 47.0548 - val_loss: 46.5459\n",
      "Epoch 435/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 41.7073 - val_loss: 44.1202\n",
      "Epoch 436/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 43.5033 - val_loss: 43.3308\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(256,activation='relu',input_shape=(x_train.shape[1],)))\n",
    "model3.add(Dense(1))\n",
    "es = EarlyStopping(monitor='loss',mode='min',patience=25)\n",
    "opt = keras.optimizers.SGD(learning_rate=1e-3)\n",
    "model3.compile(optimizer=opt,loss='MSE')\n",
    "hist3=model3.fit(x_train,y_train,epochs=1000,callbacks=[es],validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d93e600d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 [==============================] - 1s 14ms/step - loss: 369.0586 - val_loss: 152.8752\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 114.3239 - val_loss: 112.6892\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 95.5138 - val_loss: 101.7395\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 88.9604 - val_loss: 89.6710\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 84.9687 - val_loss: 82.6064\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 82.2979 - val_loss: 77.6135\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 73.8421 - val_loss: 75.1391\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 76.9700 - val_loss: 72.1234\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 70.7404 - val_loss: 69.7957\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 71.3880 - val_loss: 68.3176\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 73.6236 - val_loss: 67.4555\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 72.6247 - val_loss: 66.5571\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 71.6498 - val_loss: 64.5574\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 71.8687 - val_loss: 64.1952\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 70.7783 - val_loss: 63.3514\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 70.8863 - val_loss: 63.1542\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 71.3228 - val_loss: 62.2111\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 69.8601 - val_loss: 61.7937\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 68.8834 - val_loss: 61.9809\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 68.4092 - val_loss: 61.7731\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 66.4761 - val_loss: 62.6339\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 64.1919 - val_loss: 60.9542\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.0112 - val_loss: 62.7200\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 65.7399 - val_loss: 59.9940\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 69.5622 - val_loss: 59.5865\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 66.9027 - val_loss: 61.2064\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 67.4740 - val_loss: 59.2654\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 65.2732 - val_loss: 59.2348\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 65.1166 - val_loss: 58.9659\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 66.0286 - val_loss: 59.1738\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 67.1622 - val_loss: 59.3576\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 67.5407 - val_loss: 59.4501\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 63.7088 - val_loss: 58.4638\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.3464 - val_loss: 58.1545\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 65.1675 - val_loss: 58.8379\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 64.3234 - val_loss: 58.7040\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.9106 - val_loss: 58.3780\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 63.6132 - val_loss: 58.2329\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 64.6837 - val_loss: 58.2193\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 64.3397 - val_loss: 58.3552\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 64.0329 - val_loss: 57.6278\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 64.0691 - val_loss: 57.8403\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 63.8736 - val_loss: 58.7990\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 64.2315 - val_loss: 59.3710\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 63.1784 - val_loss: 57.1861\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 64.7305 - val_loss: 57.8120\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 62.0443 - val_loss: 57.2757\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 62.1120 - val_loss: 57.0353\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.6464 - val_loss: 58.5759\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.9264 - val_loss: 57.0431\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 60.1172 - val_loss: 58.1791\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.0494 - val_loss: 57.1421\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 60.9650 - val_loss: 59.4442\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 60.8742 - val_loss: 57.6660\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 62.5910 - val_loss: 56.6079\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 63.4788 - val_loss: 56.7268\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.6279 - val_loss: 56.6662\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 60.7741 - val_loss: 56.6280\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 63.8713 - val_loss: 56.4401\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 63.3732 - val_loss: 58.0356\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 60.7827 - val_loss: 58.3161\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 62.9720 - val_loss: 56.6695\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 63.3638 - val_loss: 56.4100\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 62.9698 - val_loss: 59.5209\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 60.8314 - val_loss: 57.1059\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 59.1654 - val_loss: 56.9558\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 60.2779 - val_loss: 56.7979\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 61.4067 - val_loss: 61.7410\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 61.6390 - val_loss: 57.7880\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 60.1149 - val_loss: 58.5302\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 63.4752 - val_loss: 57.1223\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 60.6090 - val_loss: 55.7071\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 60.1717 - val_loss: 55.7205\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 59.9650 - val_loss: 56.6009\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 62.3533 - val_loss: 55.4058\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 59.9746 - val_loss: 56.0364\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 61.2355 - val_loss: 55.3361\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.2008 - val_loss: 55.5091\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 60.4237 - val_loss: 55.7712\n",
      "Epoch 80/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 58.6968 - val_loss: 56.2140\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 59.2595 - val_loss: 55.6799\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 58.5656 - val_loss: 55.8077\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 59.6585 - val_loss: 56.6103\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 61.3619 - val_loss: 57.0467\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 57.5011 - val_loss: 56.2500\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 59.1207 - val_loss: 56.4236\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 58.4852 - val_loss: 55.2382\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 59.6124 - val_loss: 56.3955\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 59.4383 - val_loss: 58.1866\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 59.7071 - val_loss: 57.6003\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 60.1622 - val_loss: 54.9044\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 59.4135 - val_loss: 55.8888\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 59.2865 - val_loss: 57.0157\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 60.7108 - val_loss: 55.7174\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 59.3266 - val_loss: 55.5263\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 59.8169 - val_loss: 57.4150\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 59.7639 - val_loss: 55.8905\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 60.0351 - val_loss: 55.7773\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 57.4559 - val_loss: 55.1730\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 57.4633 - val_loss: 54.9842\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 59.5464 - val_loss: 54.7054\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 58.5827 - val_loss: 55.4912\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 58.3166 - val_loss: 54.6450\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 57.5015 - val_loss: 55.1466\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 59.1480 - val_loss: 56.2798\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 58.5870 - val_loss: 55.0607\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.8039 - val_loss: 55.0125\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 58.5929 - val_loss: 55.3003\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 58.4910 - val_loss: 54.8825\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 60.4664 - val_loss: 56.2704\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 58.3899 - val_loss: 55.1625\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 58.5625 - val_loss: 54.2053\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 58.9460 - val_loss: 54.0761\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 59.5038 - val_loss: 54.4415\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 60.2335 - val_loss: 54.4566\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 58.8150 - val_loss: 54.9276\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 59.0621 - val_loss: 55.7943\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 58.2689 - val_loss: 54.6360\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 58.2076 - val_loss: 54.0510\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 60.5858 - val_loss: 55.5368\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 58.3358 - val_loss: 54.8444\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 57.6838 - val_loss: 54.3310\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 57.0155 - val_loss: 53.7629\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 58.0770 - val_loss: 54.4355\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 56.3562 - val_loss: 53.6342\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 57.5830 - val_loss: 53.9573\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 59.4390 - val_loss: 55.2876\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 57.7130 - val_loss: 55.6960\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 57.6491 - val_loss: 54.2095\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 58.0989 - val_loss: 53.9541\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 58.7032 - val_loss: 55.1867\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 58.9716 - val_loss: 53.5698\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 58.0931 - val_loss: 56.3262\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 60.0442 - val_loss: 54.3453\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 56.8432 - val_loss: 53.3766\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 58.1746 - val_loss: 53.7589\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 58.6957 - val_loss: 54.9972\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 57.9142 - val_loss: 53.6549\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 56.1054 - val_loss: 55.5786\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 54.6801 - val_loss: 54.2594\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 57.0230 - val_loss: 55.5353\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 58.8932 - val_loss: 56.9520\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 57.6738 - val_loss: 54.0289\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 58.1723 - val_loss: 53.3605\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.8272 - val_loss: 53.5967\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 55.1884 - val_loss: 53.6502\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 56.1642 - val_loss: 53.1087\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 57.5994 - val_loss: 55.1869\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.8492 - val_loss: 53.8251\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 57.7856 - val_loss: 53.6714\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 54.7651 - val_loss: 53.1546\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 56.6685 - val_loss: 53.6176\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 57.1112 - val_loss: 53.6274\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 56.7151 - val_loss: 55.9211\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 56.2564 - val_loss: 53.0442\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 56.9655 - val_loss: 53.6546\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 58.1359 - val_loss: 54.6904\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 56.4731 - val_loss: 54.0006\n",
      "Epoch 159/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 56.4042 - val_loss: 53.0488\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 55.0020 - val_loss: 53.9467\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 54.7703 - val_loss: 54.3471\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 55.7045 - val_loss: 53.1665\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 54.0199 - val_loss: 54.4019\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 56.3026 - val_loss: 56.0726\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 57.8681 - val_loss: 53.0626\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 56.3870 - val_loss: 52.9381\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 54.6814 - val_loss: 52.6525\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 54.7094 - val_loss: 52.9554\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 55.5200 - val_loss: 54.1532\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 54.9170 - val_loss: 52.7504\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 55.9955 - val_loss: 52.9554\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 55.3546 - val_loss: 52.6475\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 55.8824 - val_loss: 52.7489\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 57.8614 - val_loss: 52.4994\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 55.6306 - val_loss: 52.6076\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 54.5862 - val_loss: 52.6534\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 56.0413 - val_loss: 53.8016\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 54.3726 - val_loss: 52.2709\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 54.3926 - val_loss: 53.5954\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 58.4212 - val_loss: 51.8107\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.8245 - val_loss: 51.9466\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.7297 - val_loss: 53.5560\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 54.5379 - val_loss: 52.8869\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.7987 - val_loss: 53.9869\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 54.7719 - val_loss: 52.2176\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 57.2099 - val_loss: 52.1138\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 57.1013 - val_loss: 52.0710\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.0473 - val_loss: 58.2360\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.8531 - val_loss: 54.1958\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 54.5494 - val_loss: 54.2173\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 57.1677 - val_loss: 51.7384\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 54.7315 - val_loss: 52.3690\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 51.6074 - val_loss: 51.7554\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 57.1123 - val_loss: 52.1922\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 54.5526 - val_loss: 52.8645\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 54.6644 - val_loss: 52.3761\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 54.5081 - val_loss: 52.9197\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 57.3354 - val_loss: 52.4660\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.3540 - val_loss: 51.9907\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 56.2103 - val_loss: 52.0704\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 54.6627 - val_loss: 53.2744\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.2917 - val_loss: 51.6414\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.6405 - val_loss: 51.5593\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 56.8865 - val_loss: 53.0434\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.6314 - val_loss: 51.7357\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.5505 - val_loss: 51.8648\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 53.2772 - val_loss: 51.5363\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 54.0152 - val_loss: 51.4300\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 53.3192 - val_loss: 51.4611\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.0199 - val_loss: 51.7110\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 54.0818 - val_loss: 52.7172\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 53.7958 - val_loss: 52.0841\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.9990 - val_loss: 53.9958\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 54.5422 - val_loss: 51.3944\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 54.4772 - val_loss: 57.6810\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 54.1004 - val_loss: 53.0937\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 54.3818 - val_loss: 56.8745\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 54.5501 - val_loss: 51.2188\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 52.6241 - val_loss: 52.8070\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 54.6637 - val_loss: 51.5206\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 54.1710 - val_loss: 51.4243\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 54.5883 - val_loss: 54.0334\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 55.1957 - val_loss: 52.9515\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 54.8905 - val_loss: 51.8610\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 52.3262 - val_loss: 54.3580\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 54.4283 - val_loss: 52.3554\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 54.6956 - val_loss: 50.7835\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 53.5150 - val_loss: 51.7381\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 53.6934 - val_loss: 53.3769\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 55.3216 - val_loss: 50.7321\n",
      "Epoch 231/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 53.6742 - val_loss: 50.8017\n",
      "Epoch 232/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 52.3582 - val_loss: 51.0657\n",
      "Epoch 233/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 52.8502 - val_loss: 51.2307\n",
      "Epoch 234/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 53.6085 - val_loss: 51.9889\n",
      "Epoch 235/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 54.6035 - val_loss: 54.2624\n",
      "Epoch 236/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 55.4016 - val_loss: 51.6525\n",
      "Epoch 237/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 51.7353 - val_loss: 51.8763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 53.1039 - val_loss: 52.5592\n",
      "Epoch 239/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 52.0068 - val_loss: 50.6823\n",
      "Epoch 240/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 53.6320 - val_loss: 50.2424\n",
      "Epoch 241/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 52.9227 - val_loss: 52.5130\n",
      "Epoch 242/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 53.2244 - val_loss: 50.3022\n",
      "Epoch 243/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 51.4904 - val_loss: 50.9195\n",
      "Epoch 244/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 53.0957 - val_loss: 51.0626\n",
      "Epoch 245/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 50.4919 - val_loss: 54.6275\n",
      "Epoch 246/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 52.9768 - val_loss: 56.4697\n",
      "Epoch 247/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 51.3952 - val_loss: 50.9887\n",
      "Epoch 248/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 51.8508 - val_loss: 52.8268\n",
      "Epoch 249/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 52.8869 - val_loss: 56.5153\n",
      "Epoch 250/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 52.6005 - val_loss: 50.5902\n",
      "Epoch 251/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 51.4532 - val_loss: 50.1027\n",
      "Epoch 252/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 51.7750 - val_loss: 51.4325\n",
      "Epoch 253/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 51.7855 - val_loss: 50.5563\n",
      "Epoch 254/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 52.0864 - val_loss: 49.7222\n",
      "Epoch 255/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 51.5635 - val_loss: 50.8462\n",
      "Epoch 256/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 51.4658 - val_loss: 49.9469\n",
      "Epoch 257/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 53.0722 - val_loss: 51.1459\n",
      "Epoch 258/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 52.5314 - val_loss: 50.3653\n",
      "Epoch 259/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 52.6044 - val_loss: 50.2322\n",
      "Epoch 260/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 52.3568 - val_loss: 50.6791\n",
      "Epoch 261/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 50.6371 - val_loss: 51.4120\n",
      "Epoch 262/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 51.9214 - val_loss: 50.2675\n",
      "Epoch 263/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 50.8684 - val_loss: 49.5805\n",
      "Epoch 264/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 51.6967 - val_loss: 53.6225\n",
      "Epoch 265/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 51.8172 - val_loss: 50.4327\n",
      "Epoch 266/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 51.4858 - val_loss: 56.2768\n",
      "Epoch 267/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 51.2991 - val_loss: 51.4675\n",
      "Epoch 268/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 51.6432 - val_loss: 50.0790\n",
      "Epoch 269/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 49.9103 - val_loss: 50.1926\n",
      "Epoch 270/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 52.2155 - val_loss: 49.5275\n",
      "Epoch 271/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 52.3948 - val_loss: 51.0480\n",
      "Epoch 272/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 51.1782 - val_loss: 50.2632\n",
      "Epoch 273/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 50.9304 - val_loss: 49.4524\n",
      "Epoch 274/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 51.1133 - val_loss: 51.8003\n",
      "Epoch 275/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 50.4486 - val_loss: 51.2934\n",
      "Epoch 276/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 51.7918 - val_loss: 49.2535\n",
      "Epoch 277/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 51.6865 - val_loss: 48.9155\n",
      "Epoch 278/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 50.8217 - val_loss: 49.9624\n",
      "Epoch 279/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 47.9941 - val_loss: 54.0937\n",
      "Epoch 280/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 52.3808 - val_loss: 49.9602\n",
      "Epoch 281/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 48.9559 - val_loss: 52.1268\n",
      "Epoch 282/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 51.5201 - val_loss: 48.9955\n",
      "Epoch 283/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 51.9672 - val_loss: 49.7402\n",
      "Epoch 284/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 51.0972 - val_loss: 48.8527\n",
      "Epoch 285/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 52.1159 - val_loss: 49.0097\n",
      "Epoch 286/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 50.0792 - val_loss: 49.8323\n",
      "Epoch 287/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 49.3107 - val_loss: 49.5888\n",
      "Epoch 288/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 52.2745 - val_loss: 50.1609\n",
      "Epoch 289/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 50.4738 - val_loss: 49.9894\n",
      "Epoch 290/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 51.3001 - val_loss: 52.3485\n",
      "Epoch 291/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 52.9784 - val_loss: 49.0065\n",
      "Epoch 292/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 50.4631 - val_loss: 49.3127\n",
      "Epoch 293/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 49.5466 - val_loss: 49.2840\n",
      "Epoch 294/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 50.0737 - val_loss: 49.1276\n",
      "Epoch 295/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 49.4546 - val_loss: 50.4505\n",
      "Epoch 296/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 51.5058 - val_loss: 48.6341\n",
      "Epoch 297/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 50.3445 - val_loss: 48.0259\n",
      "Epoch 298/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 49.1964 - val_loss: 48.6951\n",
      "Epoch 299/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 49.4303 - val_loss: 50.0154\n",
      "Epoch 300/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 50.5433 - val_loss: 48.6560\n",
      "Epoch 301/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 51.5333 - val_loss: 48.9555\n",
      "Epoch 302/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 50.7703 - val_loss: 52.2385\n",
      "Epoch 303/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 51.3342 - val_loss: 49.9970\n",
      "Epoch 304/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 49.6090 - val_loss: 48.6059\n",
      "Epoch 305/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 47.2101 - val_loss: 55.9270\n",
      "Epoch 306/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 48.2826 - val_loss: 48.2976\n",
      "Epoch 307/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 50.3989 - val_loss: 49.0880\n",
      "Epoch 308/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 51.0134 - val_loss: 48.6394\n",
      "Epoch 309/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 50.8335 - val_loss: 51.8945\n",
      "Epoch 310/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 47.1523 - val_loss: 50.4957\n",
      "Epoch 311/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 52.0710 - val_loss: 47.8629\n",
      "Epoch 312/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 49.9452 - val_loss: 49.2185\n",
      "Epoch 313/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 49.1879 - val_loss: 49.7341\n",
      "Epoch 314/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 49.2682 - val_loss: 51.6351\n",
      "Epoch 315/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 49.3182 - val_loss: 54.3567\n",
      "Epoch 316/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 48.6344 - val_loss: 50.6482\n",
      "Epoch 317/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 49.9410 - val_loss: 48.0477\n",
      "Epoch 318/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 49.6591 - val_loss: 47.4733\n",
      "Epoch 319/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 49.2316 - val_loss: 47.6490\n",
      "Epoch 320/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 49.2824 - val_loss: 48.0259\n",
      "Epoch 321/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 48.1010 - val_loss: 50.3210\n",
      "Epoch 322/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 48.1719 - val_loss: 47.6149\n",
      "Epoch 323/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 50.2318 - val_loss: 52.8357\n",
      "Epoch 324/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 50.0077 - val_loss: 47.8568\n",
      "Epoch 325/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 46.6221 - val_loss: 48.0678\n",
      "Epoch 326/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 48.6371 - val_loss: 48.5934\n",
      "Epoch 327/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 48.0396 - val_loss: 47.0077\n",
      "Epoch 328/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 47.3523 - val_loss: 49.7967\n",
      "Epoch 329/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 48.8112 - val_loss: 49.9874\n",
      "Epoch 330/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 49.1491 - val_loss: 47.4064\n",
      "Epoch 331/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 52.8680 - val_loss: 47.6519\n",
      "Epoch 332/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 47.9569 - val_loss: 46.9942\n",
      "Epoch 333/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 48.2130 - val_loss: 49.7975\n",
      "Epoch 334/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 50.3144 - val_loss: 50.8032\n",
      "Epoch 335/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 47.1848 - val_loss: 47.0351\n",
      "Epoch 336/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 48.9551 - val_loss: 47.5827\n",
      "Epoch 337/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 47.4877 - val_loss: 55.1704\n",
      "Epoch 338/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 48.4829 - val_loss: 48.1811\n",
      "Epoch 339/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 48.4005 - val_loss: 47.7971\n",
      "Epoch 340/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 47.9169 - val_loss: 47.2459\n",
      "Epoch 341/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 49.2577 - val_loss: 48.4319\n",
      "Epoch 342/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 46.7421 - val_loss: 48.3828\n",
      "Epoch 343/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 48.5566 - val_loss: 56.1967\n",
      "Epoch 344/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 49.9821 - val_loss: 47.6300\n",
      "Epoch 345/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 49.2486 - val_loss: 54.9465\n",
      "Epoch 346/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 47.6297 - val_loss: 46.6148\n",
      "Epoch 347/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 51.3573 - val_loss: 47.8967\n",
      "Epoch 348/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 48.6821 - val_loss: 46.4361\n",
      "Epoch 349/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 50.0062 - val_loss: 46.9878\n",
      "Epoch 350/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 46.7165 - val_loss: 47.5947\n",
      "Epoch 351/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 48.0112 - val_loss: 48.1362\n",
      "Epoch 352/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 49.6329 - val_loss: 46.6105\n",
      "Epoch 353/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 48.3448 - val_loss: 50.5206\n",
      "Epoch 354/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 46.4904 - val_loss: 50.5421\n",
      "Epoch 355/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 46.8072 - val_loss: 47.0501\n",
      "Epoch 356/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 46.7882 - val_loss: 46.0352\n",
      "Epoch 357/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 48.5019 - val_loss: 46.2137\n",
      "Epoch 358/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 47.7563 - val_loss: 49.6227\n",
      "Epoch 359/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 48.3088 - val_loss: 49.2778\n",
      "Epoch 360/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 47.9767 - val_loss: 52.3718\n",
      "Epoch 361/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 48.6008 - val_loss: 46.4390\n",
      "Epoch 362/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 47.6355 - val_loss: 49.8916\n",
      "Epoch 363/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 46.6823 - val_loss: 51.1447\n",
      "Epoch 364/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 46.2295 - val_loss: 58.2485\n",
      "Epoch 365/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 46.6516 - val_loss: 46.4494\n",
      "Epoch 366/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 46.8480 - val_loss: 46.0630\n",
      "Epoch 367/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 45.5466 - val_loss: 47.3534\n",
      "Epoch 368/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 46.8659 - val_loss: 45.7472\n",
      "Epoch 369/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 45.7034 - val_loss: 45.3340\n",
      "Epoch 370/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 44.6255 - val_loss: 52.1960\n",
      "Epoch 371/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 46.7488 - val_loss: 65.8104\n",
      "Epoch 372/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 48.8200 - val_loss: 46.4753\n",
      "Epoch 373/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 47.7999 - val_loss: 46.9779\n",
      "Epoch 374/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 50.2298 - val_loss: 46.0392\n",
      "Epoch 375/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 48.9482 - val_loss: 47.0662\n",
      "Epoch 376/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 46.2227 - val_loss: 45.6453\n",
      "Epoch 377/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 44.7403 - val_loss: 48.1466\n",
      "Epoch 378/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 46.8560 - val_loss: 45.1864\n",
      "Epoch 379/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 44.8884 - val_loss: 45.2768\n",
      "Epoch 380/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 47.2512 - val_loss: 44.9877\n",
      "Epoch 381/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 45.6829 - val_loss: 44.8033\n",
      "Epoch 382/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 47.6685 - val_loss: 47.2467\n",
      "Epoch 383/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 46.9755 - val_loss: 45.8461\n",
      "Epoch 384/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 46.9685 - val_loss: 45.0559\n",
      "Epoch 385/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 47.6351 - val_loss: 48.5462\n",
      "Epoch 386/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 45.7617 - val_loss: 46.2210\n",
      "Epoch 387/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 46.9010 - val_loss: 48.3624\n",
      "Epoch 388/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 46.1015 - val_loss: 49.5830\n",
      "Epoch 389/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 46.1331 - val_loss: 45.4074\n",
      "Epoch 390/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 45.4585 - val_loss: 43.9913\n",
      "Epoch 391/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 46.0198 - val_loss: 46.3259\n",
      "Epoch 392/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 50.7166 - val_loss: 54.7806\n",
      "Epoch 393/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 45.1025 - val_loss: 44.9990\n",
      "Epoch 394/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 44.3767 - val_loss: 47.6777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 395/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 48.2906 - val_loss: 45.0684\n",
      "Epoch 396/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 48.4221 - val_loss: 44.9960\n",
      "Epoch 397/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 45.7544 - val_loss: 48.9785\n",
      "Epoch 398/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 47.7203 - val_loss: 44.0281\n",
      "Epoch 399/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 46.0207 - val_loss: 50.1230\n",
      "Epoch 400/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 48.8335 - val_loss: 47.2587\n",
      "Epoch 401/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 45.0885 - val_loss: 47.3760\n",
      "Epoch 402/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 47.6288 - val_loss: 46.8038\n",
      "Epoch 403/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 46.5815 - val_loss: 43.8573\n",
      "Epoch 404/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 45.9993 - val_loss: 45.1890\n",
      "Epoch 405/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 46.4792 - val_loss: 45.5200\n",
      "Epoch 406/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 44.2135 - val_loss: 48.2591\n",
      "Epoch 407/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 45.0852 - val_loss: 46.1894\n",
      "Epoch 408/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 45.6590 - val_loss: 47.2359\n",
      "Epoch 409/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 48.3912 - val_loss: 43.3384\n",
      "Epoch 410/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 46.3842 - val_loss: 43.4999\n",
      "Epoch 411/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 47.9306 - val_loss: 43.6226\n",
      "Epoch 412/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 45.2730 - val_loss: 43.9386\n",
      "Epoch 413/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 47.4218 - val_loss: 49.8102\n",
      "Epoch 414/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 46.3745 - val_loss: 48.1349\n",
      "Epoch 415/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 46.1627 - val_loss: 45.0103\n",
      "Epoch 416/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 43.0404 - val_loss: 51.9084\n",
      "Epoch 417/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 49.7619 - val_loss: 45.3433\n",
      "Epoch 418/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 42.8742 - val_loss: 42.9822\n",
      "Epoch 419/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 43.7412 - val_loss: 43.2376\n",
      "Epoch 420/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 44.5696 - val_loss: 53.5029\n",
      "Epoch 421/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 47.5267 - val_loss: 43.1775\n",
      "Epoch 422/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 44.1221 - val_loss: 43.2336\n",
      "Epoch 423/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 46.6779 - val_loss: 56.3347\n",
      "Epoch 424/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 45.7817 - val_loss: 61.5602\n",
      "Epoch 425/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 47.6671 - val_loss: 43.1178\n",
      "Epoch 426/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 43.3991 - val_loss: 47.6381\n",
      "Epoch 427/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 44.6010 - val_loss: 46.6948\n",
      "Epoch 428/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 44.0029 - val_loss: 49.6789\n",
      "Epoch 429/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 41.6440 - val_loss: 45.2169\n",
      "Epoch 430/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 47.1155 - val_loss: 52.3971\n",
      "Epoch 431/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 49.1870 - val_loss: 44.5297\n",
      "Epoch 432/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 43.2997 - val_loss: 42.8101\n",
      "Epoch 433/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 41.0344 - val_loss: 42.4042\n",
      "Epoch 434/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 44.3385 - val_loss: 42.9970\n",
      "Epoch 435/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 43.4138 - val_loss: 48.5910\n",
      "Epoch 436/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 46.0741 - val_loss: 42.8239\n",
      "Epoch 437/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 46.5625 - val_loss: 47.9212\n",
      "Epoch 438/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 41.8491 - val_loss: 48.1695\n",
      "Epoch 439/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 44.3516 - val_loss: 43.0505\n",
      "Epoch 440/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 44.7012 - val_loss: 53.3066\n",
      "Epoch 441/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 45.1331 - val_loss: 43.3486\n",
      "Epoch 442/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 48.9699 - val_loss: 42.8456\n",
      "Epoch 443/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 43.5122 - val_loss: 43.0287\n",
      "Epoch 444/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 41.4921 - val_loss: 51.5417\n",
      "Epoch 445/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 43.2194 - val_loss: 43.0093\n",
      "Epoch 446/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 43.2037 - val_loss: 51.9741\n",
      "Epoch 447/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 43.4333 - val_loss: 52.7719\n",
      "Epoch 448/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 46.7292 - val_loss: 51.0075\n",
      "Epoch 449/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 41.7403 - val_loss: 49.7929\n",
      "Epoch 450/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 40.5779 - val_loss: 61.0971\n",
      "Epoch 451/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 50.8194 - val_loss: 45.5444\n",
      "Epoch 452/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 41.7975 - val_loss: 42.0794\n",
      "Epoch 453/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 43.3693 - val_loss: 41.1517\n",
      "Epoch 454/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 44.4498 - val_loss: 47.5442\n",
      "Epoch 455/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 44.2417 - val_loss: 42.9991\n",
      "Epoch 456/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 44.3748 - val_loss: 66.9337\n",
      "Epoch 457/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 44.5110 - val_loss: 43.8569\n",
      "Epoch 458/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 42.0006 - val_loss: 41.8717\n",
      "Epoch 459/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 39.7038 - val_loss: 41.4472\n",
      "Epoch 460/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 43.3486 - val_loss: 42.1157\n",
      "Epoch 461/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 43.8134 - val_loss: 69.9440\n",
      "Epoch 462/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 40.7739 - val_loss: 41.4153\n",
      "Epoch 463/1000\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 45.0903 - val_loss: 41.0143\n",
      "Epoch 464/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 43.9084 - val_loss: 41.6746\n",
      "Epoch 465/1000\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 41.6254 - val_loss: 44.1969\n",
      "Epoch 466/1000\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 42.1653 - val_loss: 46.0951\n",
      "Epoch 467/1000\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 41.0658 - val_loss: 47.5744\n",
      "Epoch 468/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 41.0667 - val_loss: 42.6355\n",
      "Epoch 469/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 46.6548 - val_loss: 57.0474\n",
      "Epoch 470/1000\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 41.6583 - val_loss: 50.8943\n",
      "Epoch 471/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 45.3096 - val_loss: 42.0957\n",
      "Epoch 472/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 43.6324 - val_loss: 53.2501\n",
      "Epoch 473/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 8ms/step - loss: 41.6185 - val_loss: 42.8524\n",
      "Epoch 474/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 43.5497 - val_loss: 47.9698\n",
      "Epoch 475/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 44.5692 - val_loss: 42.3209\n",
      "Epoch 476/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 42.6332 - val_loss: 53.0310\n",
      "Epoch 477/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 42.9294 - val_loss: 45.6878\n",
      "Epoch 478/1000\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 44.9304 - val_loss: 40.6614\n",
      "Epoch 479/1000\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 41.5780 - val_loss: 45.8990\n",
      "Epoch 480/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 44.9144 - val_loss: 44.8821\n",
      "Epoch 481/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 42.3407 - val_loss: 44.6920\n",
      "Epoch 482/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 42.4899 - val_loss: 41.3379\n",
      "Epoch 483/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 41.5781 - val_loss: 72.2292\n",
      "Epoch 484/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 48.5973 - val_loss: 40.5685\n",
      "Epoch 485/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 45.4179 - val_loss: 40.8771\n",
      "Epoch 486/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 40.2952 - val_loss: 40.3506\n",
      "Epoch 487/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 43.6836 - val_loss: 40.7230\n",
      "Epoch 488/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 38.1959 - val_loss: 58.3869\n",
      "Epoch 489/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 41.7693 - val_loss: 42.8293\n",
      "Epoch 490/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 40.8495 - val_loss: 43.8744\n",
      "Epoch 491/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 43.6576 - val_loss: 43.5284\n",
      "Epoch 492/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 41.4034 - val_loss: 43.4123\n",
      "Epoch 493/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 42.9541 - val_loss: 40.4583\n",
      "Epoch 494/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 40.4611 - val_loss: 39.9286\n",
      "Epoch 495/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 41.7538 - val_loss: 40.9489\n",
      "Epoch 496/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 47.1001 - val_loss: 39.7542\n",
      "Epoch 497/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 42.3490 - val_loss: 40.2215\n",
      "Epoch 498/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 43.2409 - val_loss: 63.3156\n",
      "Epoch 499/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 41.4144 - val_loss: 39.8638\n",
      "Epoch 500/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 41.7250 - val_loss: 44.4664\n",
      "Epoch 501/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 42.1056 - val_loss: 64.7596\n",
      "Epoch 502/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 46.4082 - val_loss: 39.7601\n",
      "Epoch 503/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 47.5257 - val_loss: 44.2005\n",
      "Epoch 504/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 41.8855 - val_loss: 41.3318\n",
      "Epoch 505/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 39.7400 - val_loss: 44.6257\n",
      "Epoch 506/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 43.0099 - val_loss: 46.7799\n",
      "Epoch 507/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 43.5283 - val_loss: 42.2317\n",
      "Epoch 508/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 45.1575 - val_loss: 49.9658\n",
      "Epoch 509/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 40.0652 - val_loss: 42.4372\n",
      "Epoch 510/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 42.8767 - val_loss: 40.0873\n",
      "Epoch 511/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 42.8674 - val_loss: 71.3423\n",
      "Epoch 512/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 45.7747 - val_loss: 38.8094\n",
      "Epoch 513/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 49.5868 - val_loss: 40.2503\n",
      "Epoch 514/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 44.9801 - val_loss: 39.0671\n",
      "Epoch 515/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 45.8890 - val_loss: 50.0296\n",
      "Epoch 516/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 42.1840 - val_loss: 48.5709\n",
      "Epoch 517/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 42.7612 - val_loss: 39.1501\n",
      "Epoch 518/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 43.5187 - val_loss: 39.5445\n",
      "Epoch 519/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 42.7680 - val_loss: 64.6744\n",
      "Epoch 520/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 41.4174 - val_loss: 42.0960\n",
      "Epoch 521/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 48.6334 - val_loss: 51.4228\n",
      "Epoch 522/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 41.5115 - val_loss: 41.7552\n",
      "Epoch 523/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 42.4951 - val_loss: 38.9216\n",
      "Epoch 524/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 43.8750 - val_loss: 38.4818\n",
      "Epoch 525/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 40.4952 - val_loss: 47.5947\n",
      "Epoch 526/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 41.3214 - val_loss: 39.2920\n",
      "Epoch 527/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 38.7969 - val_loss: 44.3260\n",
      "Epoch 528/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 49.4853 - val_loss: 48.8454\n",
      "Epoch 529/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 46.2781 - val_loss: 41.4771\n",
      "Epoch 530/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 41.5667 - val_loss: 38.0870\n",
      "Epoch 531/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 43.4725 - val_loss: 40.4424\n",
      "Epoch 532/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 42.6155 - val_loss: 43.6065\n",
      "Epoch 533/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 41.9792 - val_loss: 40.3927\n",
      "Epoch 534/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 41.4465 - val_loss: 39.0732\n",
      "Epoch 535/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 48.1873 - val_loss: 41.4252\n",
      "Epoch 536/1000\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 43.9455 - val_loss: 41.1418\n",
      "Epoch 537/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 40.7112 - val_loss: 81.0903\n",
      "Epoch 538/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 49.5732 - val_loss: 38.5105\n",
      "Epoch 539/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 38.3259 - val_loss: 38.0076\n",
      "Epoch 540/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 39.7635 - val_loss: 54.0493\n",
      "Epoch 541/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 40.6407 - val_loss: 39.4430\n",
      "Epoch 542/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 41.3708 - val_loss: 44.2805\n",
      "Epoch 543/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 44.5770 - val_loss: 45.9128\n",
      "Epoch 544/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 40.3898 - val_loss: 84.9067\n",
      "Epoch 545/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 44.9536 - val_loss: 38.1895\n",
      "Epoch 546/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 42.4408 - val_loss: 39.7110\n",
      "Epoch 547/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 38.6624 - val_loss: 61.1585\n",
      "Epoch 548/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 40.0659 - val_loss: 50.0667\n",
      "Epoch 549/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 52.3102 - val_loss: 51.7863\n",
      "Epoch 550/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 41.3130 - val_loss: 39.3713\n",
      "Epoch 551/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 8ms/step - loss: 41.1993 - val_loss: 52.3611\n",
      "Epoch 552/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 45.4906 - val_loss: 38.4651\n",
      "Epoch 553/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 38.9319 - val_loss: 61.7753\n",
      "Epoch 554/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 42.7329 - val_loss: 46.2022\n",
      "Epoch 555/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 45.1472 - val_loss: 37.9505\n",
      "Epoch 556/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 39.4982 - val_loss: 40.4908\n",
      "Epoch 557/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 37.3400 - val_loss: 41.9819\n",
      "Epoch 558/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 43.2395 - val_loss: 44.1211\n",
      "Epoch 559/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 41.9764 - val_loss: 38.7118\n",
      "Epoch 560/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 38.9391 - val_loss: 41.2944\n",
      "Epoch 561/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 41.1971 - val_loss: 52.0602\n",
      "Epoch 562/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 37.3059 - val_loss: 43.2312\n",
      "Epoch 563/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 37.9749 - val_loss: 45.1664\n",
      "Epoch 564/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 36.4406 - val_loss: 37.6910\n",
      "Epoch 565/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 38.0587 - val_loss: 37.5153\n",
      "Epoch 566/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 39.9936 - val_loss: 42.3371\n",
      "Epoch 567/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 44.1628 - val_loss: 37.3350\n",
      "Epoch 568/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 39.3402 - val_loss: 44.7641\n",
      "Epoch 569/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 36.1330 - val_loss: 37.3005\n",
      "Epoch 570/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 37.8456 - val_loss: 45.3767\n",
      "Epoch 571/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 40.8744 - val_loss: 45.0627\n",
      "Epoch 572/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 38.6126 - val_loss: 55.0691\n",
      "Epoch 573/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 39.7544 - val_loss: 40.5860\n",
      "Epoch 574/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 37.8578 - val_loss: 41.1116\n",
      "Epoch 575/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 43.9284 - val_loss: 39.8491\n",
      "Epoch 576/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 37.5947 - val_loss: 37.3228\n",
      "Epoch 577/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 36.4213 - val_loss: 37.3522\n",
      "Epoch 578/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 39.4897 - val_loss: 53.7282\n",
      "Epoch 579/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 41.8377 - val_loss: 38.4239\n",
      "Epoch 580/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 41.5054 - val_loss: 37.9068\n",
      "Epoch 581/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 39.7574 - val_loss: 38.9752\n",
      "Epoch 582/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 37.6468 - val_loss: 114.8687\n",
      "Epoch 583/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 44.6507 - val_loss: 49.5938\n",
      "Epoch 584/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 34.9279 - val_loss: 38.1656\n",
      "Epoch 585/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 36.2678 - val_loss: 36.6997\n",
      "Epoch 586/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 37.4667 - val_loss: 37.5970\n",
      "Epoch 587/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 36.8454 - val_loss: 73.8073\n",
      "Epoch 588/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 52.0213 - val_loss: 51.8530\n",
      "Epoch 589/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 43.7915 - val_loss: 51.2366\n",
      "Epoch 590/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 37.4664 - val_loss: 36.7110\n",
      "Epoch 591/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 39.5894 - val_loss: 40.2821\n",
      "Epoch 592/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 39.4624 - val_loss: 37.1959\n",
      "Epoch 593/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 39.8809 - val_loss: 47.0847\n",
      "Epoch 594/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 37.3555 - val_loss: 43.3862\n",
      "Epoch 595/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 42.2830 - val_loss: 39.5844\n",
      "Epoch 596/1000\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 35.7885 - val_loss: 38.5586\n",
      "Epoch 597/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 36.5100 - val_loss: 38.8435\n",
      "Epoch 598/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 45.3104 - val_loss: 49.3493\n",
      "Epoch 599/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 42.9010 - val_loss: 42.0420\n",
      "Epoch 600/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 40.9247 - val_loss: 42.3128\n",
      "Epoch 601/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 36.2444 - val_loss: 44.2573\n",
      "Epoch 602/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 39.5694 - val_loss: 56.4541\n",
      "Epoch 603/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 40.1364 - val_loss: 36.0460\n",
      "Epoch 604/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 36.0050 - val_loss: 42.1506\n",
      "Epoch 605/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 40.8992 - val_loss: 38.8852\n",
      "Epoch 606/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 35.8420 - val_loss: 44.9347\n",
      "Epoch 607/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 36.7104 - val_loss: 36.7457\n",
      "Epoch 608/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 40.9028 - val_loss: 36.1730\n",
      "Epoch 609/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 40.7401 - val_loss: 37.6657\n",
      "Epoch 610/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 37.0694 - val_loss: 47.2585\n",
      "Epoch 611/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 38.4699 - val_loss: 35.9053\n",
      "Epoch 612/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 41.8459 - val_loss: 39.1376\n",
      "Epoch 613/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 37.1033 - val_loss: 52.4791\n",
      "Epoch 614/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 49.1444 - val_loss: 36.5844\n",
      "Epoch 615/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 33.7416 - val_loss: 41.1105\n",
      "Epoch 616/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 37.0865 - val_loss: 39.2223\n",
      "Epoch 617/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 37.6546 - val_loss: 43.2780\n",
      "Epoch 618/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 39.9451 - val_loss: 44.3648\n",
      "Epoch 619/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 39.7857 - val_loss: 35.6629\n",
      "Epoch 620/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 43.4272 - val_loss: 40.7515\n",
      "Epoch 621/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 45.8375 - val_loss: 37.8949\n",
      "Epoch 622/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 40.7585 - val_loss: 40.2176\n",
      "Epoch 623/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 49.9650 - val_loss: 36.9778\n",
      "Epoch 624/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 37.4848 - val_loss: 35.9284\n",
      "Epoch 625/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 42.2408 - val_loss: 41.8401\n",
      "Epoch 626/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 37.5610 - val_loss: 50.1945\n",
      "Epoch 627/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 35.2893 - val_loss: 35.9765\n",
      "Epoch 628/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 37.6350 - val_loss: 37.7558\n",
      "Epoch 629/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 35.7309 - val_loss: 50.7123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 630/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 39.7951 - val_loss: 35.6648\n",
      "Epoch 631/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 37.6949 - val_loss: 45.1771\n",
      "Epoch 632/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 42.2303 - val_loss: 48.9862\n",
      "Epoch 633/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 37.8497 - val_loss: 36.7886\n",
      "Epoch 634/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 35.7351 - val_loss: 65.3341\n",
      "Epoch 635/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 38.8336 - val_loss: 70.3102\n",
      "Epoch 636/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 39.1145 - val_loss: 46.8493\n",
      "Epoch 637/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 44.0977 - val_loss: 65.3579\n",
      "Epoch 638/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 38.6465 - val_loss: 36.0749\n",
      "Epoch 639/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 42.6911 - val_loss: 35.3044\n",
      "Epoch 640/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 37.8985 - val_loss: 35.8132\n",
      "Epoch 641/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 33.4198 - val_loss: 69.0327\n",
      "Epoch 642/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 43.3017 - val_loss: 38.6253\n",
      "Epoch 643/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 35.3652 - val_loss: 60.6908\n",
      "Epoch 644/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 38.7097 - val_loss: 39.7459\n",
      "Epoch 645/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 39.1484 - val_loss: 45.3027\n",
      "Epoch 646/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 38.4177 - val_loss: 35.8562\n",
      "Epoch 647/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 35.8627 - val_loss: 35.8503\n",
      "Epoch 648/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 33.4563 - val_loss: 44.9955\n",
      "Epoch 649/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 34.6700 - val_loss: 35.4513\n",
      "Epoch 650/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 34.9211 - val_loss: 35.9675\n",
      "Epoch 651/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 35.1078 - val_loss: 38.8339\n",
      "Epoch 652/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 41.6651 - val_loss: 36.4754\n",
      "Epoch 653/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 36.7410 - val_loss: 66.7690\n",
      "Epoch 654/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 45.8632 - val_loss: 37.8432\n",
      "Epoch 655/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 38.9901 - val_loss: 36.0764\n",
      "Epoch 656/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 34.6648 - val_loss: 39.7319\n",
      "Epoch 657/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 33.5857 - val_loss: 37.1304\n",
      "Epoch 658/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 37.1124 - val_loss: 45.5075\n",
      "Epoch 659/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 34.1161 - val_loss: 40.4122\n",
      "Epoch 660/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 42.7566 - val_loss: 43.4899\n",
      "Epoch 661/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 43.6968 - val_loss: 35.4421\n",
      "Epoch 662/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 41.7053 - val_loss: 36.3069\n",
      "Epoch 663/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 35.6357 - val_loss: 35.3652\n",
      "Epoch 664/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 38.9069 - val_loss: 47.2844\n",
      "Epoch 665/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 37.8995 - val_loss: 65.2821\n",
      "Epoch 666/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 38.0750 - val_loss: 46.7630\n",
      "Epoch 667/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 34.0716 - val_loss: 142.3566\n",
      "Epoch 668/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 59.4322 - val_loss: 40.1586\n",
      "Epoch 669/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 39.3659 - val_loss: 63.5014\n",
      "Epoch 670/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 42.4150 - val_loss: 38.4847\n",
      "Epoch 671/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 36.2445 - val_loss: 35.6882\n",
      "Epoch 672/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 37.1515 - val_loss: 51.1603\n",
      "Epoch 673/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 38.8144 - val_loss: 37.0350\n",
      "Epoch 674/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 36.2391 - val_loss: 46.7470\n",
      "Epoch 675/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 39.8329 - val_loss: 38.6755\n",
      "Epoch 676/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 40.3295 - val_loss: 37.6480\n",
      "Epoch 677/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 47.4544 - val_loss: 40.3488\n",
      "Epoch 678/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 38.2451 - val_loss: 40.5558\n",
      "Epoch 679/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 35.5974 - val_loss: 46.5476\n",
      "Epoch 680/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 44.3338 - val_loss: 51.4934\n",
      "Epoch 681/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 41.6988 - val_loss: 41.4167\n",
      "Epoch 682/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 37.0183 - val_loss: 41.1241\n",
      "Epoch 683/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 40.0548 - val_loss: 38.2045\n",
      "Epoch 684/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 35.2741 - val_loss: 41.3452\n",
      "Epoch 685/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 35.6533 - val_loss: 49.0262\n",
      "Epoch 686/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 37.9994 - val_loss: 34.2691\n",
      "Epoch 687/1000\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 35.1990 - val_loss: 34.1389\n",
      "Epoch 688/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 37.7005 - val_loss: 34.6519\n",
      "Epoch 689/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 40.7546 - val_loss: 38.8383\n",
      "Epoch 690/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 33.9198 - val_loss: 48.9679\n",
      "Epoch 691/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 40.0827 - val_loss: 34.7413\n",
      "Epoch 692/1000\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 36.3732 - val_loss: 35.3866\n",
      "Epoch 693/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 39.1726 - val_loss: 35.5557\n",
      "Epoch 694/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 43.1118 - val_loss: 36.4582\n",
      "Epoch 695/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 33.3813 - val_loss: 39.5043\n",
      "Epoch 696/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 39.5014 - val_loss: 34.5278\n",
      "Epoch 697/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 43.9074 - val_loss: 39.1066\n",
      "Epoch 698/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 35.2018 - val_loss: 41.0463\n",
      "Epoch 699/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 42.1508 - val_loss: 37.0478\n",
      "Epoch 700/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 34.8020 - val_loss: 35.4153\n",
      "Epoch 701/1000\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 44.3575 - val_loss: 36.7539\n",
      "Epoch 702/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 33.8635 - val_loss: 35.2032\n",
      "Epoch 703/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 35.8092 - val_loss: 35.3274\n",
      "Epoch 704/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 37.2553 - val_loss: 41.5173\n",
      "Epoch 705/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 35.8860 - val_loss: 40.9863\n",
      "Epoch 706/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 38.8439 - val_loss: 40.9449\n",
      "Epoch 707/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 44.7940 - val_loss: 44.7059\n",
      "Epoch 708/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 35.5386 - val_loss: 45.4713\n",
      "Epoch 709/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 40.6076 - val_loss: 35.7171\n",
      "Epoch 710/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 37.6674 - val_loss: 46.2091\n",
      "Epoch 711/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 35.7447 - val_loss: 53.7530\n",
      "Epoch 712/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 46.4869 - val_loss: 39.0468\n",
      "Epoch 713/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 36.2836 - val_loss: 65.4201\n",
      "Epoch 714/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 40.3304 - val_loss: 34.5043\n",
      "Epoch 715/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 34.3930 - val_loss: 35.0079\n",
      "Epoch 716/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 33.3595 - val_loss: 35.1970\n",
      "Epoch 717/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 37.9684 - val_loss: 37.7478\n",
      "Epoch 718/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 36.9579 - val_loss: 34.0861\n",
      "Epoch 719/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 41.0657 - val_loss: 35.1268\n",
      "Epoch 720/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 32.5167 - val_loss: 34.3809\n",
      "Epoch 721/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 35.7927 - val_loss: 159.5777\n",
      "Epoch 722/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 53.1187 - val_loss: 41.0858\n",
      "Epoch 723/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 36.5532 - val_loss: 45.3608\n",
      "Epoch 724/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 39.5091 - val_loss: 36.0868\n",
      "Epoch 725/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 45.6826 - val_loss: 43.0329\n",
      "Epoch 726/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 34.9734 - val_loss: 38.9480\n",
      "Epoch 727/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 33.9866 - val_loss: 38.2523\n",
      "Epoch 728/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 34.2857 - val_loss: 91.1332\n",
      "Epoch 729/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 45.6534 - val_loss: 37.6300\n",
      "Epoch 730/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 36.0477 - val_loss: 33.9789\n",
      "Epoch 731/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 44.3814 - val_loss: 35.5971\n",
      "Epoch 732/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 39.4083 - val_loss: 34.6511\n",
      "Epoch 733/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 33.5708 - val_loss: 37.9809\n",
      "Epoch 734/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 37.2561 - val_loss: 36.4178\n",
      "Epoch 735/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 34.2614 - val_loss: 45.6415\n",
      "Epoch 736/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 38.1665 - val_loss: 35.4256\n",
      "Epoch 737/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 35.1139 - val_loss: 44.3286\n",
      "Epoch 738/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 37.2300 - val_loss: 35.5694\n",
      "Epoch 739/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 34.6107 - val_loss: 33.6157\n",
      "Epoch 740/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 34.7004 - val_loss: 34.2674\n",
      "Epoch 741/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 47.7722 - val_loss: 36.4320\n",
      "Epoch 742/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 37.8169 - val_loss: 34.0653\n",
      "Epoch 743/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 39.1773 - val_loss: 34.1124\n",
      "Epoch 744/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 41.1329 - val_loss: 46.4422\n",
      "Epoch 745/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 46.5908 - val_loss: 34.1615\n",
      "Epoch 746/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 41.3574 - val_loss: 41.6247\n",
      "Epoch 747/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 34.1492 - val_loss: 33.7393\n",
      "Epoch 748/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 30.1876 - val_loss: 38.9068\n",
      "Epoch 749/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 36.6601 - val_loss: 34.0139\n",
      "Epoch 750/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 32.8141 - val_loss: 38.9031\n",
      "Epoch 751/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 32.7695 - val_loss: 34.0842\n",
      "Epoch 752/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 33.9641 - val_loss: 33.7663\n",
      "Epoch 753/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 33.3378 - val_loss: 33.7653\n",
      "Epoch 754/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 34.3100 - val_loss: 33.2633\n",
      "Epoch 755/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 32.4582 - val_loss: 34.9208\n",
      "Epoch 756/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 37.0640 - val_loss: 39.0960\n",
      "Epoch 757/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 34.6363 - val_loss: 33.5195\n",
      "Epoch 758/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 32.1773 - val_loss: 41.0416\n",
      "Epoch 759/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 41.2749 - val_loss: 37.1229\n",
      "Epoch 760/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 48.7223 - val_loss: 34.5788\n",
      "Epoch 761/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 38.7348 - val_loss: 34.0485\n",
      "Epoch 762/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 34.7451 - val_loss: 37.0210\n",
      "Epoch 763/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 33.9252 - val_loss: 43.8035\n",
      "Epoch 764/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 39.4542 - val_loss: 37.9920\n",
      "Epoch 765/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 36.5217 - val_loss: 34.3377\n",
      "Epoch 766/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 39.4913 - val_loss: 49.0939\n",
      "Epoch 767/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 39.9893 - val_loss: 36.1900\n",
      "Epoch 768/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 34.8094 - val_loss: 33.4908\n",
      "Epoch 769/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 33.5012 - val_loss: 39.2980\n",
      "Epoch 770/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 38.6307 - val_loss: 48.4149\n",
      "Epoch 771/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 36.2482 - val_loss: 36.0528\n",
      "Epoch 772/1000\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 30.4332 - val_loss: 35.2618\n",
      "Epoch 773/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 35.3011 - val_loss: 40.2516\n",
      "Epoch 774/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 34.4330 - val_loss: 40.6945\n",
      "Epoch 775/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 33.2592 - val_loss: 35.9556\n",
      "Epoch 776/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 39.0212 - val_loss: 33.4746\n",
      "Epoch 777/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 35.0532 - val_loss: 54.7065\n",
      "Epoch 778/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 34.6558 - val_loss: 36.0767\n",
      "Epoch 779/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 30.0043 - val_loss: 33.7159\n",
      "Epoch 780/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 29.4528 - val_loss: 37.6038\n",
      "Epoch 781/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 38.1583 - val_loss: 38.1512\n",
      "Epoch 782/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 36.2459 - val_loss: 37.3594\n",
      "Epoch 783/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 34.1515 - val_loss: 47.8992\n",
      "Epoch 784/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 33.1222 - val_loss: 33.6946\n",
      "Epoch 785/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 42.2157 - val_loss: 44.5314\n",
      "Epoch 786/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 38.0999 - val_loss: 56.2151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 787/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 45.8360 - val_loss: 37.1448\n",
      "Epoch 788/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 41.3739 - val_loss: 34.2888\n",
      "Epoch 789/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 33.7449 - val_loss: 40.8077\n",
      "Epoch 790/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 33.5157 - val_loss: 35.3085\n",
      "Epoch 791/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 35.0319 - val_loss: 92.6041\n",
      "Epoch 792/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 43.2298 - val_loss: 48.6681\n",
      "Epoch 793/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 33.7966 - val_loss: 33.8388\n",
      "Epoch 794/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 40.0127 - val_loss: 33.3236\n",
      "Epoch 795/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 32.6497 - val_loss: 36.3388\n",
      "Epoch 796/1000\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 33.7255 - val_loss: 39.3424\n",
      "Epoch 797/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 36.6857 - val_loss: 36.9233\n",
      "Epoch 798/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 34.6291 - val_loss: 33.9221\n",
      "Epoch 799/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 32.4112 - val_loss: 64.3865\n",
      "Epoch 800/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 36.2616 - val_loss: 32.9733\n",
      "Epoch 801/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 40.4035 - val_loss: 35.7824\n",
      "Epoch 802/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 36.0309 - val_loss: 80.4383\n",
      "Epoch 803/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 36.8331 - val_loss: 33.9683\n",
      "Epoch 804/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 35.1488 - val_loss: 33.1814\n",
      "Epoch 805/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 33.7834 - val_loss: 35.3943\n",
      "Epoch 806/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 38.8089 - val_loss: 33.3066\n",
      "Epoch 807/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 33.3518 - val_loss: 32.9532\n",
      "Epoch 808/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 33.8692 - val_loss: 33.2723\n",
      "Epoch 809/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 43.6070 - val_loss: 82.5735\n",
      "Epoch 810/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 43.5066 - val_loss: 36.2315\n",
      "Epoch 811/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 32.8737 - val_loss: 32.8809\n",
      "Epoch 812/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 42.3163 - val_loss: 34.8664\n",
      "Epoch 813/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 32.2064 - val_loss: 38.9252\n",
      "Epoch 814/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 37.6649 - val_loss: 90.7048\n",
      "Epoch 815/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 48.9526 - val_loss: 33.5254\n",
      "Epoch 816/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 30.1025 - val_loss: 33.1233\n",
      "Epoch 817/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 32.0743 - val_loss: 35.3038\n",
      "Epoch 818/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 34.6451 - val_loss: 38.4257\n",
      "Epoch 819/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 36.3648 - val_loss: 32.3227\n",
      "Epoch 820/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 34.5003 - val_loss: 38.2331\n",
      "Epoch 821/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 38.1516 - val_loss: 44.7095\n",
      "Epoch 822/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 36.6162 - val_loss: 39.2235\n",
      "Epoch 823/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 37.9757 - val_loss: 33.9789\n",
      "Epoch 824/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 31.3332 - val_loss: 34.5086\n",
      "Epoch 825/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 37.3259 - val_loss: 32.7015\n",
      "Epoch 826/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 32.2156 - val_loss: 32.4439\n",
      "Epoch 827/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 32.8110 - val_loss: 35.0863\n",
      "Epoch 828/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 31.3238 - val_loss: 39.5659\n",
      "Epoch 829/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 35.7634 - val_loss: 37.5294\n",
      "Epoch 830/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 44.2775 - val_loss: 35.3927\n",
      "Epoch 831/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 32.1194 - val_loss: 32.0869\n",
      "Epoch 832/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 38.7479 - val_loss: 32.8433\n",
      "Epoch 833/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 37.8321 - val_loss: 32.9575\n",
      "Epoch 834/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 35.2916 - val_loss: 44.3115\n",
      "Epoch 835/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 32.7348 - val_loss: 38.1297\n",
      "Epoch 836/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 36.3375 - val_loss: 38.0662\n",
      "Epoch 837/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 32.2726 - val_loss: 55.8739\n",
      "Epoch 838/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 33.2778 - val_loss: 88.3212\n",
      "Epoch 839/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 44.4019 - val_loss: 35.4181\n",
      "Epoch 840/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 32.4014 - val_loss: 41.4582\n",
      "Epoch 841/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 33.3432 - val_loss: 38.8144\n",
      "Epoch 842/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 35.1883 - val_loss: 34.9049\n",
      "Epoch 843/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 39.2200 - val_loss: 37.0560\n",
      "Epoch 844/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 40.0037 - val_loss: 37.9184\n",
      "Epoch 845/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 34.5121 - val_loss: 45.6547\n",
      "Epoch 846/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 33.3390 - val_loss: 32.7090\n",
      "Epoch 847/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 37.4491 - val_loss: 35.3230\n",
      "Epoch 848/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 41.8815 - val_loss: 38.5450\n",
      "Epoch 849/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 37.1321 - val_loss: 32.6019\n",
      "Epoch 850/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 33.3071 - val_loss: 44.5470\n",
      "Epoch 851/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 36.6863 - val_loss: 34.4834\n",
      "Epoch 852/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 31.5923 - val_loss: 32.4847\n",
      "Epoch 853/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 37.8430 - val_loss: 38.7605\n",
      "Epoch 854/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 37.3570 - val_loss: 62.9751\n",
      "Epoch 855/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 32.8376 - val_loss: 33.6458\n",
      "Epoch 856/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 36.3523 - val_loss: 49.4470\n",
      "Epoch 857/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 33.1530 - val_loss: 36.9908\n",
      "Epoch 858/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 28.7525 - val_loss: 33.0850\n",
      "Epoch 859/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 34.9822 - val_loss: 35.9525\n",
      "Epoch 860/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 38.6313 - val_loss: 34.6603\n",
      "Epoch 861/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 35.7640 - val_loss: 40.5992\n",
      "Epoch 862/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 52.4715 - val_loss: 37.2681\n",
      "Epoch 863/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 38.8701 - val_loss: 34.4033\n",
      "Epoch 864/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 31.0332 - val_loss: 39.5961\n",
      "Epoch 865/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 8ms/step - loss: 31.8846 - val_loss: 41.5776\n",
      "Epoch 866/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 32.2243 - val_loss: 32.9863\n",
      "Epoch 867/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 37.4412 - val_loss: 33.6511\n",
      "Epoch 868/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 34.3461 - val_loss: 32.7957\n",
      "Epoch 869/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 34.5999 - val_loss: 32.7034\n",
      "Epoch 870/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 34.0106 - val_loss: 32.0572\n",
      "Epoch 871/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 34.3503 - val_loss: 32.7425\n",
      "Epoch 872/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 33.3732 - val_loss: 34.4615\n",
      "Epoch 873/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 34.9073 - val_loss: 32.3081\n",
      "Epoch 874/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 29.3855 - val_loss: 31.7736\n",
      "Epoch 875/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 37.8828 - val_loss: 33.9194\n",
      "Epoch 876/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 31.2130 - val_loss: 55.4682\n",
      "Epoch 877/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 39.8587 - val_loss: 39.3023\n",
      "Epoch 878/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.7211 - val_loss: 36.9217\n",
      "Epoch 879/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 38.8905 - val_loss: 46.0184\n",
      "Epoch 880/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 31.2689 - val_loss: 33.2542\n",
      "Epoch 881/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 29.2384 - val_loss: 31.9450\n",
      "Epoch 882/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 35.3490 - val_loss: 34.3537\n",
      "Epoch 883/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 31.1314 - val_loss: 33.3765\n",
      "Epoch 884/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.7050 - val_loss: 33.3938\n",
      "Epoch 885/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 33.2263 - val_loss: 40.2851\n",
      "Epoch 886/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 32.5528 - val_loss: 41.8115\n",
      "Epoch 887/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 30.7444 - val_loss: 45.8146\n",
      "Epoch 888/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 33.0177 - val_loss: 68.2159\n",
      "Epoch 889/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 41.3962 - val_loss: 32.1353\n",
      "Epoch 890/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 33.3942 - val_loss: 33.7372\n",
      "Epoch 891/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 32.5696 - val_loss: 32.0286\n",
      "Epoch 892/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 31.9302 - val_loss: 35.8409\n",
      "Epoch 893/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 34.1533 - val_loss: 47.9855\n",
      "Epoch 894/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 35.3371 - val_loss: 32.3929\n",
      "Epoch 895/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 40.3268 - val_loss: 32.5877\n",
      "Epoch 896/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 29.2099 - val_loss: 34.8853\n",
      "Epoch 897/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 37.5361 - val_loss: 32.6269\n",
      "Epoch 898/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 34.8909 - val_loss: 40.3085\n",
      "Epoch 899/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 30.1035 - val_loss: 44.0160\n",
      "Epoch 900/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 30.7821 - val_loss: 32.0924\n",
      "Epoch 901/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 31.9362 - val_loss: 38.9493\n",
      "Epoch 902/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 35.1146 - val_loss: 32.1652\n",
      "Epoch 903/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 32.5229 - val_loss: 37.3724\n",
      "Epoch 904/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 34.4695 - val_loss: 36.1699\n",
      "Epoch 905/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 31.5558 - val_loss: 31.9754\n",
      "Epoch 906/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 36.1569 - val_loss: 45.0835\n",
      "Epoch 907/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 33.2583 - val_loss: 33.3348\n",
      "Epoch 908/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 34.5176 - val_loss: 33.6561\n",
      "Epoch 909/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 33.0209 - val_loss: 33.7062\n",
      "Epoch 910/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 28.5453 - val_loss: 39.6989\n",
      "Epoch 911/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 29.5780 - val_loss: 31.3418\n",
      "Epoch 912/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 30.7172 - val_loss: 35.3400\n",
      "Epoch 913/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 33.6396 - val_loss: 33.4995\n",
      "Epoch 914/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 28.3222 - val_loss: 36.5249\n",
      "Epoch 915/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 34.5884 - val_loss: 31.2715\n",
      "Epoch 916/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 33.5695 - val_loss: 36.7144\n",
      "Epoch 917/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 41.2237 - val_loss: 44.0718\n",
      "Epoch 918/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 33.1661 - val_loss: 32.4573\n",
      "Epoch 919/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 32.4546 - val_loss: 42.0313\n",
      "Epoch 920/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 32.8527 - val_loss: 31.2066\n",
      "Epoch 921/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 39.6503 - val_loss: 42.4332\n",
      "Epoch 922/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 35.5275 - val_loss: 31.7024\n",
      "Epoch 923/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 33.2304 - val_loss: 51.9931\n",
      "Epoch 924/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 30.8688 - val_loss: 40.9255\n",
      "Epoch 925/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 29.6551 - val_loss: 34.6388\n",
      "Epoch 926/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 30.2561 - val_loss: 31.9925\n",
      "Epoch 927/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 34.9030 - val_loss: 34.9037\n",
      "Epoch 928/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 31.3887 - val_loss: 34.3190\n",
      "Epoch 929/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 33.6918 - val_loss: 39.3593\n",
      "Epoch 930/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 31.7008 - val_loss: 67.3754\n",
      "Epoch 931/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 39.2980 - val_loss: 31.6225\n",
      "Epoch 932/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8838 - val_loss: 36.6389\n",
      "Epoch 933/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 40.4728 - val_loss: 33.5069\n",
      "Epoch 934/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.8358 - val_loss: 31.8235\n",
      "Epoch 935/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 29.4925 - val_loss: 37.0215\n",
      "Epoch 936/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 30.8361 - val_loss: 42.3415\n",
      "Epoch 937/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 31.4086 - val_loss: 64.1561\n",
      "Epoch 938/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 37.9234 - val_loss: 32.1939\n",
      "Epoch 939/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 28.8485 - val_loss: 31.4969\n",
      "Epoch 940/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 32.9005 - val_loss: 35.1482\n",
      "Epoch 941/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 34.9284 - val_loss: 32.8032\n",
      "Epoch 942/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 38.4354 - val_loss: 60.4531\n",
      "Epoch 943/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 30.9302 - val_loss: 48.6390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 944/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 38.8757 - val_loss: 56.0936\n",
      "Epoch 945/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 33.9047 - val_loss: 46.4768\n",
      "Epoch 946/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 35.7085 - val_loss: 51.7219\n",
      "Epoch 947/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 35.1314 - val_loss: 31.7610\n",
      "Epoch 948/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 33.0776 - val_loss: 33.7525\n",
      "Epoch 949/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 29.3250 - val_loss: 78.9934\n",
      "Epoch 950/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 44.8733 - val_loss: 42.2005\n",
      "Epoch 951/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 32.6994 - val_loss: 35.3130\n",
      "Epoch 952/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 31.0740 - val_loss: 31.3465\n",
      "Epoch 953/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 35.1029 - val_loss: 31.5872\n",
      "Epoch 954/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 36.8052 - val_loss: 32.9139\n",
      "Epoch 955/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 33.9197 - val_loss: 61.2883\n",
      "Epoch 956/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 39.5162 - val_loss: 32.0297\n",
      "Epoch 957/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 34.3040 - val_loss: 33.1804\n",
      "Epoch 958/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 32.3959 - val_loss: 57.6101\n",
      "Epoch 959/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 32.7802 - val_loss: 49.0608\n",
      "Epoch 960/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 40.2007 - val_loss: 39.8774\n",
      "Epoch 961/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 33.7876 - val_loss: 34.2509\n",
      "Epoch 962/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 31.9000 - val_loss: 36.4168\n",
      "Epoch 963/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 36.3634 - val_loss: 31.0813\n",
      "Epoch 964/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 29.9447 - val_loss: 42.7708\n",
      "Epoch 965/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 31.6608 - val_loss: 31.4384\n",
      "Epoch 966/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 28.5581 - val_loss: 42.8116\n",
      "Epoch 967/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 31.9573 - val_loss: 31.8276\n",
      "Epoch 968/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 31.8182 - val_loss: 41.0839\n",
      "Epoch 969/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 31.7175 - val_loss: 43.6263\n",
      "Epoch 970/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 33.5896 - val_loss: 60.2814\n",
      "Epoch 971/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 32.4095 - val_loss: 34.7847\n",
      "Epoch 972/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 28.8453 - val_loss: 38.3721\n",
      "Epoch 973/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 33.8347 - val_loss: 38.5658\n",
      "Epoch 974/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 32.5372 - val_loss: 43.2898\n",
      "Epoch 975/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 34.5857 - val_loss: 31.6649\n",
      "Epoch 976/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 30.5569 - val_loss: 55.6022\n",
      "Epoch 977/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 34.8571 - val_loss: 37.8729\n",
      "Epoch 978/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 31.5461 - val_loss: 31.8273\n",
      "Epoch 979/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 31.1420 - val_loss: 35.0800\n",
      "Epoch 980/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 33.2511 - val_loss: 39.3847\n",
      "Epoch 981/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 37.1499 - val_loss: 34.4181\n",
      "Epoch 982/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 25.7486 - val_loss: 33.7780\n",
      "Epoch 983/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.6035 - val_loss: 69.9690\n",
      "Epoch 984/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 36.8582 - val_loss: 33.3220\n",
      "Epoch 985/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 29.7059 - val_loss: 45.9023\n",
      "Epoch 986/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 33.6431 - val_loss: 56.5361\n",
      "Epoch 987/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 49.1753 - val_loss: 31.8755\n",
      "Epoch 988/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 38.4520 - val_loss: 34.5126\n",
      "Epoch 989/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 32.0581 - val_loss: 38.3163\n",
      "Epoch 990/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 31.3455 - val_loss: 40.2304\n",
      "Epoch 991/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 36.1632 - val_loss: 34.8293\n",
      "Epoch 992/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 35.2471 - val_loss: 42.1010\n",
      "Epoch 993/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 37.8672 - val_loss: 37.6457\n",
      "Epoch 994/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 32.1652 - val_loss: 33.8949\n",
      "Epoch 995/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 30.7778 - val_loss: 31.0582\n",
      "Epoch 996/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 36.4582 - val_loss: 45.5197\n",
      "Epoch 997/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 35.4031 - val_loss: 34.7513\n",
      "Epoch 998/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 30.3844 - val_loss: 32.3566\n",
      "Epoch 999/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 30.7384 - val_loss: 47.9790\n",
      "Epoch 1000/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 39.4122 - val_loss: 33.2952\n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Dense(256,activation='relu',input_shape=(x_train.shape[1],)))\n",
    "model4.add(Dropout(0.25))\n",
    "model4.add(Dense(1))\n",
    "opt = keras.optimizers.SGD(learning_rate=1e-3)\n",
    "model4.compile(optimizer=opt,loss='MSE')\n",
    "hist4=model4.fit(x_train,y_train,epochs=1000,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6c9175a7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 [==============================] - 2s 15ms/step - loss: 96.9081 - val_loss: 93.4607\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 90.8561 - val_loss: 86.0588\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 82.5771 - val_loss: 75.8158\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 71.4793 - val_loss: 64.8306\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 58.0909 - val_loss: 56.0990\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 49.1969 - val_loss: 51.8399\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 44.3895 - val_loss: 48.4453\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 41.3139 - val_loss: 46.4776\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 39.4677 - val_loss: 45.0954\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 38.0912 - val_loss: 43.8884\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 36.7454 - val_loss: 42.6478\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 35.6318 - val_loss: 41.5228\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 34.6227 - val_loss: 40.4878\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 33.7167 - val_loss: 39.4831\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 32.8525 - val_loss: 38.5403\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 32.0324 - val_loss: 37.6569\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 31.2630 - val_loss: 36.7429\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 30.5494 - val_loss: 35.9920\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 29.9193 - val_loss: 35.3389\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 29.4587 - val_loss: 34.7657\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 28.9970 - val_loss: 34.2268\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 28.6292 - val_loss: 33.6903\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 28.1968 - val_loss: 33.2077\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 27.8904 - val_loss: 32.7351\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 27.5272 - val_loss: 32.3405\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 27.2128 - val_loss: 32.0411\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 26.9168 - val_loss: 31.7873\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 26.6798 - val_loss: 31.3484\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 26.3724 - val_loss: 31.0919\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 26.1687 - val_loss: 30.9904\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 25.9601 - val_loss: 30.8412\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 25.8051 - val_loss: 30.4709\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 25.6237 - val_loss: 30.3941\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 25.4492 - val_loss: 30.0979\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 25.3826 - val_loss: 30.0041\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 25.2355 - val_loss: 29.9699\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 25.1126 - val_loss: 29.8058\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 25.0223 - val_loss: 29.7158\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 24.8928 - val_loss: 29.6298\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 24.8293 - val_loss: 29.4716\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 24.7088 - val_loss: 29.2903\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 24.6362 - val_loss: 29.2113\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 24.6056 - val_loss: 29.1373\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 24.4967 - val_loss: 29.1719\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 24.3889 - val_loss: 28.9436\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 24.3491 - val_loss: 28.8602\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 24.2613 - val_loss: 28.8949\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 24.1836 - val_loss: 28.7354\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 24.1056 - val_loss: 28.6168\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 24.0715 - val_loss: 28.5690\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 24.0212 - val_loss: 28.4982\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 23.9670 - val_loss: 28.4340\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 23.8697 - val_loss: 28.3883\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 23.8254 - val_loss: 28.4194\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 23.7914 - val_loss: 28.3423\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 23.7875 - val_loss: 28.2716\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 23.6840 - val_loss: 28.1667\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 23.6047 - val_loss: 28.1286\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 23.5379 - val_loss: 28.0746\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 23.4873 - val_loss: 28.0541\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 23.4690 - val_loss: 27.9851\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 23.4423 - val_loss: 27.8853\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 23.3475 - val_loss: 27.7893\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 23.2951 - val_loss: 27.8376\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 23.3353 - val_loss: 27.7285\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 23.2196 - val_loss: 27.6590\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 23.1995 - val_loss: 27.6426\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 23.1640 - val_loss: 27.6267\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 23.1653 - val_loss: 27.6040\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 23.0650 - val_loss: 27.7599\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 23.0732 - val_loss: 27.4654\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 22.9762 - val_loss: 27.4029\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 22.9555 - val_loss: 27.3369\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 22.9353 - val_loss: 27.4473\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 22.9006 - val_loss: 27.3372\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 22.8500 - val_loss: 27.3955\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 22.8393 - val_loss: 27.3466\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 22.8149 - val_loss: 27.2487\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 22.7539 - val_loss: 27.2947\n",
      "Epoch 80/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 7ms/step - loss: 22.7623 - val_loss: 27.2454\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 22.6684 - val_loss: 27.2899\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 22.7023 - val_loss: 27.1928\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 22.6372 - val_loss: 27.2434\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 22.6157 - val_loss: 27.2034\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 22.6330 - val_loss: 27.1424\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 22.5649 - val_loss: 27.1052\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 22.6296 - val_loss: 27.0520\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 22.5703 - val_loss: 27.1988\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 22.5478 - val_loss: 27.0626\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 22.4891 - val_loss: 27.0106\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 22.4932 - val_loss: 27.0178\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 22.4463 - val_loss: 26.9778\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 22.4804 - val_loss: 26.9211\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 22.4406 - val_loss: 27.0026\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 22.4180 - val_loss: 26.8697\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 22.3679 - val_loss: 26.9685\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 22.3963 - val_loss: 26.8607\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 22.3881 - val_loss: 26.8667\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 22.3391 - val_loss: 26.8571\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 22.2875 - val_loss: 26.8016\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 22.3249 - val_loss: 26.8387\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 22.3072 - val_loss: 26.8169\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 22.2946 - val_loss: 26.8346\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 22.2784 - val_loss: 26.8122\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 22.2485 - val_loss: 26.8180\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 22.2394 - val_loss: 26.8268\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 22.2257 - val_loss: 26.7724\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 22.2085 - val_loss: 26.7532\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 22.2086 - val_loss: 26.6669\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 22.2280 - val_loss: 26.7715\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 22.1810 - val_loss: 26.7891\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 22.1549 - val_loss: 26.7469\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 22.1824 - val_loss: 26.7173\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 22.1272 - val_loss: 26.6885\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 22.1058 - val_loss: 26.6305\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 22.1130 - val_loss: 26.7269\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 22.0660 - val_loss: 26.6208\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 22.0494 - val_loss: 26.6823\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 22.0294 - val_loss: 26.6663\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 22.0562 - val_loss: 26.6447\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 22.1124 - val_loss: 26.6873\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 22.0097 - val_loss: 26.6420\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 22.0465 - val_loss: 26.7263\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 21.9722 - val_loss: 26.7779\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 21.9206 - val_loss: 26.7520\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 21.9470 - val_loss: 26.7186\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 21.8865 - val_loss: 26.6962\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 21.9247 - val_loss: 26.5641\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.9489 - val_loss: 26.6028\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 21.9935 - val_loss: 26.6486\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 21.9319 - val_loss: 26.6494\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 21.8673 - val_loss: 26.6597\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 21.9171 - val_loss: 26.6224\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 21.8492 - val_loss: 26.6649\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 21.8781 - val_loss: 26.8634\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.8396 - val_loss: 26.8490\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.8556 - val_loss: 26.7348\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.7995 - val_loss: 26.6351\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 21.7946 - val_loss: 26.6976\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.7760 - val_loss: 26.5938\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.8436 - val_loss: 26.5784\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 21.7449 - val_loss: 26.7709\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 21.7614 - val_loss: 26.6296\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 21.7066 - val_loss: 26.6842\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 21.7276 - val_loss: 26.6317\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 21.7702 - val_loss: 26.6838\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 21.7595 - val_loss: 26.5547\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 21.6989 - val_loss: 26.5170\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 21.6389 - val_loss: 26.7495\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 21.7428 - val_loss: 26.6204\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 21.7271 - val_loss: 26.5509\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 21.6328 - val_loss: 26.6696\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.7102 - val_loss: 26.5694\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 21.6784 - val_loss: 26.5353\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 21.6421 - val_loss: 26.7148\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.6704 - val_loss: 26.4788\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.6335 - val_loss: 26.7099\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.6362 - val_loss: 26.4725\n",
      "Epoch 159/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 21.6542 - val_loss: 26.5415\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.6053 - val_loss: 26.4327\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.6522 - val_loss: 26.4947\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.6081 - val_loss: 26.4694\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.5412 - val_loss: 26.4640\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.5765 - val_loss: 26.5213\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.5659 - val_loss: 26.5151\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.5703 - val_loss: 26.4989\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 21.5560 - val_loss: 26.5104\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 21.5936 - val_loss: 26.3533\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 21.5366 - val_loss: 26.4366\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.5864 - val_loss: 26.3952\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.5491 - val_loss: 26.5043\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.5668 - val_loss: 26.4428\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.5517 - val_loss: 26.5486\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.4715 - val_loss: 26.5267\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.4483 - val_loss: 26.4883\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.4765 - val_loss: 26.3590\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.5731 - val_loss: 26.4447\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.4600 - val_loss: 26.3673\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.5044 - val_loss: 26.3368\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.5028 - val_loss: 26.4284\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.4502 - val_loss: 26.2741\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.5137 - val_loss: 26.2694\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.3755 - val_loss: 26.4267\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.4740 - val_loss: 26.3852\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.4096 - val_loss: 26.4606\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.4366 - val_loss: 26.2733\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.4732 - val_loss: 26.6126\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.4348 - val_loss: 26.3398\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.4611 - val_loss: 26.2679\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.4087 - val_loss: 26.2734\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.3957 - val_loss: 26.4698\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.4653 - val_loss: 26.3203\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.4394 - val_loss: 26.2487\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.3574 - val_loss: 26.2862\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.4093 - val_loss: 26.2123\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.4174 - val_loss: 26.2091\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 21.4056 - val_loss: 26.2252\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.3693 - val_loss: 26.2584\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.3742 - val_loss: 26.2766\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.3269 - val_loss: 26.2467\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.3974 - val_loss: 26.2075\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.3052 - val_loss: 26.2027\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.3223 - val_loss: 26.2102\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.2889 - val_loss: 26.2374\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.3280 - val_loss: 26.1827\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.3382 - val_loss: 26.2383\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.3765 - val_loss: 26.1226\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.3777 - val_loss: 26.2036\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.3097 - val_loss: 26.2074\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.2864 - val_loss: 26.2265\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.2813 - val_loss: 26.1250\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 21.3016 - val_loss: 26.1859\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.3545 - val_loss: 26.2081\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.2930 - val_loss: 26.1454\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.2855 - val_loss: 26.4200\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.3251 - val_loss: 26.1257\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.2509 - val_loss: 26.1250\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.2266 - val_loss: 26.1437\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.2676 - val_loss: 26.1217\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.2037 - val_loss: 26.2371\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.2084 - val_loss: 26.0752\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.1794 - val_loss: 26.0297\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.2130 - val_loss: 26.0165\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.2363 - val_loss: 26.0174\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.1714 - val_loss: 26.0545\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.1234 - val_loss: 26.4700\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.2496 - val_loss: 26.2051\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.2052 - val_loss: 26.0904\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.1208 - val_loss: 25.9766\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.1858 - val_loss: 25.9614\n",
      "Epoch 231/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.1649 - val_loss: 25.9894\n",
      "Epoch 232/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.2219 - val_loss: 26.0103\n",
      "Epoch 233/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.1324 - val_loss: 26.0474\n",
      "Epoch 234/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.1308 - val_loss: 25.9874\n",
      "Epoch 235/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.1223 - val_loss: 26.0763\n",
      "Epoch 236/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.1054 - val_loss: 26.0640\n",
      "Epoch 237/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.1460 - val_loss: 26.0525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.1421 - val_loss: 26.0715\n",
      "Epoch 239/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.1844 - val_loss: 25.9998\n",
      "Epoch 240/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.2612 - val_loss: 25.9548\n",
      "Epoch 241/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.1922 - val_loss: 25.9359\n",
      "Epoch 242/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.0967 - val_loss: 25.9685\n",
      "Epoch 243/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.0700 - val_loss: 25.9152\n",
      "Epoch 244/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.0952 - val_loss: 25.9086\n",
      "Epoch 245/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.1231 - val_loss: 25.9036\n",
      "Epoch 246/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.1253 - val_loss: 25.8760\n",
      "Epoch 247/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.0678 - val_loss: 25.8737\n",
      "Epoch 248/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 21.1211 - val_loss: 25.8667\n",
      "Epoch 249/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.0732 - val_loss: 25.8520\n",
      "Epoch 250/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.0659 - val_loss: 25.8626\n",
      "Epoch 251/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.0513 - val_loss: 25.8653\n",
      "Epoch 252/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.0651 - val_loss: 25.8735\n",
      "Epoch 253/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.0436 - val_loss: 25.8803\n",
      "Epoch 254/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.0363 - val_loss: 25.8438\n",
      "Epoch 255/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.0168 - val_loss: 25.8794\n",
      "Epoch 256/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.0452 - val_loss: 25.8720\n",
      "Epoch 257/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.0599 - val_loss: 25.8444\n",
      "Epoch 258/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.0116 - val_loss: 25.8353\n",
      "Epoch 259/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.9900 - val_loss: 25.8969\n",
      "Epoch 260/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.0091 - val_loss: 25.8424\n",
      "Epoch 261/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.9968 - val_loss: 25.8178\n",
      "Epoch 262/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.0658 - val_loss: 25.8656\n",
      "Epoch 263/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.9755 - val_loss: 25.8541\n",
      "Epoch 264/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.9575 - val_loss: 25.9818\n",
      "Epoch 265/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.9809 - val_loss: 25.8434\n",
      "Epoch 266/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.0398 - val_loss: 25.8460\n",
      "Epoch 267/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.9143 - val_loss: 26.0118\n",
      "Epoch 268/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 21.0302 - val_loss: 25.9874\n",
      "Epoch 269/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.9865 - val_loss: 25.8464\n",
      "Epoch 270/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.9446 - val_loss: 25.7505\n",
      "Epoch 271/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.9431 - val_loss: 25.7653\n",
      "Epoch 272/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.9646 - val_loss: 25.7791\n",
      "Epoch 273/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.9606 - val_loss: 25.7951\n",
      "Epoch 274/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.9614 - val_loss: 25.7852\n",
      "Epoch 275/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.9507 - val_loss: 25.9049\n",
      "Epoch 276/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.9575 - val_loss: 25.8627\n",
      "Epoch 277/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.9131 - val_loss: 25.8260\n",
      "Epoch 278/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.9375 - val_loss: 25.8028\n",
      "Epoch 279/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.8971 - val_loss: 25.7757\n",
      "Epoch 280/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.9682 - val_loss: 25.7478\n",
      "Epoch 281/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.8387 - val_loss: 25.8374\n",
      "Epoch 282/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.9463 - val_loss: 25.7602\n",
      "Epoch 283/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.8628 - val_loss: 25.7268\n",
      "Epoch 284/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.8530 - val_loss: 25.6674\n",
      "Epoch 285/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.8495 - val_loss: 25.6413\n",
      "Epoch 286/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.8329 - val_loss: 25.6565\n",
      "Epoch 287/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.8789 - val_loss: 25.6710\n",
      "Epoch 288/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.8675 - val_loss: 25.6399\n",
      "Epoch 289/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.8714 - val_loss: 25.6399\n",
      "Epoch 290/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.8322 - val_loss: 25.6484\n",
      "Epoch 291/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.7988 - val_loss: 25.6914\n",
      "Epoch 292/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.7028 - val_loss: 26.2468\n",
      "Epoch 293/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.9796 - val_loss: 25.6448\n",
      "Epoch 294/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.8441 - val_loss: 25.6528\n",
      "Epoch 295/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.8483 - val_loss: 25.6333\n",
      "Epoch 296/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.8178 - val_loss: 25.6338\n",
      "Epoch 297/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.7903 - val_loss: 25.6447\n",
      "Epoch 298/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.8432 - val_loss: 25.6255\n",
      "Epoch 299/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.7750 - val_loss: 25.6083\n",
      "Epoch 300/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.8294 - val_loss: 25.6163\n",
      "Epoch 301/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.7885 - val_loss: 25.6554\n",
      "Epoch 302/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.8313 - val_loss: 25.6734\n",
      "Epoch 303/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.7106 - val_loss: 25.8170\n",
      "Epoch 304/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.7991 - val_loss: 25.6560\n",
      "Epoch 305/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.8047 - val_loss: 25.6932\n",
      "Epoch 306/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.7958 - val_loss: 25.6365\n",
      "Epoch 307/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.7714 - val_loss: 25.7164\n",
      "Epoch 308/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.7700 - val_loss: 25.6413\n",
      "Epoch 309/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.7987 - val_loss: 25.6125\n",
      "Epoch 310/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.7498 - val_loss: 25.5675\n",
      "Epoch 311/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.8256 - val_loss: 25.5863\n",
      "Epoch 312/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.7695 - val_loss: 25.5665\n",
      "Epoch 313/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.7510 - val_loss: 25.5525\n",
      "Epoch 314/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.6821 - val_loss: 25.6247\n",
      "Epoch 315/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.7084 - val_loss: 25.6786\n",
      "Epoch 316/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.7329 - val_loss: 25.5274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 317/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.7154 - val_loss: 25.5324\n",
      "Epoch 318/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.6539 - val_loss: 25.5129\n",
      "Epoch 319/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 20.8431 - val_loss: 25.5185\n",
      "Epoch 320/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 20.6541 - val_loss: 25.6552\n",
      "Epoch 321/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 20.7463 - val_loss: 25.5356\n",
      "Epoch 322/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.6841 - val_loss: 25.6599\n",
      "Epoch 323/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.6930 - val_loss: 25.6922\n",
      "Epoch 324/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.7099 - val_loss: 25.7572\n",
      "Epoch 325/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 20.7306 - val_loss: 25.5237\n",
      "Epoch 326/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.6497 - val_loss: 25.5048\n",
      "Epoch 327/1000\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 20.6586 - val_loss: 25.5345\n",
      "Epoch 328/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 20.6265 - val_loss: 25.4915\n",
      "Epoch 329/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 20.6944 - val_loss: 25.4952\n",
      "Epoch 330/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 20.6515 - val_loss: 25.4552\n",
      "Epoch 331/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 20.6068 - val_loss: 25.4470\n",
      "Epoch 332/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 20.6296 - val_loss: 25.4283\n",
      "Epoch 333/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 20.5973 - val_loss: 25.4202\n",
      "Epoch 334/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 20.6263 - val_loss: 25.4759\n",
      "Epoch 335/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 20.6142 - val_loss: 25.4469\n",
      "Epoch 336/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 20.6302 - val_loss: 25.6228\n",
      "Epoch 337/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 20.5869 - val_loss: 25.4242\n",
      "Epoch 338/1000\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 20.5658 - val_loss: 25.4706\n",
      "Epoch 339/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 20.5216 - val_loss: 25.4562\n",
      "Epoch 340/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 20.5971 - val_loss: 25.5046\n",
      "Epoch 341/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.5621 - val_loss: 25.4131\n",
      "Epoch 342/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 20.5306 - val_loss: 25.4226\n",
      "Epoch 343/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.4787 - val_loss: 25.6966\n",
      "Epoch 344/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.4796 - val_loss: 25.4890\n",
      "Epoch 345/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.6056 - val_loss: 25.5706\n",
      "Epoch 346/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.5913 - val_loss: 25.8576\n",
      "Epoch 347/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.4725 - val_loss: 25.5408\n",
      "Epoch 348/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.5124 - val_loss: 25.3579\n",
      "Epoch 349/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.5947 - val_loss: 25.4020\n",
      "Epoch 350/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.5020 - val_loss: 25.3563\n",
      "Epoch 351/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.5085 - val_loss: 25.3746\n",
      "Epoch 352/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.4153 - val_loss: 25.3997\n",
      "Epoch 353/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.4889 - val_loss: 25.4889\n",
      "Epoch 354/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 20.4469 - val_loss: 25.4336\n",
      "Epoch 355/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.4432 - val_loss: 25.5340\n",
      "Epoch 356/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.4370 - val_loss: 25.6337\n",
      "Epoch 357/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.4061 - val_loss: 25.4202\n",
      "Epoch 358/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.4154 - val_loss: 25.4321\n",
      "Epoch 359/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.4531 - val_loss: 25.3651\n",
      "Epoch 360/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.3430 - val_loss: 25.5255\n",
      "Epoch 361/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 20.4280 - val_loss: 25.5607\n",
      "Epoch 362/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 20.3551 - val_loss: 25.3852\n",
      "Epoch 363/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.4336 - val_loss: 25.3707\n",
      "Epoch 364/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.3620 - val_loss: 25.8647\n",
      "Epoch 365/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.4574 - val_loss: 25.4258\n",
      "Epoch 366/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.2966 - val_loss: 25.3193\n",
      "Epoch 367/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.4800 - val_loss: 25.4167\n",
      "Epoch 368/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.3642 - val_loss: 25.4299\n",
      "Epoch 369/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 20.3011 - val_loss: 25.4152\n",
      "Epoch 370/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 20.3491 - val_loss: 25.3295\n",
      "Epoch 371/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 20.3527 - val_loss: 25.3164\n",
      "Epoch 372/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.3178 - val_loss: 25.2745\n",
      "Epoch 373/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 20.2992 - val_loss: 25.6150\n",
      "Epoch 374/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 20.3669 - val_loss: 25.4784\n",
      "Epoch 375/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.3244 - val_loss: 25.3139\n",
      "Epoch 376/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.2881 - val_loss: 25.2725\n",
      "Epoch 377/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.2679 - val_loss: 25.3863\n",
      "Epoch 378/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.2673 - val_loss: 25.3225\n",
      "Epoch 379/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.2728 - val_loss: 25.2814\n",
      "Epoch 380/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 20.2698 - val_loss: 25.2569\n",
      "Epoch 381/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 20.2263 - val_loss: 25.6886\n",
      "Epoch 382/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.3501 - val_loss: 25.2078\n",
      "Epoch 383/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.1240 - val_loss: 25.7884\n",
      "Epoch 384/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 20.3422 - val_loss: 25.5897\n",
      "Epoch 385/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.2888 - val_loss: 25.2419\n",
      "Epoch 386/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.2117 - val_loss: 25.3025\n",
      "Epoch 387/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.2419 - val_loss: 25.2146\n",
      "Epoch 388/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.2633 - val_loss: 25.3529\n",
      "Epoch 389/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.1520 - val_loss: 25.1628\n",
      "Epoch 390/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.2273 - val_loss: 25.3756\n",
      "Epoch 391/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.1950 - val_loss: 25.2013\n",
      "Epoch 392/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 20.1435 - val_loss: 25.5452\n",
      "Epoch 393/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 20.1816 - val_loss: 25.3070\n",
      "Epoch 394/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.1014 - val_loss: 25.2357\n",
      "Epoch 395/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 13ms/step - loss: 20.1601 - val_loss: 25.2786\n",
      "Epoch 396/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 20.2341 - val_loss: 25.4611\n",
      "Epoch 397/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 20.2219 - val_loss: 25.3354\n",
      "Epoch 398/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 20.0858 - val_loss: 25.2336\n",
      "Epoch 399/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 20.1338 - val_loss: 25.1818\n",
      "Epoch 400/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.1985 - val_loss: 25.1789\n",
      "Epoch 401/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 19.9951 - val_loss: 25.5413\n",
      "Epoch 402/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 20.1002 - val_loss: 25.1560\n",
      "Epoch 403/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.0960 - val_loss: 25.2508\n",
      "Epoch 404/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.1937 - val_loss: 25.2153\n",
      "Epoch 405/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.1188 - val_loss: 25.2464\n",
      "Epoch 406/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.1568 - val_loss: 25.1422\n",
      "Epoch 407/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.0819 - val_loss: 25.1111\n",
      "Epoch 408/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 20.1764 - val_loss: 25.1378\n",
      "Epoch 409/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 20.1326 - val_loss: 25.0644\n",
      "Epoch 410/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 20.0795 - val_loss: 25.1195\n",
      "Epoch 411/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 20.2630 - val_loss: 25.0719\n",
      "Epoch 412/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.0968 - val_loss: 25.1554\n",
      "Epoch 413/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.0215 - val_loss: 25.0868\n",
      "Epoch 414/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 20.3088 - val_loss: 25.0182\n",
      "Epoch 415/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 20.1284 - val_loss: 25.3382\n",
      "Epoch 416/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 20.1095 - val_loss: 25.1049\n",
      "Epoch 417/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 20.1827 - val_loss: 25.2159\n",
      "Epoch 418/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.1460 - val_loss: 25.3896\n",
      "Epoch 419/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.1623 - val_loss: 25.3537\n",
      "Epoch 420/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.1743 - val_loss: 25.3314\n",
      "Epoch 421/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 20.1607 - val_loss: 25.2887\n",
      "Epoch 422/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.2089 - val_loss: 25.1992\n",
      "Epoch 423/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 20.0540 - val_loss: 25.2247\n",
      "Epoch 424/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 20.0632 - val_loss: 24.9935\n",
      "Epoch 425/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 20.0841 - val_loss: 25.2402\n",
      "Epoch 426/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 20.0832 - val_loss: 25.2423\n"
     ]
    }
   ],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(Dense(32, activation='relu', kernel_regularizer=\"l1\",input_shape=(x_train.shape[1],)))\n",
    "model5.add(Dense(1 ,kernel_regularizer=\"l2\"))\n",
    "es = EarlyStopping(monitor='loss',mode='min',patience=25)\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "model5.compile(optimizer=opt,loss='MAPE')\n",
    "hist5 = model5.fit(x=x_train,y=y_train,epochs=1000,validation_data=(x_test,y_test),callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dc3b88b2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 256)               3584      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                8224      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,841\n",
      "Trainable params: 11,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 256)               3584      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                8224      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,841\n",
      "Trainable params: 11,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 256)               3584      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,841\n",
      "Trainable params: 3,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None None None\n"
     ]
    }
   ],
   "source": [
    "print(model1.summary(),model2.summary(),model3.summary(),model4.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ea4444",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2b9cbddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "19f916b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "754a7b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = to_categorical(y_train,num_classes=10)\n",
    "Y_test = to_categorical(y_test,num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "119c50bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.reshape(len(x_train),28,28,1)\n",
    "x_test=x_test.reshape(len(x_test),28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fa8e4913",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist1 = Sequential()\n",
    "mnist1.add(Conv2D(32,kernel_size=(5,5),padding='same',activation='relu',input_shape=(28,28,1)))\n",
    "mnist1.add(MaxPooling2D(pool_size=(2,2)))\n",
    "mnist1.add(Dropout(0.25))\n",
    "mnist1.add(Flatten())\n",
    "mnist1.add(Dense(64,activation='relu'))\n",
    "mnist1.add(Dropout(0.25))\n",
    "mnist1.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "91c370d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 0.0928 - accuracy: 0.9720 - val_loss: 0.0500 - val_accuracy: 0.9832\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 37s 20ms/step - loss: 0.0677 - accuracy: 0.9792 - val_loss: 0.0404 - val_accuracy: 0.9870\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.0533 - accuracy: 0.9833 - val_loss: 0.0357 - val_accuracy: 0.9887\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 41s 22ms/step - loss: 0.0431 - accuracy: 0.9861 - val_loss: 0.0355 - val_accuracy: 0.9887\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 41s 22ms/step - loss: 0.0399 - accuracy: 0.9875 - val_loss: 0.0327 - val_accuracy: 0.9900\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 41s 22ms/step - loss: 0.0318 - accuracy: 0.9899 - val_loss: 0.0358 - val_accuracy: 0.9897\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 42s 22ms/step - loss: 0.0305 - accuracy: 0.9901 - val_loss: 0.0366 - val_accuracy: 0.9885\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 60s 32ms/step - loss: 0.0288 - accuracy: 0.9909 - val_loss: 0.0364 - val_accuracy: 0.9886\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 64s 34ms/step - loss: 0.0257 - accuracy: 0.9914 - val_loss: 0.0392 - val_accuracy: 0.9884\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 44s 23ms/step - loss: 0.0239 - accuracy: 0.9924 - val_loss: 0.0374 - val_accuracy: 0.9887\n"
     ]
    }
   ],
   "source": [
    "mnist1.compile('adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "mnist1_his = mnist1.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c7f5a079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = mnist1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ddb18b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       983\n",
      "           1       1.00      0.99      1.00      1137\n",
      "           2       0.99      0.99      0.99      1039\n",
      "           3       0.99      0.99      0.99      1015\n",
      "           4       0.99      0.99      0.99       989\n",
      "           5       0.99      0.98      0.98       907\n",
      "           6       0.99      0.99      0.99       954\n",
      "           7       0.98      0.99      0.99      1018\n",
      "           8       0.98      0.99      0.99       961\n",
      "           9       0.98      0.99      0.98       997\n",
      "\n",
      "    accuracy                           0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(y_pred,axis=1)\n",
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cf18600f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 973    0    2    0    0    1    4    0    2    1]\n",
      " [   1 1131    0    0    0    0    2    2    1    0]\n",
      " [   1    2 1025    1    0    0    0    8    2    0]\n",
      " [   2    1    0 1001    0    5    0    1    1    4]\n",
      " [   0    0    0    0  977    0    1    0    2    9]\n",
      " [   0    0    0    5    0  885    4    0    7    6]\n",
      " [   2    1    0    0    3    1  947    0    0    0]\n",
      " [   0    0    4    0    0    0    0 1009    3    2]\n",
      " [   1    0    1    3    0    0    0    2  953    1]\n",
      " [   0    0    0    0    2    0    0    6    3  986]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51768caa",
   "metadata": {},
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8f9386cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist2 = Sequential()\n",
    "mnist2.add(Flatten())\n",
    "mnist2.add(Dense(256, activation = \"relu\"))\n",
    "mnist2.add(Dense(64, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c9788817",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "aed6f113",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist2.compile(optimizer=opt,loss=tf.keras.losses.sparse_categorical_crossentropy,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "767c2e21",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.5561 - accuracy: 0.8720 - val_loss: 0.4714 - val_accuracy: 0.8880\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.4539 - accuracy: 0.8866 - val_loss: 0.4046 - val_accuracy: 0.8989\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.4008 - accuracy: 0.8955 - val_loss: 0.3661 - val_accuracy: 0.9070\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3677 - accuracy: 0.9023 - val_loss: 0.3404 - val_accuracy: 0.9122\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3444 - accuracy: 0.9075 - val_loss: 0.3215 - val_accuracy: 0.9160\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3268 - accuracy: 0.9117 - val_loss: 0.3070 - val_accuracy: 0.9174\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3127 - accuracy: 0.9154 - val_loss: 0.2958 - val_accuracy: 0.9202\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3009 - accuracy: 0.9181 - val_loss: 0.2855 - val_accuracy: 0.9228\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2905 - accuracy: 0.9204 - val_loss: 0.2770 - val_accuracy: 0.9247\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2814 - accuracy: 0.9230 - val_loss: 0.2691 - val_accuracy: 0.9259\n"
     ]
    }
   ],
   "source": [
    "mnist2_his = mnist2.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bfe2dc",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d4372b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = tf.keras.datasets.imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c2ebff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import pad_sequences\n",
    "x_train = pad_sequences(x_train,maxlen=300)\n",
    "x_test = pad_sequences(x_test,maxlen=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "1edf2195",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = Sequential()\n",
    "imdb.add(Embedding(10000,32,input_length=(300)))\n",
    "imdb.add(SimpleRNN(16,activation='relu'))\n",
    "imdb.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "bccfe75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a1b1d654",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 94s 118ms/step - loss: 0.5495 - accuracy: 0.7070 - val_loss: 0.4445 - val_accuracy: 0.7919\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 149s 191ms/step - loss: 0.4380 - accuracy: 0.8060 - val_loss: 0.4407 - val_accuracy: 0.8066\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 233s 298ms/step - loss: 0.4042 - accuracy: 0.8229 - val_loss: 0.4367 - val_accuracy: 0.7995\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 152s 194ms/step - loss: 1.2628 - accuracy: 0.7135 - val_loss: 0.5679 - val_accuracy: 0.6941\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 195s 250ms/step - loss: 0.5365 - accuracy: 0.7234 - val_loss: 0.5228 - val_accuracy: 0.7370\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 107s 137ms/step - loss: 0.4511 - accuracy: 0.7869 - val_loss: 0.4048 - val_accuracy: 0.8181\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 113s 144ms/step - loss: 0.3630 - accuracy: 0.8442 - val_loss: 0.4754 - val_accuracy: 0.7799\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 82s 105ms/step - loss: 0.3513 - accuracy: 0.8461 - val_loss: 0.3424 - val_accuracy: 0.8504\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 79s 101ms/step - loss: 0.3438 - accuracy: 0.8560 - val_loss: 0.3812 - val_accuracy: 0.8360\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 78s 100ms/step - loss: 0.3215 - accuracy: 0.8642 - val_loss: 0.3499 - val_accuracy: 0.8483\n"
     ]
    }
   ],
   "source": [
    "imdb_his = imdb.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75ac586",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "46789f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = Sequential()\n",
    "lstm.add(Embedding(10000,32,input_length=(300)))\n",
    "lstm.add(LSTM(128))\n",
    "lstm.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4cd46065",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "64129bbd",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "175/782 [=====>........................] - ETA: 3:04 - loss: 0.6524 - accuracy: 0.6232"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[159], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m lstm_his \u001b[38;5;241m=\u001b[39m \u001b[43mlstm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lstm_his = lstm.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a93893c",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e268ffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = Sequential()\n",
    "gru.add(Embedding(10000,32,input_length=(300)))\n",
    "gru.add(GRU(128))\n",
    "gru.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "4993de3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "c9d45419",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 71/782 [=>............................] - ETA: 2:47 - loss: 0.7023 - accuracy: 0.5555"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[162], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m gru_his \u001b[38;5;241m=\u001b[39m \u001b[43mgru\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gru_his = gru.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3ad7fd",
   "metadata": {},
   "source": [
    "### AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "50f7e018",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c919ad3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(len(x_train),28,28,1)\n",
    "x_test = x_test.reshape(len(x_test),28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6c121606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAZJ0lEQVR4nO3df2hV9/3H8dfV2tsoN7dkNrk3M4asKBuNda1aNViNgsHAZDbbsC1suj+knVEmaZE5/zA4ZpygdJDVoQynTFf3Q52g1GbERItNSSX+wBWJMy7pTBoMbW6M7qbq5/uHeL+9xl/nem/eucnzAQe8556P5+Px4NOTe++5PuecEwAABkZYTwAAMHwRIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYOYJ6wnc7datW7p8+bICgYB8Pp/1dAAAHjnn1NPTo9zcXI0Y8eBrnUEXocuXLysvL896GgCAx9TW1qZx48Y9cJtB9+O4QCBgPQUAQBI8yr/nKYvQu+++q4KCAj311FOaMmWKjh8//kjj+BEcAAwNj/LveUoitHfvXq1atUpr165VU1OTXn75ZZWWlqq1tTUVuwMApClfKu6iPX36dL344ovaunVrbN13vvMdLVq0SFVVVQ8cG4lEFAwGkz0lAMAA6+7uVmZm5gO3SfqVUF9fn06ePKmSkpK49SUlJTpx4kS/7aPRqCKRSNwCABgekh6hK1eu6ObNm8rJyYlbn5OTo46Ojn7bV1VVKRgMxhbeGQcAw0fK3phw9wtSzrl7vki1Zs0adXd3x5a2trZUTQkAMMgk/XNCY8eO1ciRI/td9XR2dva7OpIkv98vv9+f7GkAANJA0q+EnnzySU2ZMkU1NTVx62tqalRUVJTs3QEA0lhK7phQUVGhH//4x5o6dapmzpypbdu2qbW1VW+++WYqdgcASFMpidDixYvV1dWl9evXq729XYWFhTp8+LDy8/NTsTsAQJpKyeeEHgefEwKAocHkc0IAADwqIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABgJukRqqyslM/ni1tCoVCydwMAGAKeSMVv+txzz+mf//xn7PHIkSNTsRsAQJpLSYSeeOIJrn4AAA+VkteEmpublZubq4KCAr366qu6ePHifbeNRqOKRCJxCwBgeEh6hKZPn65du3bpyJEj2r59uzo6OlRUVKSurq57bl9VVaVgMBhb8vLykj0lAMAg5XPOuVTuoLe3V88++6xWr16tioqKfs9Ho1FFo9HY40gkQogAYAjo7u5WZmbmA7dJyWtCXzdmzBhNmjRJzc3N93ze7/fL7/enehoAgEEo5Z8Tikaj+vTTTxUOh1O9KwBAmkl6hN5++23V19erpaVFH3/8sX74wx8qEoloyZIlyd4VACDNJf3HcZ999plee+01XblyRc8884xmzJihhoYG5efnJ3tXAIA0l/I3JngViUQUDAatpwEAeEyP8sYE7h0HADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJhJ+ZfaAenk6aef9jxm27Ztnsf86Ec/8jwmkXsN//vf//Y8RpJeeOEFz2OuXr2a0L4wvHElBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADPcRRtDUl5eXkLjTp8+7XlMInfevnnzpucx0WjU85hvfetbnsdI0vr16z2PqaioSGhfGN64EgIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzHADUwx64XDY85hEbkQqJXYz0o6ODs9jli1b5nnMoUOHPI/ZtWuX5zGSNG3atITGAV5xJQQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmOEGphj0qqurPY9J5EakknT+/HnPY1566SXPY3p6ejyPGTt2rOcxL7zwgucxkuT3+z2PGT16tOcx165d8zwGQwtXQgAAM0QIAGDGc4SOHTumhQsXKjc3Vz6fTwcOHIh73jmnyspK5ebmKiMjQ8XFxTp37lyy5gsAGEI8R6i3t1eTJ0++78/pN23apC1btqi6ulqNjY0KhUKaP39+Qj8DBwAMbZ7fmFBaWqrS0tJ7Puec0zvvvKO1a9eqrKxMkrRz507l5ORoz549euONNx5vtgCAISWprwm1tLSoo6NDJSUlsXV+v19z5szRiRMn7jkmGo0qEonELQCA4SGpEero6JAk5eTkxK3PycmJPXe3qqoqBYPB2JKXl5fMKQEABrGUvDvO5/PFPXbO9Vt3x5o1a9Td3R1b2traUjElAMAglNQPq4ZCIUm3r4jC4XBsfWdnZ7+rozv8fn9CH4wDAKS/pF4JFRQUKBQKqaamJraur69P9fX1KioqSuauAABDgOcroatXr+rChQuxxy0tLTp16pSysrI0fvx4rVq1Shs2bNCECRM0YcIEbdiwQaNHj9brr7+e1IkDANKf5wh98sknmjt3buxxRUWFJGnJkiX64x//qNWrV+v69etavny5vvjiC02fPl0ffPCBAoFA8mYNABgSfM45Zz2Jr4tEIgoGg9bTwCBy/Phxz2MmTZqU0L6ef/55z2NaW1sT2pdXxcXFnsfU1tYmtK+vvvrK85jx48d7HvP55597HoP00d3drczMzAduw73jAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYCap36wKPMw3vvENz2MSuSP23//+d89jpMTuiD1q1CjPY5YvX+55zIYNGzyPSdSePXs8j+GO2EgEV0IAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBluYIoB5ff7PY/JzMz0PKalpcXzGEn66U9/6nnMT37yE89j5syZ43nMQPrtb39rPQUME1wJAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmuIEpBtSVK1c8jzlz5oznMevXr/c8ZiiKRqMJjfv888+TPBPg3rgSAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMcANTDKi+vj7PY3796197HrNz507PYyRpxAjv/y/bvn275zGnT5/2PGbbtm2ex5w6dcrzGElqb29PaBzgFVdCAAAzRAgAYMZzhI4dO6aFCxcqNzdXPp9PBw4ciHt+6dKl8vl8ccuMGTOSNV8AwBDiOUK9vb2aPHmyqqur77vNggUL1N7eHlsOHz78WJMEAAxNnt+YUFpaqtLS0gdu4/f7FQqFEp4UAGB4SMlrQnV1dcrOztbEiRO1bNkydXZ23nfbaDSqSCQStwAAhoekR6i0tFS7d+9WbW2tNm/erMbGRs2bN+++33VfVVWlYDAYW/Ly8pI9JQDAIJX0zwktXrw49uvCwkJNnTpV+fn5OnTokMrKyvptv2bNGlVUVMQeRyIRQgQAw0TKP6waDoeVn5+v5ubmez7v9/vl9/tTPQ0AwCCU8s8JdXV1qa2tTeFwONW7AgCkGc9XQlevXtWFCxdij1taWnTq1CllZWUpKytLlZWV+sEPfqBwOKxLly7pl7/8pcaOHatXXnklqRMHAKQ/zxH65JNPNHfu3NjjO6/nLFmyRFu3btXZs2e1a9cuffnllwqHw5o7d6727t2rQCCQvFkDAIYEzxEqLi6Wc+6+zx85cuSxJgTc7a9//avnMU1NTQnta+TIkZ7HnD9/3vOY559/3vOYROzfv39A9gMkinvHAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwEzKv1kVsPD177wajJ5++ukB2c9f/vKXAdkPkCiuhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM9zAFDDw85//3POY3t5ez2O++uorz2OAgcSVEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghhuYAo8pIyPD85jvfve7nsd89NFHnsf897//9TwGGEhcCQEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZriBKfCYCgoKBmTMb37zG89jgMGOKyEAgBkiBAAw4ylCVVVVmjZtmgKBgLKzs7Vo0SKdP38+bhvnnCorK5Wbm6uMjAwVFxfr3LlzSZ00AGBo8BSh+vp6lZeXq6GhQTU1Nbpx44ZKSkrU29sb22bTpk3asmWLqqur1djYqFAopPnz56unpyfpkwcApDdPb0x4//334x7v2LFD2dnZOnnypGbPni3nnN555x2tXbtWZWVlkqSdO3cqJydHe/bs0RtvvJG8mQMA0t5jvSbU3d0tScrKypIktbS0qKOjQyUlJbFt/H6/5syZoxMnTtzz94hGo4pEInELAGB4SDhCzjlVVFRo1qxZKiwslCR1dHRIknJycuK2zcnJiT13t6qqKgWDwdiSl5eX6JQAAGkm4QitWLFCZ86c0Z///Od+z/l8vrjHzrl+6+5Ys2aNuru7Y0tbW1uiUwIApJmEPqy6cuVKHTx4UMeOHdO4ceNi60OhkKTbV0ThcDi2vrOzs9/V0R1+v19+vz+RaQAA0pynKyHnnFasWKF9+/aptra236e+CwoKFAqFVFNTE1vX19en+vp6FRUVJWfGAIAhw9OVUHl5ufbs2aN//OMfCgQCsdd5gsGgMjIy5PP5tGrVKm3YsEETJkzQhAkTtGHDBo0ePVqvv/56Sv4AAID05SlCW7dulSQVFxfHrd+xY4eWLl0qSVq9erWuX7+u5cuX64svvtD06dP1wQcfKBAIJGXCAIChw+ecc9aT+LpIJKJgMGg9DeCRrV692vOYjRs3eh4zceJEz2MuXLjgeQyQLN3d3crMzHzgNtw7DgBghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGYS+mZVAP8vLy/PegpA2uJKCABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwww1Mgcc0e/Zsz2POnTvneUxLS4vnMcBgx5UQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGG5gCBhoaGjyPuXnzZgpmAtjiSggAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMMMNTAEDra2t1lMABgWuhAAAZogQAMCMpwhVVVVp2rRpCgQCys7O1qJFi3T+/Pm4bZYuXSqfzxe3zJgxI6mTBgAMDZ4iVF9fr/LycjU0NKimpkY3btxQSUmJent747ZbsGCB2tvbY8vhw4eTOmkAwNDg6Y0J77//ftzjHTt2KDs7WydPntTs2bNj6/1+v0KhUHJmCAAYsh7rNaHu7m5JUlZWVtz6uro6ZWdna+LEiVq2bJk6Ozvv+3tEo1FFIpG4BQAwPCQcIeecKioqNGvWLBUWFsbWl5aWavfu3aqtrdXmzZvV2NioefPmKRqN3vP3qaqqUjAYjC15eXmJTgkAkGZ8zjmXyMDy8nIdOnRIH374ocaNG3ff7drb25Wfn6/33ntPZWVl/Z6PRqNxgYpEIoQIaeX06dOex/ztb3/zPOZXv/qV5zGApe7ubmVmZj5wm4Q+rLpy5UodPHhQx44de2CAJCkcDis/P1/Nzc33fN7v98vv9ycyDQBAmvMUIeecVq5cqf3796uurk4FBQUPHdPV1aW2tjaFw+GEJwkAGJo8vSZUXl6uP/3pT9qzZ48CgYA6OjrU0dGh69evS5KuXr2qt99+Wx999JEuXbqkuro6LVy4UGPHjtUrr7ySkj8AACB9eboS2rp1qySpuLg4bv2OHTu0dOlSjRw5UmfPntWuXbv05ZdfKhwOa+7cudq7d68CgUDSJg0AGBo8/zjuQTIyMnTkyJHHmhAAYPjgLtrAY/rss888j/n4449TMBMg/XADUwCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADATMJf750qkUhEwWDQehoAgMf0KF/vzZUQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM4MuQoPsVnYAgAQ9yr/ngy5CPT091lMAACTBo/x7Pujuon3r1i1dvnxZgUBAPp8v7rlIJKK8vDy1tbU99M6sQxnH4TaOw20ch9s4DrcNhuPgnFNPT49yc3M1YsSDr3WeGKA5PbIRI0Zo3LhxD9wmMzNzWJ9kd3AcbuM43MZxuI3jcJv1cXjUr+QZdD+OAwAMH0QIAGAmrSLk9/u1bt06+f1+66mY4jjcxnG4jeNwG8fhtnQ7DoPujQkAgOEjra6EAABDCxECAJghQgAAM0QIAGAmrSL07rvvqqCgQE899ZSmTJmi48ePW09pQFVWVsrn88UtoVDIelopd+zYMS1cuFC5ubny+Xw6cOBA3PPOOVVWVio3N1cZGRkqLi7WuXPnbCabQg87DkuXLu13fsyYMcNmsilSVVWladOmKRAIKDs7W4sWLdL58+fjthkO58OjHId0OR/SJkJ79+7VqlWrtHbtWjU1Nenll19WaWmpWltbrac2oJ577jm1t7fHlrNnz1pPKeV6e3s1efJkVVdX3/P5TZs2acuWLaqurlZjY6NCoZDmz58/5O5D+LDjIEkLFiyIOz8OHz48gDNMvfr6epWXl6uhoUE1NTW6ceOGSkpK1NvbG9tmOJwPj3IcpDQ5H1yaeOmll9ybb74Zt+7b3/62+8UvfmE0o4G3bt06N3nyZOtpmJLk9u/fH3t869YtFwqF3MaNG2Pr/ve//7lgMOh+//vfG8xwYNx9HJxzbsmSJe773/++yXysdHZ2Okmuvr7eOTd8z4e7j4Nz6XM+pMWVUF9fn06ePKmSkpK49SUlJTpx4oTRrGw0NzcrNzdXBQUFevXVV3Xx4kXrKZlqaWlRR0dH3Lnh9/s1Z86cYXduSFJdXZ2ys7M1ceJELVu2TJ2dndZTSqnu7m5JUlZWlqThez7cfRzuSIfzIS0idOXKFd28eVM5OTlx63NyctTR0WE0q4E3ffp07dq1S0eOHNH27dvV0dGhoqIidXV1WU/NzJ2//+F+bkhSaWmpdu/erdraWm3evFmNjY2aN2+eotGo9dRSwjmniooKzZo1S4WFhZKG5/lwr+Mgpc/5MOjuov0gd3+1g3Ou37qhrLS0NPbrSZMmaebMmXr22We1c+dOVVRUGM7M3nA/NyRp8eLFsV8XFhZq6tSpys/P16FDh1RWVmY4s9RYsWKFzpw5ow8//LDfc8PpfLjfcUiX8yEtroTGjh2rkSNH9vufTGdnZ7//8QwnY8aM0aRJk9Tc3Gw9FTN33h3IudFfOBxWfn7+kDw/Vq5cqYMHD+ro0aNxX/0y3M6H+x2Hexms50NaROjJJ5/UlClTVFNTE7e+pqZGRUVFRrOyF41G9emnnyocDltPxUxBQYFCoVDcudHX16f6+vphfW5IUldXl9ra2obU+eGc04oVK7Rv3z7V1taqoKAg7vnhcj487Djcy6A9HwzfFOHJe++950aNGuX+8Ic/uH/9619u1apVbsyYMe7SpUvWUxswb731lqurq3MXL150DQ0N7nvf+54LBAJD/hj09PS4pqYm19TU5CS5LVu2uKamJvef//zHOefcxo0bXTAYdPv27XNnz551r732mguHwy4SiRjPPLkedBx6enrcW2+95U6cOOFaWlrc0aNH3cyZM903v/nNIXUcfvazn7lgMOjq6upce3t7bLl27Vpsm+FwPjzsOKTT+ZA2EXLOud/97ncuPz/fPfnkk+7FF1+MezvicLB48WIXDofdqFGjXG5urisrK3Pnzp2znlbKHT161EnqtyxZssQ5d/ttuevWrXOhUMj5/X43e/Zsd/bsWdtJp8CDjsO1a9dcSUmJe+aZZ9yoUaPc+PHj3ZIlS1xra6v1tJPqXn9+SW7Hjh2xbYbD+fCw45BO5wNf5QAAMJMWrwkBAIYmIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMDM/wHATqae0aivVwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[600],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4d1b5b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Sequential()\n",
    "autoencoder.add(Flatten(input_shape=(28,28)))\n",
    "autoencoder.add(Dropout(0.25))\n",
    "autoencoder.add(Dense(256,activation='relu'))\n",
    "autoencoder.add(Dropout(0.25))\n",
    "autoencoder.add(Dense(128,activation='relu'))\n",
    "autoencoder.add(Dropout(0.25))\n",
    "autoencoder.add(Dense(64,activation='relu'))\n",
    "autoencoder.add(Dropout(0.25))\n",
    "autoencoder.add(Dense(32,activation='relu'))\n",
    "autoencoder.add(Dense(64,activation='relu'))\n",
    "autoencoder.add(Dropout(0.25))\n",
    "autoencoder.add(Dense(128,activation='relu'))\n",
    "autoencoder.add(Dropout(0.25))\n",
    "autoencoder.add(Dense(256,activation='relu'))\n",
    "autoencoder.add(Dropout(0.25))\n",
    "autoencoder.add(Dense(784,activation='sigmoid'))\n",
    "autoencoder.add(Reshape((28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8d992f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Input(shape=(28,28))\n",
    "output = autoencoder(img)\n",
    "auto = Model(inputs=img,outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d99975d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.compile(optimizer='adam',loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "cd0a0d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.fit(x_train,x_train,epochs=10,validation_data=(x_test,x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3d0594",
   "metadata": {},
   "source": [
    "### Text Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99190fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿Buffalo Billâ€™s\n",
      "defunct\n",
      "who used to\n",
      "ride a watersmooth-silver\n",
      "stallion\n",
      "and break one two three four five pigeons just like that\n",
      "Jesus\n",
      "\n",
      "he was a handsome man\n",
      "and what i want to know is\n",
      "how do you like your blueeyed boy\n",
      "Mister Death\n",
      "\n",
      "Had I the heavenâ€™s embroidered cloths,\n",
      "Enwrought with golden and silver light,\n",
      "The blue and the dim and the dark cloths\n",
      "Of night and light and the half-light,\n",
      "I would spread the cloths under your feet:\n",
      "But I, being poor, have only my dreams;\n",
      "I have spread my dreams under your feet;\n",
      "Tread softly because you tread on my dreams.\n",
      "\n",
      "He clasps the crag with crooked hands;\n",
      "Close to the sun in lonely lands,\n",
      "Ringâ€™d with the azure world, he stands.\n",
      "\n",
      "The wrinkled sea beneath him crawls;\n",
      "He watches from his mountain walls,\n",
      "And like a thunderbolt he falls.\n",
      "\n",
      "Some say the world will end in fire,\n",
      "Some say in ice.\n",
      "From what Iâ€™ve tasted of desire\n",
      "I hold with those who favor fire.\n",
      "But if it had to perish twice,\n",
      "I think I know enough of hate\n",
      "To say that for destruction ice\n",
      "Is also great\n",
      "And would suffice.\n",
      "\n",
      "Two roads diverged in a yellow wood,\n",
      "And sorry I could not travel both\n",
      "And be one traveler, long I stood\n",
      "And looked down one as far as I could\n",
      "To where it bent in the undergrowth;\n",
      "\n",
      "Then took the other, as just as fair,\n",
      "And having perhaps the better claim,\n",
      "Because it was grassy and wanted wear;\n",
      "Though as for that the passing there\n",
      "Had worn them really about the same,\n",
      "\n",
      "And both that morning equally lay\n",
      "In leaves no step had trodden black.\n",
      "Oh, I kept the first for another day!\n",
      "Yet knowing how way leads on to way,\n",
      "I doubted if I should ever come back.\n",
      "\n",
      "I shall be telling this with a sigh\n",
      "Somewhere ages and ages hence:\n",
      "Two roads diverged in a wood, and Iâ€”\n",
      "I took the one less traveled by,\n",
      "And that has made all the difference.\n"
     ]
    }
   ],
   "source": [
    "with open ('poems.txt') as f:\n",
    "    text = f.read()\n",
    "print(text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa1af74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey There :  [[6], [2], [17], [1], [4], [6], [2], [11], [2]]\n",
      "hey There :  [[6, 2, 17, 1, 4, 6, 2, 11, 2]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(text)\n",
    "print(\"hey There : \",tokenizer.texts_to_sequences('hey There'))\n",
    "print(\"hey There : \",tokenizer.texts_to_sequences(['hey There']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41772182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33, 34, 35, ..., 19,  1, 25])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array(tokenizer.texts_to_sequences([text]))[0] - 1\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6445fb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "vo_len = len(tokenizer.word_index)\n",
    "seq_len = 100\n",
    "data = tf.data.Dataset.from_tensor_slices(data)\n",
    "data = data.batch(seq_len+1,drop_remainder=True)\n",
    "data = data.map(lambda x : (x[:-1],x[1:]))\n",
    "data = data.shuffle(1000).batch(64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3710f9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = Sequential()\n",
    "tok.add(Embedding(vo_len,32))\n",
    "tok.add(GRU(100,return_sequences=True,dropout=0.1))\n",
    "tok.add(Dense(vo_len,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3deca42",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok.compile(loss='sparse_categorical_crossentropy',optimizer='adam')\n",
    "his=tok.fit(data,epochs=1000,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9c25b99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(s):\n",
    "    dat = np.array(tokenizer.texts_to_sequences([s]))-1\n",
    "    dat = tok.predict(dat)\n",
    "    out = np.argmax(dat,axis=-1)+1\n",
    "    out = tokenizer.sequences_to_texts(out)[0][-1]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5b1676f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(s,loop=10):\n",
    "    for _ in range(loop):\n",
    "        s+=generator(s)\n",
    "    return s    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "07a9303b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "vanakam da maaplads and the\n"
     ]
    }
   ],
   "source": [
    "print(pred('vanakam da maapla'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908d7883",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
